{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW3PMDt0CW9L"
      },
      "source": [
        "# 2. Physics Informed Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUooiwKyCW9P"
      },
      "source": [
        "Poisson equation with unknown forcing field\n",
        "\n",
        "<p style='font-size:18px; line-height:2.5em'> We will solve the Poisson equation : \\begin{equation}\n",
        "u_{xx} = q(x), \\quad \\text{ for } x \\in [-1,1]\n",
        "\\end{equation}\n",
        "with the Dirichlet boundary conditions \\begin{equation}\n",
        "u(-1) = 0, \\quad u(1) = 0.\n",
        "\\end{equation} Here, we assume both the solution $u(x)$ and the forcing term $q(x)$ are unknown. Instead, we assume that we are given a set of supervised observations $\\{(x_i, u_i)\\}_{i=1}^{100}$.\n",
        "    \n",
        "<p style='font-size:18px; line-height:2.5em'> The reference solution is $u(x)=\\sin(\\pi x)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Poisson equation with unknown forcing field\n",
        "\n",
        "$$\n",
        "u_{xx} = q(x), \\quad \\text{ for } x \\in [-1,1]\n",
        "\\text{ with the Dirichlet boundary conditions }\n",
        "u(-1) = 0, \\quad u(1) = 0.\n",
        "$$\n",
        "\n",
        "Here, we assume both the solution $u(x)$ and the forcing term $q(x)$ are unknown. Instead, we assume that we are given a set of supervised observations $\\{(x_i, u_i)\\}_{i=1}^{100}$.\n",
        "\n",
        "    \n",
        "The reference solution is $u(x)=\\sin(\\pi x)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kNtRR_BCW9P"
      },
      "source": [
        "# Dataset generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-26T12:25:07.375344Z",
          "start_time": "2022-05-26T12:25:07.368315Z"
        },
        "id": "7Gr2_hQBCW9P"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m N = \u001b[32m1000\u001b[39m                                                 \u001b[38;5;66;03m# Number of samples\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m x = \u001b[43mtorch\u001b[49m.linspace(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, N).view(-\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m)                  \u001b[38;5;66;03m# Input data (N x 1)\u001b[39;00m\n\u001b[32m      3\u001b[39m x_bdry = torch.FloatTensor([[-\u001b[32m1\u001b[39m],[\u001b[32m1\u001b[39m]])                   \u001b[38;5;66;03m# Input data the initial conditions (1 x 1)\u001b[39;00m\n\u001b[32m      4\u001b[39m u_bdry = torch.zeros_like(x_bdry)                        \u001b[38;5;66;03m# Target data the initial conditions (1 x 2)\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "N = 1000                                                 # Number of samples\n",
        "x = torch.linspace(-1, 1, N).view(-1,1)                  # Input data (N x 1)\n",
        "x_bdry = torch.FloatTensor([[-1],[1]])                   # Input data the initial conditions (1 x 1)\n",
        "u_bdry = torch.zeros_like(x_bdry)                        # Target data the initial conditions (1 x 2)\n",
        "x_obs = torch.linspace(-1, 1, 100).view(-1,1)            # Input data (N x 1)\n",
        "u_obs = torch.sin(np.pi*x_obs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2h5gnCSCW9P"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-26T12:25:07.917514Z",
          "start_time": "2022-05-26T12:25:07.908573Z"
        },
        "id": "Lpi2JS6bCW9P"
      },
      "outputs": [],
      "source": [
        "# Build a neural network\n",
        "\n",
        "class model(nn.Module) :\n",
        "    def __init__(self, hidden_dims) :                    # Hidden_dims : [h1, h2, h3, ..., hn]\n",
        "        super(model, self).__init__()\n",
        "\n",
        "        self.layers = []\n",
        "        for i in range(len(hidden_dims)-1) :\n",
        "            self.layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1])) # hidden layers\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "        for layer in self.layers :                       # Weight initialization\n",
        "            nn.init.xavier_uniform_(layer.weight)        # Also known as Glorot initialization\n",
        "\n",
        "        self.act = nn.Tanh()                             # Nonlinear activation function\n",
        "\n",
        "    def forward(self, x) :\n",
        "        for layer in self.layers[:-1] :\n",
        "            x = self.act(layer(x))\n",
        "        x = self.layers[-1](x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSiCF0eeCW9P"
      },
      "source": [
        "# Loss function, Optimizer, Additional Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-26T12:25:09.300182Z",
          "start_time": "2022-05-26T12:25:09.277285Z"
        },
        "id": "MgIG7_JvCW9P"
      },
      "outputs": [],
      "source": [
        "# Prepare for training\n",
        "\n",
        "network_u = model(hidden_dims=[1,64,64,64,64,1]).to(device)   # Pass the network to GPU\n",
        "network_q =\n",
        "##### Fill your own q(x) with NN, name network_q = .....\n",
        "\n",
        "x = x.to(device).requires_grad_(True)                 # Pass data to GPU\n",
        "x_bdry = x_bdry.to(device)                            # Pass data to GPU\n",
        "u_bdry = u_bdry.to(device)                            # Pass data to GPU\n",
        "x_obs = x_obs.to(device)                              # Pass data to GPU\n",
        "u_obs = u_obs.to(device)                              # Pass data to GPU\n",
        "\n",
        "loss_f = nn.MSELoss()                                             # Mean Square Error loss function\n",
        "optimizer = optim.Adam([{'params': network_u.parameters()},???], lr=1e-4)              # Adam optimizer\n",
        "#### Fill ??? part\n",
        "\n",
        "EPOCHS = 100000                                                    # Number of Training Iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-26T12:25:10.345475Z",
          "start_time": "2022-05-26T12:25:10.340890Z"
        },
        "id": "sZ3z68l3CW9P"
      },
      "outputs": [],
      "source": [
        "def derivative(y, t) :\n",
        "    return torch.autograd.grad(y, t, create_graph=True,\\\n",
        "                               grad_outputs=torch.ones(y.size()).to(device))[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX_ycDK7CW9Q"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-26T12:09:31.202174Z",
          "start_time": "2022-05-26T11:43:07.669589Z"
        },
        "id": "7hES2ijqCW9Q",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "loss_list = []\n",
        "network_u.train()\n",
        "#network_q.train()\n",
        "\n",
        "for i in range(1, EPOCHS+1) :\n",
        "    optimizer.zero_grad()\n",
        "    output_u = network_u(x)\n",
        "    output_q = network_q(x) ### possible way...\n",
        "    output_bdry = network_u(x_bdry)\n",
        "    output_obs = network_u(x_obs)\n",
        "\n",
        "    doutput = derivative(output_u, x)\n",
        "    d2output = derivative(doutput, x)\n",
        "\n",
        "    loss_bdry = loss_f(output_bdry, u_bdry)\n",
        "    loss_obs = loss_f(output_obs, u_obs)\n",
        "    loss_ge = loss_f(d2output-output_q, torch.zeros_like(output_q))\n",
        "\n",
        "    loss = loss_ge + loss_bdry + loss_obs\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "    if not i % 1000 :\n",
        "        print('EPOCH : %6d/%6d | Loss_ge : %8.7f | Loss_bdry : %8.7f | Loss_obs : %8.7f' \\\n",
        "              %(i, EPOCHS, loss_ge.item(), loss_bdry.item(), loss_obs.item()))\n",
        "        #clear_output(wait=True)\n",
        "print('Training Finished.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-26T12:25:12.681478Z",
          "start_time": "2022-05-26T12:25:12.668815Z"
        },
        "id": "m7akSN0ZCW9Q"
      },
      "outputs": [],
      "source": [
        "#torch.save([network_u, network_q], 'Poisson_inverse.pt')\n",
        "#network_u, network_q = torch.load('Poisson_inverse.pt', map_location=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-26T12:25:26.854534Z",
          "start_time": "2022-05-26T12:25:26.095939Z"
        },
        "id": "sdfk0Gi4CW9Q"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure(figsize=(13,5))\n",
        "ax1 = figure.add_subplot(1,2,1)\n",
        "ax1.plot(x.cpu().detach(), torch.sin(np.pi * x).cpu().detach(), color='r', label='True $u(x)$')\n",
        "ax1.plot(x.cpu().detach(), network_u(x).cpu().detach(), color='b', linestyle='--', lw=3, label='Trained Neural $u(x)$')\n",
        "ax1.legend(fontsize=13)\n",
        "ax1.set_title('$u(x)$', fontsize=15)\n",
        "\n",
        "ax2 = figure.add_subplot(1,2,2)\n",
        "ax2.plot(x.cpu().detach(), -(np.pi**2)*torch.sin(np.pi * x).cpu().detach(), color='r', label='True $q(x)$')\n",
        "ax2.plot(x.cpu().detach(), network_q(x).cpu().detach(), color='b', linestyle='--', lw=3, label='Trained Neural $q(x)$')\n",
        "ax2.legend(fontsize=13)\n",
        "ax2.set_title('$q(x)$', fontsize=15)\n",
        "plt.savefig('poisson_inv', dpi=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6sAVHLrCW9Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Aries",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
