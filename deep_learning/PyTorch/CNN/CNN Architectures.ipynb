{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Classification Model for ISL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sign_Lang_VGG(\n",
      "  (convolutional_block_1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (convolutional_block_2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (convolutional_block_3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (convolutional_block_4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (convolutional_block_5): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=8192, out_features=1000, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=1000, out_features=26, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 23934714\n"
     ]
    }
   ],
   "source": [
    "#Building Model: ISL Classification Model\n",
    "class Sign_Lang_VGG(torch.nn.Module):\n",
    "  '''\n",
    "  Built a VGG16 architecture variant for  Indian Sign Language Classification\n",
    "  The dataset: https://www.kaggle.com/datasets/prathumarikeri/indian-sign-language-isl\n",
    "  '''\n",
    "  def __init__(self,\n",
    "               input_shape: int,\n",
    "               output_shape: int):\n",
    "    super().__init__()\n",
    "    self.convolutional_block_1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=input_shape,\n",
    "                  out_channels=64,\n",
    "                  kernel_size=(3,3),\n",
    "                  stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=64,\n",
    "                  out_channels=64,\n",
    "                  kernel_size=(3,3),\n",
    "                  stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=(2,2))\n",
    "\n",
    "    )\n",
    "    self.convolutional_block_2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64,\n",
    "                  out_channels=128,\n",
    "                  kernel_size=(3,3),\n",
    "                  stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=128,\n",
    "                out_channels=128,\n",
    "                kernel_size=(3,3),\n",
    "                stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=(2,2))\n",
    "    )\n",
    "    self.convolutional_block_3 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=128,\n",
    "                  out_channels=256,\n",
    "                  kernel_size=(3,3),\n",
    "                  stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=256,\n",
    "                out_channels=256,\n",
    "                kernel_size=(3,3),\n",
    "                stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=256,\n",
    "        out_channels=256,\n",
    "        kernel_size=(3,3),\n",
    "        stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=(2,2))\n",
    "    )\n",
    "    self.convolutional_block_4 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=256,\n",
    "                  out_channels=512,\n",
    "                  kernel_size=(3,3),\n",
    "                  stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512,\n",
    "                out_channels=512,\n",
    "                kernel_size=(3,3),\n",
    "                stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512,\n",
    "        out_channels=512,\n",
    "        kernel_size=(3,3),\n",
    "        stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=(2,2))\n",
    "    )\n",
    "    self.convolutional_block_5 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=512,\n",
    "                  out_channels=512,\n",
    "                  kernel_size=(3,3),\n",
    "                  stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512,\n",
    "                out_channels=512,\n",
    "                kernel_size=(3,3),\n",
    "                stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512,\n",
    "        out_channels=512,\n",
    "        kernel_size=(3,3),\n",
    "        stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=(2,2))\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(512*4*4,\n",
    "                  1000),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1000,\n",
    "                  1000),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1000,\n",
    "                  output_shape)\n",
    "    )\n",
    "\n",
    "  def forward(self, x: torch.Tensor):\n",
    "    x = self.convolutional_block_1(x)\n",
    "    x = self.convolutional_block_2(x)\n",
    "    x = self.convolutional_block_3(x)\n",
    "    x = self.convolutional_block_4(x)\n",
    "    x = self.convolutional_block_5(x)\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "\n",
    "seed = 25\n",
    "torch.manual_seed(seed)\n",
    "model= Sign_Lang_VGG(input_shape=3,\n",
    "                  output_shape=26)\n",
    "print(f\"{model}\")\n",
    "\n",
    "\n",
    "# Count the total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16 = [64, 64, \"MaxPool\", 128, 128, \"MaxPool\", 256, 256, 256, \"MaxPool\", 512, 512, 512, \"MaxPool\", 512, 512, 512, \"MaxPool\"]\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, input=3, output_shape=1000):\n",
    "        super(VGG, self).__init__()\n",
    "        self.input = input\n",
    "        self.convolutional_blocks = self.create_convolutional_blocks(VGG16)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(512*7*7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, out):\n",
    "        out = self.convolutional_blocks(out)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    \n",
    "    def create_convolutional_blocks(self, architecture):\n",
    "        layers = []\n",
    "        input = self.input\n",
    "\n",
    "        for k in architecture:\n",
    "            if type(k) == int:\n",
    "                output = k\n",
    "\n",
    "                layers += [nn.Conv2d(input, output, \n",
    "                                     kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "                                     nn.ReLU()]\n",
    "                input = k\n",
    "            elif k == \"MaxPool\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))]\n",
    "        return nn.Sequential(*layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSL VGG13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_params = [32, 32, \"MaxPool\", 64, 64, \"MaxPool\", 128, 128, 128,\"MaxPool\", 256, 256, 256, \"MaxPool\"]\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, input=3, output_shape=1000):\n",
    "        super(VGG, self).__init__()\n",
    "        self.input = input\n",
    "        self.convolutional_blocks = self.create_convolutional_blocks(chosen_model_params)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(256*2*2, 2096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2096, 2096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2096, output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, out):\n",
    "        out = self.convolutional_blocks(out)\n",
    "        # print(f\"Shape after convolutional blocks: {out.shape}\") ### --> print this to get proper shape for the fully connected layer\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    \n",
    "    def create_convolutional_blocks(self, architecture):\n",
    "        layers = []\n",
    "        input = self.input\n",
    "\n",
    "        for k in architecture:\n",
    "            if type(k) == int:\n",
    "                output = k\n",
    "\n",
    "                layers += [nn.Conv2d(input, output, \n",
    "                                     kernel_size=(5,5), stride=(1,1), padding=(1,1)),\n",
    "                                     nn.BatchNorm2d(k),\n",
    "                                     nn.ReLU()]\n",
    "                input = k\n",
    "            elif k == \"MaxPool\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "seed = 25\n",
    "torch.manual_seed(25)\n",
    "# fsl_model = VGG(input=3, output_shape=len(train_data.classes)).to(device)\n",
    "fsl_model = VGG(input=3, output_shape=26)\n",
    "print(f\"{fsl_model}\")\n",
    "\n",
    "\n",
    "\n",
    "# Count the total number of parameters\n",
    "total_params = sum(p.numel() for p in fsl_model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): Block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): Block(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=2048, out_features=17, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 23563153\n"
     ]
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    expansion: int = 4\n",
    "    def __init__(self, input, output, identity_downsample=None, stride=(1,1)):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input, output, kernel_size=(1,1), stride=(1,1), padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(output)\n",
    "        self.conv2 = nn.Conv2d(output, output, kernel_size=(3,3), stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(output)\n",
    "        self.conv3 = nn.Conv2d(output, output*self.expansion, \n",
    "                               kernel_size=(1,1), stride=(1,1), padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(output*self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block: Block, layers, input_shape, output_shape):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.input = 64\n",
    "        self.conv1 = nn.Conv2d(input_shape, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3))\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "\n",
    "        ###ResNet Layers\n",
    "        self.layer1 = self.make_layer(block,layers[0], output=64, stride=(1,1))\n",
    "        self.layer2 = self.make_layer(block,layers[1], output=128, stride=(1,1))\n",
    "        self.layer3 = self.make_layer(block,layers[2], output=256, stride=(1,1))\n",
    "        self.layer4 = self.make_layer(block,layers[3], output=512, stride=(1,1))\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Sequential( \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*block.expansion, output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def make_layer(self, block, num_residual_MyBlocks, output, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.input != output*block.expansion:\n",
    "            identity_downsample = nn.Sequential(nn.Conv2d(\n",
    "                self.input, output * block.expansion, kernel_size=(1,1), stride=stride),\n",
    "                nn.BatchNorm2d(output*4)\n",
    "            )\n",
    "        layers.append(block(self.input, output, identity_downsample, stride))\n",
    "        self.input = output*block.expansion\n",
    "\n",
    "        for i in range(num_residual_MyBlocks-1):\n",
    "            layers.append(block(self.input, output))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "seed = 25\n",
    "torch.manual_seed(25)\n",
    "model2 = ResNet(Block, [3,4,6,3], input_shape=1, output_shape=17)\n",
    "print(f\"{model2}\")\n",
    "\n",
    "\n",
    "# Count the total number of parameters\n",
    "total_params = sum(p.numel() for p in model2.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=(2, 2), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=256, out_features=17, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 1424721\n"
     ]
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    expansion: int = 2\n",
    "\n",
    "    def __init__(self, input, output, identity_downsample=None, stride=(1,1)):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input, output, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.bn1 = nn.BatchNorm2d(output)\n",
    "        self.conv2 = nn.Conv2d(output,output*self.expansion, kernel_size=(3,3), stride=stride, padding=(1,1))\n",
    "        self.bn2 = nn.BatchNorm2d(output*self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        # print(f\"{self.expansion}\")\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block: Block, layers, input_shape, output_shape):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.input = 16\n",
    "        self.conv1 = nn.Conv2d(input_shape, 16, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2,2), stride=1, padding=0)\n",
    "\n",
    "        self.layer1 = self.create_layers(block, layers[0], output=16, stride=1)\n",
    "        self.layer2 = self.create_layers(block, layers[1], output=32, stride=2)\n",
    "        self.layer3 = self.create_layers(block, layers[2], output=64, stride=2)\n",
    "        self.layer4 = self.create_layers(block, layers[3], output=128, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential( \n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(128 * block.expansion, output_shape)\n",
    "        )\n",
    "        # print(f\"{block.expansion}\")\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def create_layers(self, block, num_residual_blocks, output, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.input != output * block.expansion:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.input, output * block.expansion, kernel_size=(1,1), stride=stride),\n",
    "                nn.BatchNorm2d(output * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers.append(block(self.input, output, identity_downsample, stride))\n",
    "        self.input = output * block.expansion\n",
    "\n",
    "        for _ in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.input, output))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "  \n",
    "\n",
    "seed = 25\n",
    "torch.manual_seed(25)\n",
    "model2 = ResNet(Block, [2,2,2,2], input_shape=1, output_shape=17)\n",
    "print(f\"{model2}\")\n",
    "\n",
    "\n",
    "# Count the total number of parameters\n",
    "total_params = sum(p.numel() for p in model2.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    expansion: int = 2\n",
    "\n",
    "    def __init__(self, input, output, identity_downsample=None, stride=(1,1)):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input, output, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.bn1 = nn.BatchNorm2d(output)\n",
    "        self.conv2 = nn.Conv2d(output,output*self.expansion, kernel_size=(3,3), stride=stride, padding=(1,1))\n",
    "        self.bn2 = nn.BatchNorm2d(output*self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class Baybayin_ResNet(nn.Module):\n",
    "    def __init__(self, block: Block, layers, input_shape, output_shape):\n",
    "        super(Baybayin_ResNet, self).__init__()\n",
    "        self.input = 16\n",
    "        self.conv1 = nn.Conv2d(input_shape, 16, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2,2), stride=1, padding=0)\n",
    "\n",
    "        self.layer1 = self.create_layers(block, layers[0], output=16, stride=1)\n",
    "        self.layer2 = self.create_layers(block, layers[1], output=32, stride=2)\n",
    "        self.layer3 = self.create_layers(block, layers[2], output=64, stride=2)\n",
    "        self.layer4 = self.create_layers(block, layers[3], output=128, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential( \n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(128 * block.expansion, output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def create_layers(self, block, num_residual_blocks, output, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.input != output * block.expansion:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.input, output * block.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(output * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers.append(block(self.input, output, identity_downsample, stride))\n",
    "        self.input = output * block.expansion\n",
    "\n",
    "        for _ in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.input, output))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "  \n",
    "\n",
    "def ResNet18(img_channels=1, output_shape=10):\n",
    "    return ResNet(Block, [2, 2, 2, 2], img_channels, output_shape)\n",
    "\n",
    "# Example usage:\n",
    "model = ResNet18()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FSL ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=512, out_features=26, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 10743674\n"
     ]
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    expansion: int = 2\n",
    "    def __init__(self, input, output, identity_downsample=None, stride=(1,1)):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input, output, kernel_size=(3,3), stride=(1,1), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(output)\n",
    "        self.conv2 = nn.Conv2d(output, output*self.expansion, \n",
    "                               kernel_size=(3,3), stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(output*self.expansion,)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block: Block, layers, input_shape, output_shape):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.input = 32\n",
    "        self.conv1 = nn.Conv2d(input_shape, 32, kernel_size=(5,5), stride=(2,2), padding=(2,2))\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "\n",
    "        ###ResNet Layers\n",
    "        self.layer1 = self.make_layer(block,layers[0], output=32, stride=(1,1))\n",
    "        self.layer2 = self.make_layer(block,layers[1], output=64, stride=(2,2))\n",
    "        self.layer3 = self.make_layer(block,layers[2], output=128, stride=(2,2))\n",
    "        self.layer4 = self.make_layer(block,layers[3], output=256, stride=(2,2))\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Sequential( \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*block.expansion, output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def make_layer(self, block, num_residual_MyBlocks, output, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.input != output*block.expansion:\n",
    "            identity_downsample = nn.Sequential(nn.Conv2d(\n",
    "                self.input, output * block.expansion, kernel_size=(1,1), stride=stride),\n",
    "                nn.BatchNorm2d(output*block.expansion)\n",
    "            )\n",
    "        layers.append(block(self.input, output, identity_downsample, stride))\n",
    "        self.input = output*block.expansion\n",
    "\n",
    "        for i in range(num_residual_MyBlocks-1):\n",
    "            layers.append(block(self.input, output))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "seed = 25\n",
    "torch.manual_seed(25)\n",
    "# fsl_model = ResNet(Block, [3,4,6,3], input_shape=3, output_shape=26).to(device)\n",
    "fsl_model = ResNet(Block, [3,4,6,3], input_shape=3, output_shape=26)\n",
    "print(f\"{fsl_model}\")\n",
    "\n",
    "\n",
    "# Count the total number of parameters\n",
    "total_params = sum(p.numel() for p in fsl_model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper codes F1, Recall, Precision, and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import ConfusionMatrix\n",
    "from torchmetrics.functional import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "def infer(data_loader:torch.utils.data.DataLoader,\n",
    "           model:torch.nn.Module,\n",
    "           test_data):\n",
    "    y_preds = []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(data_loader):\n",
    "            # Send the data to the proper target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Forward pass\n",
    "            y_logit = model(X)\n",
    "            # Turn predictions into class labels\n",
    "            y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "            # Put predictions on CPU for evaluation\n",
    "            y_preds.append(y_pred.cpu())\n",
    "\n",
    "    # Concatenate list of predictions into a tensor\n",
    "    y_preds = torch.cat(y_preds)  # This line ensures y_preds is a tensor\n",
    "\n",
    "    # Ensure test_data.targets is a tensor\n",
    "    test_targets_tensor = torch.tensor(test_data.targets) if not isinstance(test_data.targets, torch.Tensor) else test_data.targets\n",
    "    return test_targets_tensor, y_preds\n",
    "\n",
    "test_targets1, y_preds1 = infer(test_dataloader, model_LION, test_data)\n",
    "\n",
    "def create_confusion_matrix(y_true, y_pred, class_names, num_classes=None, figsize=(19, 10)):\n",
    "\n",
    "    if num_classes is None:\n",
    "        num_classes = len(class_names)\n",
    "    \n",
    "    # Create confusion matrix instance\n",
    "    confmat = ConfusionMatrix(num_classes=num_classes, task=\"multiclass\")\n",
    "    confmat_tensor = confmat(preds=y_pred, target=y_true)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    fig, ax = plot_confusion_matrix(\n",
    "        conf_mat=confmat_tensor.numpy(),\n",
    "        class_names=class_names,\n",
    "        figsize=figsize\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    return confmat_tensor\n",
    "\n",
    "create_confusion_matrix(test_targets1, y_preds1, class_names=train_data.classes)\n",
    "f1_score1, precision_score1, recall_score1 = calculate_metric(test_targets1.cpu(), y_preds1)\n",
    "print(f\"Print F1 score: {f1_score1}\")\n",
    "print(f\"Precision Score: {precision_score1}\")\n",
    "print(f\"Recall Score: {recall_score1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "def calculate_metric(y_true, y_pred, average=\"weighted\"): ##--> Choose 'micro', 'macro', or 'weighted'\n",
    "    # Convert logits to predicted class labels if necessary\n",
    "    if y_pred.dim() > 1:\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    # Move to CPU and convert to numpy arrays if necessary\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average=average)  \n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    \n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN KAN\n",
    "\n",
    "Convolutional Neural Network Kolgomorov Arnold Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG_KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG_KAN(\n",
      "  (convolutional_blocks): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU()\n",
      "    (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU()\n",
      "    (20): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU()\n",
      "    (23): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU()\n",
      "    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU()\n",
      "    (30): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU()\n",
      "    (33): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (KANClassifier): Sequential(\n",
      "    (0): NaiveFourierKANLayer()\n",
      "    (1): NaiveFourierKANLayer()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 1329305164\n"
     ]
    }
   ],
   "source": [
    "# chosen_model_params = [32, 32, \"MaxPool\", 64, 64, \"MaxPool\", 128, 128, 128,\"MaxPool\", 256, 256, 256, \"MaxPool\"]\n",
    "chosen_model_params = [64, \"MaxPool\",128, 128, \"MaxPool\"]\n",
    "# chosen_model_params = [16,16,\"MaxPool\",32,\"Maxpool\"]\n",
    "\n",
    "class NaiveFourierKANLayer(nn.Module):\n",
    "    def __init__(self, inputdim, outdim, initial_gridsize, addbias=True):\n",
    "        super(NaiveFourierKANLayer, self).__init__()\n",
    "        self.addbias = addbias\n",
    "        self.inputdim = inputdim\n",
    "        self.outdim = outdim\n",
    "        self.gridsize_param = nn.Parameter(torch.tensor(initial_gridsize, dtype=torch.float32)) #adjusted during training\n",
    "        self.fouriercoeffs = nn.Parameter(torch.empty(2, outdim, inputdim, initial_gridsize)) #adjusted during training\n",
    "        nn.init.xavier_uniform_(self.fouriercoeffs)\n",
    "        if self.addbias:\n",
    "            self.bias = nn.Parameter(torch.zeros(1, outdim))\n",
    "\n",
    "    def forward(self, x): #Combines cosine/sine terms with learnable coefficents for Fourier expansion and sums them + bias\n",
    "        gridsize = torch.clamp(self.gridsize_param, min=1).round().int()\n",
    "        outshape = x.shape[:-1] + (self.outdim,)\n",
    "        x = torch.reshape(x, (-1, self.inputdim))\n",
    "        k = torch.reshape(torch.arange(1, gridsize + 1, device=x.device), (1, 1, 1, gridsize))\n",
    "        xrshp = torch.reshape(x, (x.shape[0], 1, x.shape[1], 1))\n",
    "        c = torch.cos(k * xrshp)\n",
    "        s = torch.sin(k * xrshp)\n",
    "        y = torch.sum(c * self.fouriercoeffs[0:1, :, :, :gridsize], (-2, -1))\n",
    "        y += torch.sum(s * self.fouriercoeffs[1:2, :, :, :gridsize], (-2, -1))\n",
    "        if self.addbias:\n",
    "            y += self.bias\n",
    "        y = torch.reshape(y, outshape)\n",
    "        return y\n",
    "\n",
    "class VGG_KAN(nn.Module):\n",
    "    def __init__(self, input=3, output_shape=26):\n",
    "        super(VGG_KAN, self).__init__()\n",
    "        self.input = input\n",
    "        self.convolutional_blocks = self.create_convolutional_blocks(chosen_model_params)\n",
    "\n",
    "        self.KANClassifier = nn.Sequential(\n",
    "            NaiveFourierKANLayer(128*3*3, 256, initial_gridsize=25),\n",
    "            NaiveFourierKANLayer(256, output_shape, initial_gridsize=25)\n",
    "\n",
    "        )\n",
    "    \n",
    "    def forward(self, out):\n",
    "        out = self.convolutional_blocks(out)\n",
    "        # print(f\"Shape after convolutional blocks: {out.shape}\") ### --> print this to get proper shape for the fully connected layer\n",
    "\n",
    "        # out = self.classifier(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.KANClassifier(out)\n",
    "        return out\n",
    "    \n",
    "    def create_convolutional_blocks(self, architecture):\n",
    "        layers = []\n",
    "        input = self.input\n",
    "\n",
    "        for k in architecture:\n",
    "            if type(k) == int:\n",
    "                output = k\n",
    "\n",
    "                layers += [nn.Conv2d(input, output, \n",
    "                                     kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
    "                                     nn.BatchNorm2d(k),\n",
    "                                     nn.SELU()]\n",
    "                input = k\n",
    "            elif k == \"MaxPool\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=(4,4), stride=(2,2))]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "\n",
    "torch.manual_seed(42)\n",
    "fsl_model = VGG_KAN(input=3, output_shape=26)\n",
    "print(f\"{fsl_model}\")\n",
    "\n",
    "\n",
    "\n",
    "# Count the total number of parameters\n",
    "total_params = sum(p.numel() for p in fsl_model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n",
      "Shape after convolutional blocks: torch.Size([1, 256, 7, 7])\n",
      "tensor([[-0.0244,  0.1089, -0.3710, -0.1900, -0.3575, -0.3632,  0.3811, -0.0240,\n",
      "         -0.0849, -0.0614,  0.0439, -0.0904, -0.1795, -0.0823,  0.0301,  0.2366,\n",
      "          0.3434,  0.1383,  0.1374,  0.2822,  0.1175,  0.0741,  0.1067, -0.1370,\n",
      "          0.1333, -0.2222]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.randn(size=(3, 128, 128))  # Single image (C, H, W)\n",
    "print(tensor1.shape) \n",
    "\n",
    "output = fsl_model(tensor1.unsqueeze(dim=0))  # Add batch dimension\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_KAN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): Block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (KANClassifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): NaiveFourierKANLayer()\n",
      "    (2): NaiveFourierKANLayer()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 38276476\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveFourierKANLayer(nn.Module):\n",
    "    def __init__(self, inputdim, outdim, initial_gridsize, addbias=True):\n",
    "        super(NaiveFourierKANLayer, self).__init__()\n",
    "        self.addbias = addbias\n",
    "        self.inputdim = inputdim\n",
    "        self.outdim = outdim\n",
    "        self.gridsize_param = nn.Parameter(torch.tensor(initial_gridsize, dtype=torch.float32)) #adjusted during training\n",
    "        self.fouriercoeffs = nn.Parameter(torch.empty(2, outdim, inputdim, initial_gridsize)) #adjusted during training\n",
    "        nn.init.xavier_uniform_(self.fouriercoeffs)\n",
    "        if self.addbias:\n",
    "            self.bias = nn.Parameter(torch.zeros(1, outdim))\n",
    "            nn.init.uniform_(self.bias, -np.pi, np.pi)\n",
    "\n",
    "\n",
    "    def forward(self, x): #Combines cosine/sine terms with learnable coefficents for Fourier expansion and sums them + bias\n",
    "        gridsize = torch.clamp(self.gridsize_param, min=1).round().int()\n",
    "        outshape = x.shape[:-1] + (self.outdim,)\n",
    "        x = torch.reshape(x, (-1, self.inputdim))\n",
    "        k = torch.reshape(torch.arange(1, gridsize + 1, device=x.device), (1, 1, 1, gridsize))\n",
    "        xrshp = torch.reshape(x, (x.shape[0], 1, x.shape[1], 1))\n",
    "        c = torch.cos(k * xrshp)\n",
    "        s = torch.sin(k * xrshp)\n",
    "        y = torch.sum(c * self.fouriercoeffs[0:1, :, :, :gridsize], (-2, -1))\n",
    "        y += torch.sum(s * self.fouriercoeffs[1:2, :, :, :gridsize], (-2, -1))\n",
    "        if self.addbias:\n",
    "            y += self.bias\n",
    "        y = torch.reshape(y, outshape)\n",
    "        return y\n",
    "\n",
    "class Block(nn.Module):\n",
    "    expansion: int = 2\n",
    "    def __init__(self, input, output, identity_downsample=None, stride=(1,1)):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input, output, kernel_size=(3,3), stride=(1,1), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(output)\n",
    "        self.conv2 = nn.Conv2d(output, output*self.expansion, \n",
    "                               kernel_size=(3,3), stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(output*self.expansion,)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet_KAN(nn.Module):\n",
    "    def __init__(self, block: Block, layers, input_shape, output_shape):\n",
    "        super(ResNet_KAN, self).__init__()\n",
    "        self.input = 32\n",
    "        self.conv1 = nn.Conv2d(input_shape, 32, kernel_size=(5,5), stride=(2,2), padding=(2,2))\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2), padding=(1,1))\n",
    "\n",
    "        ###ResNet Layers\n",
    "        self.layer1 = self.make_layer(block,layers[0], output=32, stride=(1,1))\n",
    "        self.layer2 = self.make_layer(block,layers[1], output=64, stride=(2,2))\n",
    "        self.layer3 = self.make_layer(block,layers[2], output=128, stride=(2,2))\n",
    "        self.layer4 = self.make_layer(block,layers[3], output=256, stride=(2,2))\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        self.KANClassifier = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            NaiveFourierKANLayer(256*block.expansion, 512, initial_gridsize=50),\n",
    "            NaiveFourierKANLayer(512, output_shape, initial_gridsize=50)\n",
    "\n",
    "        )\n",
    "    \n",
    "    def forward(self,x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = self.KANClassifier(x)\n",
    "        return x\n",
    "    \n",
    "    def make_layer(self, block, num_residual_MyBlocks, output, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.input != output*block.expansion:\n",
    "            identity_downsample = nn.Sequential(nn.Conv2d(\n",
    "                self.input, output * block.expansion, kernel_size=(1,1), stride=stride),\n",
    "                nn.BatchNorm2d(output*block.expansion)\n",
    "            )\n",
    "        layers.append(block(self.input, output, identity_downsample, stride))\n",
    "        self.input = output*block.expansion\n",
    "\n",
    "        for i in range(num_residual_MyBlocks-1):\n",
    "            layers.append(block(self.input, output))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(42)\n",
    "fsl_model = ResNet_KAN(Block, [3,4,6,3], input_shape=3, output_shape=26)\n",
    "print(f\"{fsl_model}\")\n",
    "\n",
    "\n",
    "# Count the total number of parameters\n",
    "total_params = sum(p.numel() for p in fsl_model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View initialization for ResNet KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1.weight:, Weights: tensor([[[[ 0.0883,  0.0958, -0.0271,  0.1061, -0.0253],\n",
      "          [ 0.0233, -0.0562,  0.0678,  0.1018, -0.0847],\n",
      "          [ 0.1004,  0.0216,  0.0853,  0.0156,  0.0557],\n",
      "          [-0.0163,  0.0890,  0.0171, -0.0539,  0.0294],\n",
      "          [-0.0532, -0.0135, -0.0469,  0.0766, -0.0911]],\n",
      "\n",
      "         [[-0.0532, -0.0326, -0.0694,  0.0109, -0.1140],\n",
      "          [ 0.1043, -0.0981,  0.0891,  0.0192, -0.0375],\n",
      "          [ 0.0714,  0.0180,  0.0933,  0.0126, -0.0364],\n",
      "          [ 0.0310, -0.0313,  0.0486,  0.1031,  0.0667],\n",
      "          [-0.0505,  0.0667,  0.0207,  0.0586, -0.0704]],\n",
      "\n",
      "         [[-0.1143, -0.0446, -0.0886,  0.0947,  0.0333],\n",
      "          [ 0.0478,  0.0365, -0.0020,  0.0904, -0.0820],\n",
      "          [ 0.0073, -0.0788,  0.0356, -0.0398,  0.0354],\n",
      "          [-0.0241,  0.0958, -0.0684, -0.0689, -0.0689],\n",
      "          [ 0.1039,  0.0385,  0.1111, -0.0953, -0.1145]]],\n",
      "\n",
      "\n",
      "        [[[-0.0903, -0.0777,  0.0468,  0.0413,  0.0959],\n",
      "          [-0.0596, -0.0787,  0.0613, -0.0467,  0.0701],\n",
      "          [-0.0274,  0.0661, -0.0897, -0.0583,  0.0352],\n",
      "          [ 0.0244, -0.0294,  0.0688,  0.0785, -0.0837],\n",
      "          [-0.0616,  0.1057, -0.0390, -0.0409, -0.1117]],\n",
      "\n",
      "         [[-0.0661,  0.0288, -0.0152, -0.0838,  0.0027],\n",
      "          [-0.0789, -0.0980, -0.0636, -0.1011, -0.0735],\n",
      "          [ 0.1154,  0.0218,  0.0356, -0.1077, -0.0758],\n",
      "          [-0.0384,  0.0181, -0.1016, -0.0498, -0.0691],\n",
      "          [ 0.0003, -0.0430, -0.0080, -0.0782, -0.0793]],\n",
      "\n",
      "         [[-0.0674, -0.0395, -0.0911,  0.0968, -0.0229],\n",
      "          [ 0.0994,  0.0360, -0.0978,  0.0799, -0.0318],\n",
      "          [-0.0443, -0.0958, -0.1148,  0.0330, -0.0252],\n",
      "          [ 0.0450, -0.0948,  0.0857, -0.0848, -0.0199],\n",
      "          [ 0.0241,  0.0596,  0.0932,  0.1052, -0.0916]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0291, -0.0497, -0.0127, -0.0864,  0.1052],\n",
      "          [-0.0847,  0.0617,  0.0406,  0.0375, -0.0624],\n",
      "          [ 0.1050,  0.0254,  0.0149, -0.1018,  0.0485],\n",
      "          [-0.0173, -0.0529,  0.0992,  0.0257, -0.0639],\n",
      "          [-0.0584, -0.0055,  0.0645, -0.0295, -0.0659]],\n",
      "\n",
      "         [[-0.0395, -0.0863,  0.0412,  0.0894, -0.1087],\n",
      "          [ 0.0268,  0.0597,  0.0209, -0.0411,  0.0603],\n",
      "          [ 0.0607,  0.0432, -0.0203, -0.0306,  0.0124],\n",
      "          [-0.0204, -0.0344,  0.0738,  0.0992, -0.0114],\n",
      "          [-0.0259,  0.0017, -0.0069,  0.0278,  0.0324]],\n",
      "\n",
      "         [[-0.1049, -0.0426,  0.0972,  0.0450, -0.0057],\n",
      "          [-0.0696, -0.0706, -0.1034, -0.0376,  0.0390],\n",
      "          [ 0.0736,  0.0533, -0.1021, -0.0694, -0.0182],\n",
      "          [ 0.1117,  0.0167, -0.0299,  0.0478, -0.0440],\n",
      "          [-0.0747,  0.0843, -0.0525, -0.0231, -0.1149]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0466,  0.0552,  0.0315, -0.0444,  0.0703],\n",
      "          [-0.0371, -0.0038, -0.0440, -0.1095,  0.0186],\n",
      "          [ 0.0334, -0.0581,  0.0708, -0.1036, -0.1113],\n",
      "          [-0.0713, -0.0399, -0.0128, -0.0223,  0.0527],\n",
      "          [-0.1013,  0.0170,  0.0020,  0.0305,  0.1148]],\n",
      "\n",
      "         [[ 0.0711, -0.0639, -0.0946, -0.0280, -0.0579],\n",
      "          [ 0.0403,  0.0011,  0.0929,  0.0454, -0.0212],\n",
      "          [ 0.0040,  0.0277, -0.0143,  0.0932, -0.0903],\n",
      "          [ 0.0563, -0.0736, -0.1012, -0.0237,  0.0563],\n",
      "          [ 0.0816,  0.0290, -0.0100, -0.0065, -0.0468]],\n",
      "\n",
      "         [[-0.0104, -0.0080,  0.0983,  0.0676, -0.0924],\n",
      "          [ 0.0005, -0.0710, -0.0183, -0.0918,  0.0300],\n",
      "          [-0.0833,  0.1140,  0.0872, -0.0795, -0.1087],\n",
      "          [ 0.0045, -0.0322,  0.0339, -0.0782,  0.0473],\n",
      "          [-0.0997, -0.0609, -0.0607,  0.0559, -0.0030]]],\n",
      "\n",
      "\n",
      "        [[[-0.1110, -0.0659, -0.0534, -0.1071,  0.0148],\n",
      "          [ 0.0411, -0.0212, -0.0460, -0.0007, -0.0917],\n",
      "          [-0.0703, -0.0026,  0.1026, -0.0355,  0.0572],\n",
      "          [-0.0454, -0.0307, -0.1099,  0.0957,  0.1124],\n",
      "          [-0.0024,  0.0734,  0.0944,  0.0574,  0.0595]],\n",
      "\n",
      "         [[-0.1099, -0.1085, -0.0886,  0.0361, -0.0999],\n",
      "          [-0.0881, -0.0560, -0.1064,  0.0002,  0.0167],\n",
      "          [-0.0676,  0.0756, -0.0438, -0.0325,  0.0880],\n",
      "          [ 0.0991, -0.0132, -0.0829, -0.0579,  0.0147],\n",
      "          [ 0.0677,  0.0575, -0.0510, -0.1092, -0.1011]],\n",
      "\n",
      "         [[-0.0367,  0.0014, -0.0519, -0.0913,  0.0122],\n",
      "          [-0.0917, -0.0887, -0.0939, -0.0313,  0.1020],\n",
      "          [ 0.0451, -0.0137,  0.0238,  0.0460,  0.0007],\n",
      "          [-0.0931, -0.0711, -0.0784, -0.0029, -0.1057],\n",
      "          [-0.0210, -0.0422,  0.1133,  0.0939,  0.0671]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0065, -0.0374,  0.0295, -0.0798, -0.0492],\n",
      "          [-0.0232, -0.0271, -0.1094,  0.0459,  0.0951],\n",
      "          [-0.0637,  0.0311, -0.0134, -0.0042,  0.0067],\n",
      "          [ 0.1001,  0.0155, -0.0731, -0.0415,  0.0564],\n",
      "          [ 0.0360,  0.0022, -0.0152, -0.0449, -0.0410]],\n",
      "\n",
      "         [[-0.0609,  0.0189,  0.0324,  0.0884, -0.0261],\n",
      "          [ 0.0083,  0.0746,  0.0502,  0.0148,  0.0355],\n",
      "          [ 0.0060, -0.0990,  0.0045, -0.0252,  0.1042],\n",
      "          [ 0.1042,  0.0229,  0.1032, -0.0595,  0.1004],\n",
      "          [ 0.0994, -0.0044, -0.0927, -0.0373, -0.0309]],\n",
      "\n",
      "         [[ 0.0019, -0.1047,  0.0214, -0.0480, -0.0296],\n",
      "          [-0.0596, -0.0244, -0.1072, -0.0612,  0.0106],\n",
      "          [ 0.0757,  0.1049, -0.0873,  0.0485, -0.0651],\n",
      "          [-0.0893, -0.0051, -0.0662, -0.0994, -0.1079],\n",
      "          [-0.0773,  0.0949,  0.0644, -0.0457, -0.0773]]]])\n",
      "Layer: conv1.bias, Biases: tensor([-0.0888, -0.0682, -0.0475,  0.0694,  0.0378, -0.0445,  0.0795, -0.0717,\n",
      "        -0.0941,  0.0252, -0.0637,  0.0328,  0.0978, -0.0546, -0.0806,  0.0435,\n",
      "        -0.1043,  0.1030, -0.0545,  0.0558, -0.0918, -0.0782,  0.0127,  0.0410,\n",
      "         0.0895,  0.0966, -0.0066, -0.0148,  0.0191, -0.0268,  0.0039, -0.1094])\n",
      "Layer: bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer1.0.conv1.weight:, Weights: tensor([[[[ 4.0396e-02,  1.9030e-03,  5.5321e-02],\n",
      "          [-3.0056e-02, -1.9334e-02,  2.5461e-03],\n",
      "          [ 3.1428e-02, -5.1658e-02, -1.6494e-02]],\n",
      "\n",
      "         [[ 4.2794e-02,  1.2270e-02,  4.1659e-02],\n",
      "          [-1.9960e-02, -3.7146e-02, -4.0229e-02],\n",
      "          [-3.3130e-02, -4.4283e-02,  2.9202e-02]],\n",
      "\n",
      "         [[ 1.5838e-02, -3.7702e-02,  5.4011e-02],\n",
      "          [ 1.6776e-02,  2.1930e-02, -2.4828e-02],\n",
      "          [ 4.0796e-02, -4.1565e-02,  4.2952e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.6201e-03,  2.0233e-02,  4.9797e-02],\n",
      "          [-1.8516e-02,  4.3335e-02, -4.9558e-02],\n",
      "          [ 5.3958e-02, -1.9328e-02, -2.2178e-03]],\n",
      "\n",
      "         [[ 3.3057e-02,  4.3261e-03,  5.1525e-02],\n",
      "          [-2.5899e-02, -3.2478e-02,  5.2603e-02],\n",
      "          [-3.5567e-02,  4.0552e-02,  5.6752e-02]],\n",
      "\n",
      "         [[ 3.9889e-02, -2.2278e-02, -8.7106e-04],\n",
      "          [-5.3104e-02, -3.2086e-02, -1.2196e-02],\n",
      "          [-3.8932e-02,  3.3995e-02,  3.0877e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6862e-02, -9.2672e-03,  5.6920e-02],\n",
      "          [-3.6295e-03,  5.0049e-02,  5.4583e-02],\n",
      "          [-2.0670e-02, -5.6279e-02,  5.4964e-02]],\n",
      "\n",
      "         [[-3.1681e-02,  5.6349e-02, -3.7618e-02],\n",
      "          [ 1.0687e-02,  1.7422e-02, -1.3919e-02],\n",
      "          [ 4.5951e-02, -5.3426e-02, -2.4486e-02]],\n",
      "\n",
      "         [[-9.2757e-03,  4.5130e-02,  2.7291e-02],\n",
      "          [ 3.7904e-02,  2.5364e-02,  5.2999e-02],\n",
      "          [-1.4675e-02, -1.8191e-02, -8.0916e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1304e-02, -1.9915e-02,  5.6101e-02],\n",
      "          [-3.3085e-02, -2.6917e-02,  4.6966e-02],\n",
      "          [-1.5184e-02, -2.3799e-02,  9.1177e-03]],\n",
      "\n",
      "         [[-9.9570e-03,  3.7123e-02,  4.8109e-02],\n",
      "          [ 2.6211e-02,  1.2744e-02,  1.4803e-02],\n",
      "          [ 1.5342e-03,  6.9200e-03,  1.1189e-03]],\n",
      "\n",
      "         [[ 4.0181e-02,  3.2952e-02, -5.9246e-03],\n",
      "          [ 2.2252e-02,  3.2589e-03,  2.0823e-02],\n",
      "          [ 4.8378e-02, -4.0091e-02,  8.3739e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.2259e-02, -5.7607e-02, -5.7259e-02],\n",
      "          [-7.7156e-03,  4.2174e-02, -3.8855e-02],\n",
      "          [ 1.9194e-02,  3.3962e-02, -4.2950e-02]],\n",
      "\n",
      "         [[ 2.5306e-02,  1.1121e-02, -5.3647e-02],\n",
      "          [-1.1329e-03, -5.5320e-02,  5.1519e-02],\n",
      "          [ 2.7617e-02,  2.2578e-02,  4.5239e-02]],\n",
      "\n",
      "         [[ 4.5064e-02,  5.8498e-02,  2.4312e-02],\n",
      "          [-4.2543e-02,  5.4732e-02,  1.6369e-02],\n",
      "          [-2.3228e-02, -2.1930e-02,  5.5139e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.3371e-02, -1.7240e-02, -2.7241e-02],\n",
      "          [ 4.7728e-03,  7.4558e-03,  3.6341e-02],\n",
      "          [ 2.0935e-02,  1.8362e-02,  1.9345e-02]],\n",
      "\n",
      "         [[ 4.3872e-02,  3.5094e-02, -5.7960e-03],\n",
      "          [-4.1117e-02,  3.9733e-02, -4.8041e-03],\n",
      "          [-4.2215e-02, -9.8202e-03,  4.3357e-02]],\n",
      "\n",
      "         [[-2.7086e-02, -5.6818e-03,  1.9879e-02],\n",
      "          [ 4.2372e-02, -8.8191e-03, -4.2326e-02],\n",
      "          [-2.4633e-02, -1.9021e-02,  6.4282e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.5695e-02,  3.1834e-02, -3.1570e-02],\n",
      "          [ 1.2213e-02, -2.1140e-02,  2.3091e-02],\n",
      "          [-3.6131e-02, -3.0838e-02, -3.9144e-02]],\n",
      "\n",
      "         [[-1.0452e-02,  5.8511e-02,  3.3879e-02],\n",
      "          [-4.6758e-02,  3.0087e-02,  5.3974e-02],\n",
      "          [ 5.8315e-02,  5.8693e-03,  1.5729e-02]],\n",
      "\n",
      "         [[ 4.2767e-02,  5.6703e-02,  2.0134e-03],\n",
      "          [-1.0421e-02,  4.7830e-02, -1.5831e-02],\n",
      "          [ 4.6964e-02,  4.9863e-02,  1.6421e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2945e-02,  1.6956e-02,  3.2904e-02],\n",
      "          [ 2.5632e-02,  7.3855e-05, -4.3861e-02],\n",
      "          [ 1.4782e-02, -2.0248e-02,  2.2562e-02]],\n",
      "\n",
      "         [[-3.8342e-02, -4.0051e-03, -2.3162e-02],\n",
      "          [-5.4512e-02, -5.4476e-02,  5.4366e-02],\n",
      "          [-6.4105e-05, -5.0796e-02,  9.6623e-03]],\n",
      "\n",
      "         [[-3.6981e-03,  4.8544e-02,  5.5535e-02],\n",
      "          [-1.5146e-02, -3.5358e-02, -3.3769e-02],\n",
      "          [-1.5668e-02, -3.2346e-02,  5.3112e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2523e-02,  3.0359e-02,  2.6667e-02],\n",
      "          [ 1.3777e-02,  2.8726e-02,  4.9898e-02],\n",
      "          [ 2.5072e-02,  2.5929e-02, -4.9442e-02]],\n",
      "\n",
      "         [[-5.2221e-03,  1.3606e-03,  4.6148e-02],\n",
      "          [ 2.5179e-02,  4.5826e-02,  4.5578e-02],\n",
      "          [-2.7486e-02,  8.3596e-03,  5.6187e-02]],\n",
      "\n",
      "         [[ 2.0832e-02,  3.3317e-02,  2.3952e-02],\n",
      "          [-1.8497e-02,  1.4071e-02, -4.0715e-02],\n",
      "          [ 5.4362e-02,  3.3715e-03,  4.5663e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8064e-02, -1.9697e-03, -5.8903e-02],\n",
      "          [ 1.0885e-02, -3.3231e-02,  5.3147e-02],\n",
      "          [-1.5866e-02, -1.6037e-02, -8.7517e-03]],\n",
      "\n",
      "         [[ 5.4616e-02,  2.5840e-02, -4.0636e-02],\n",
      "          [ 1.0326e-02,  1.8736e-02, -1.5305e-02],\n",
      "          [ 1.9562e-02, -5.2893e-02, -3.0376e-02]],\n",
      "\n",
      "         [[ 3.7644e-02,  5.4743e-02,  1.8718e-02],\n",
      "          [-3.3384e-02,  2.1475e-02, -3.3940e-02],\n",
      "          [-4.7215e-02, -3.8881e-02, -5.5849e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2513e-02,  4.3874e-03,  5.6634e-02],\n",
      "          [-4.1810e-03,  5.4207e-02, -4.3793e-02],\n",
      "          [-3.0335e-02,  8.0790e-03,  3.5120e-02]],\n",
      "\n",
      "         [[ 1.7490e-02,  5.7785e-02, -3.1411e-02],\n",
      "          [ 5.5146e-02,  1.8814e-02,  1.5559e-02],\n",
      "          [-1.5107e-03, -4.2413e-02,  3.1523e-02]],\n",
      "\n",
      "         [[ 1.2781e-02,  4.0620e-02,  4.3364e-02],\n",
      "          [-5.0047e-02,  5.4586e-02, -1.3569e-02],\n",
      "          [-3.9477e-02,  5.1430e-02, -9.3191e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5053e-02,  5.7831e-02, -7.2960e-03],\n",
      "          [ 5.7330e-02,  5.7311e-02, -3.0321e-02],\n",
      "          [ 9.1609e-03,  3.3774e-02, -6.8430e-03]],\n",
      "\n",
      "         [[-3.2276e-02,  1.2565e-02,  2.5968e-02],\n",
      "          [-4.7745e-02, -4.7484e-02, -4.4464e-02],\n",
      "          [-4.5155e-02,  5.1594e-02, -2.6209e-02]],\n",
      "\n",
      "         [[-6.9981e-03, -1.5681e-02, -3.0288e-02],\n",
      "          [ 4.9856e-02, -2.1040e-02,  3.5783e-02],\n",
      "          [-2.7230e-02,  5.7797e-02,  1.4893e-02]]]])\n",
      "Layer: layer1.0.conv1.bias, Biases: tensor([-0.0104,  0.0004,  0.0244, -0.0316, -0.0175, -0.0437, -0.0395,  0.0283,\n",
      "        -0.0049, -0.0294,  0.0027,  0.0336,  0.0541, -0.0345,  0.0241,  0.0056,\n",
      "        -0.0299,  0.0131,  0.0066,  0.0348,  0.0482,  0.0277,  0.0111, -0.0443,\n",
      "        -0.0493,  0.0276, -0.0362,  0.0008,  0.0454,  0.0296, -0.0075,  0.0093])\n",
      "Layer: layer1.0.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer1.0.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer1.0.conv2.weight:, Weights: tensor([[[[ 0.0020,  0.0051,  0.0514],\n",
      "          [-0.0361,  0.0513,  0.0028],\n",
      "          [ 0.0559, -0.0251,  0.0362]],\n",
      "\n",
      "         [[-0.0324, -0.0483,  0.0428],\n",
      "          [ 0.0204,  0.0579,  0.0239],\n",
      "          [-0.0249, -0.0350,  0.0482]],\n",
      "\n",
      "         [[-0.0117, -0.0350, -0.0435],\n",
      "          [-0.0394, -0.0248, -0.0474],\n",
      "          [ 0.0567,  0.0068,  0.0194]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0084,  0.0573,  0.0498],\n",
      "          [-0.0388,  0.0289,  0.0554],\n",
      "          [-0.0104,  0.0209, -0.0529]],\n",
      "\n",
      "         [[ 0.0327, -0.0110,  0.0541],\n",
      "          [ 0.0413, -0.0339, -0.0261],\n",
      "          [-0.0463, -0.0544, -0.0535]],\n",
      "\n",
      "         [[ 0.0285,  0.0391, -0.0374],\n",
      "          [ 0.0412, -0.0185,  0.0176],\n",
      "          [ 0.0494,  0.0457, -0.0470]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0232, -0.0296, -0.0506],\n",
      "          [-0.0026, -0.0132,  0.0124],\n",
      "          [ 0.0066,  0.0341,  0.0304]],\n",
      "\n",
      "         [[-0.0528, -0.0515, -0.0372],\n",
      "          [ 0.0303,  0.0544, -0.0345],\n",
      "          [ 0.0110,  0.0033,  0.0220]],\n",
      "\n",
      "         [[ 0.0228,  0.0092,  0.0392],\n",
      "          [-0.0196,  0.0563, -0.0017],\n",
      "          [-0.0534,  0.0287,  0.0415]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0153, -0.0555,  0.0170],\n",
      "          [ 0.0421,  0.0331,  0.0507],\n",
      "          [-0.0311,  0.0337,  0.0404]],\n",
      "\n",
      "         [[ 0.0437, -0.0302,  0.0438],\n",
      "          [-0.0511, -0.0316,  0.0308],\n",
      "          [ 0.0466,  0.0389, -0.0154]],\n",
      "\n",
      "         [[-0.0442,  0.0363, -0.0294],\n",
      "          [ 0.0410, -0.0006,  0.0237],\n",
      "          [ 0.0106, -0.0078, -0.0251]]],\n",
      "\n",
      "\n",
      "        [[[-0.0125, -0.0156, -0.0484],\n",
      "          [ 0.0200,  0.0233, -0.0588],\n",
      "          [-0.0282, -0.0468, -0.0005]],\n",
      "\n",
      "         [[-0.0329,  0.0469, -0.0449],\n",
      "          [-0.0198,  0.0520,  0.0023],\n",
      "          [ 0.0472, -0.0280,  0.0510]],\n",
      "\n",
      "         [[-0.0399, -0.0234, -0.0519],\n",
      "          [ 0.0558,  0.0225, -0.0192],\n",
      "          [ 0.0067, -0.0015, -0.0429]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0428, -0.0267,  0.0580],\n",
      "          [-0.0520, -0.0180,  0.0184],\n",
      "          [ 0.0236, -0.0188, -0.0462]],\n",
      "\n",
      "         [[ 0.0498, -0.0452,  0.0561],\n",
      "          [ 0.0044, -0.0337,  0.0083],\n",
      "          [-0.0020, -0.0490,  0.0511]],\n",
      "\n",
      "         [[-0.0344, -0.0105, -0.0316],\n",
      "          [ 0.0130, -0.0395,  0.0505],\n",
      "          [-0.0156,  0.0550,  0.0003]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0503,  0.0025, -0.0088],\n",
      "          [-0.0407,  0.0511,  0.0103],\n",
      "          [-0.0016, -0.0158,  0.0507]],\n",
      "\n",
      "         [[ 0.0394,  0.0564,  0.0501],\n",
      "          [-0.0487, -0.0524, -0.0372],\n",
      "          [-0.0494, -0.0132, -0.0184]],\n",
      "\n",
      "         [[-0.0173,  0.0219, -0.0150],\n",
      "          [ 0.0350,  0.0178,  0.0499],\n",
      "          [ 0.0352, -0.0228, -0.0239]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0008,  0.0206, -0.0402],\n",
      "          [ 0.0264, -0.0530, -0.0436],\n",
      "          [-0.0335, -0.0071,  0.0588]],\n",
      "\n",
      "         [[ 0.0586, -0.0564,  0.0021],\n",
      "          [ 0.0335, -0.0062, -0.0205],\n",
      "          [ 0.0127,  0.0583, -0.0322]],\n",
      "\n",
      "         [[ 0.0061,  0.0050, -0.0305],\n",
      "          [-0.0346, -0.0071,  0.0474],\n",
      "          [ 0.0106, -0.0462,  0.0368]]],\n",
      "\n",
      "\n",
      "        [[[-0.0097, -0.0196,  0.0552],\n",
      "          [-0.0492, -0.0334, -0.0293],\n",
      "          [ 0.0059,  0.0266, -0.0519]],\n",
      "\n",
      "         [[ 0.0072,  0.0209, -0.0101],\n",
      "          [-0.0501,  0.0444,  0.0076],\n",
      "          [ 0.0031,  0.0363,  0.0542]],\n",
      "\n",
      "         [[ 0.0215, -0.0218, -0.0056],\n",
      "          [-0.0212,  0.0325,  0.0441],\n",
      "          [ 0.0361,  0.0495,  0.0402]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0426, -0.0074,  0.0056],\n",
      "          [ 0.0034, -0.0368, -0.0574],\n",
      "          [ 0.0195,  0.0200,  0.0564]],\n",
      "\n",
      "         [[-0.0303, -0.0455, -0.0342],\n",
      "          [-0.0050,  0.0098, -0.0531],\n",
      "          [ 0.0471,  0.0219,  0.0493]],\n",
      "\n",
      "         [[ 0.0237,  0.0462, -0.0096],\n",
      "          [ 0.0048,  0.0194, -0.0015],\n",
      "          [ 0.0319,  0.0373,  0.0074]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0095,  0.0101, -0.0551],\n",
      "          [ 0.0423, -0.0268,  0.0071],\n",
      "          [-0.0195, -0.0465, -0.0582]],\n",
      "\n",
      "         [[ 0.0352,  0.0528, -0.0481],\n",
      "          [-0.0133, -0.0120, -0.0542],\n",
      "          [-0.0546,  0.0093,  0.0171]],\n",
      "\n",
      "         [[ 0.0299,  0.0449, -0.0035],\n",
      "          [-0.0056,  0.0291, -0.0111],\n",
      "          [-0.0221, -0.0179,  0.0302]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0429, -0.0235, -0.0437],\n",
      "          [-0.0307,  0.0129, -0.0045],\n",
      "          [ 0.0396,  0.0348,  0.0491]],\n",
      "\n",
      "         [[-0.0084, -0.0455, -0.0230],\n",
      "          [ 0.0484, -0.0533,  0.0498],\n",
      "          [ 0.0394, -0.0248, -0.0045]],\n",
      "\n",
      "         [[-0.0311,  0.0461, -0.0069],\n",
      "          [ 0.0102, -0.0131,  0.0445],\n",
      "          [-0.0018,  0.0425,  0.0171]]]])\n",
      "Layer: layer1.0.conv2.bias, Biases: tensor([ 0.0003,  0.0360,  0.0039,  0.0038, -0.0229, -0.0346, -0.0261, -0.0554,\n",
      "         0.0455,  0.0403, -0.0260,  0.0424, -0.0528, -0.0532,  0.0495,  0.0045,\n",
      "         0.0012, -0.0119,  0.0548,  0.0125, -0.0047,  0.0546,  0.0012, -0.0564,\n",
      "         0.0257,  0.0258, -0.0349,  0.0102,  0.0017, -0.0090, -0.0088,  0.0339,\n",
      "         0.0097, -0.0544,  0.0578,  0.0248, -0.0505,  0.0459, -0.0418, -0.0132,\n",
      "        -0.0189, -0.0199,  0.0094,  0.0103,  0.0189,  0.0081, -0.0486,  0.0081,\n",
      "        -0.0026, -0.0145, -0.0509, -0.0544,  0.0407, -0.0303,  0.0325,  0.0402,\n",
      "         0.0207, -0.0205, -0.0286,  0.0492,  0.0461,  0.0347,  0.0510, -0.0469])\n",
      "Layer: layer1.0.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer1.0.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer1.0.identity_downsample.0.weight:, Weights: tensor([[[[-0.1451]],\n",
      "\n",
      "         [[ 0.1211]],\n",
      "\n",
      "         [[-0.1033]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0169]],\n",
      "\n",
      "         [[ 0.1302]],\n",
      "\n",
      "         [[ 0.1535]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0194]],\n",
      "\n",
      "         [[-0.0736]],\n",
      "\n",
      "         [[ 0.1663]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0682]],\n",
      "\n",
      "         [[-0.0613]],\n",
      "\n",
      "         [[-0.0247]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0838]],\n",
      "\n",
      "         [[ 0.0647]],\n",
      "\n",
      "         [[ 0.1282]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1746]],\n",
      "\n",
      "         [[ 0.0129]],\n",
      "\n",
      "         [[-0.0733]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0734]],\n",
      "\n",
      "         [[-0.1597]],\n",
      "\n",
      "         [[-0.0096]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0453]],\n",
      "\n",
      "         [[ 0.0833]],\n",
      "\n",
      "         [[-0.1173]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1088]],\n",
      "\n",
      "         [[-0.1659]],\n",
      "\n",
      "         [[-0.1212]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0322]],\n",
      "\n",
      "         [[ 0.1502]],\n",
      "\n",
      "         [[ 0.1088]]],\n",
      "\n",
      "\n",
      "        [[[-0.1148]],\n",
      "\n",
      "         [[-0.1076]],\n",
      "\n",
      "         [[-0.1752]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1708]],\n",
      "\n",
      "         [[-0.0655]],\n",
      "\n",
      "         [[ 0.0237]]]])\n",
      "Layer: layer1.0.identity_downsample.0.bias, Biases: tensor([-0.0311, -0.1646,  0.1328,  0.1311, -0.1066,  0.0180,  0.1174, -0.1679,\n",
      "        -0.1562,  0.0981, -0.0035,  0.0563, -0.0735,  0.0321,  0.1172, -0.0432,\n",
      "        -0.0571, -0.1683, -0.0273,  0.1120, -0.1671, -0.0137,  0.1289, -0.0505,\n",
      "        -0.0653, -0.0533, -0.0716,  0.0212, -0.1702,  0.0676, -0.0446, -0.0225,\n",
      "        -0.0119,  0.0988, -0.1098, -0.1609, -0.1279, -0.1297, -0.0861,  0.1396,\n",
      "        -0.1368, -0.1039, -0.1441, -0.0888, -0.0050, -0.1078,  0.0019,  0.0597,\n",
      "        -0.0301,  0.0763,  0.0406,  0.1708, -0.0090,  0.1532,  0.1323,  0.0845,\n",
      "         0.1000, -0.1184, -0.1184,  0.0755,  0.0642,  0.1595, -0.0230, -0.0325])\n",
      "Layer: layer1.0.identity_downsample.1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer1.0.identity_downsample.1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer1.1.conv1.weight:, Weights: tensor([[[[ 3.9692e-03, -3.5500e-02,  1.0553e-02],\n",
      "          [ 1.3919e-03, -3.8714e-02, -1.0266e-02],\n",
      "          [-2.6512e-03, -5.5816e-03,  2.4644e-02]],\n",
      "\n",
      "         [[-3.3953e-02, -2.6974e-02, -9.8869e-03],\n",
      "          [ 2.6080e-02, -3.4597e-02,  2.5882e-02],\n",
      "          [ 1.6272e-02,  2.7195e-02, -1.9584e-02]],\n",
      "\n",
      "         [[-2.8045e-02,  1.3003e-02,  1.1129e-02],\n",
      "          [ 3.3623e-02,  4.0362e-03,  1.9510e-02],\n",
      "          [-1.1591e-02, -7.9078e-03, -2.5049e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0478e-02, -1.5366e-02,  4.8746e-03],\n",
      "          [ 5.8253e-04, -3.1524e-02,  4.1350e-02],\n",
      "          [ 2.8452e-02,  2.0401e-02, -3.4399e-02]],\n",
      "\n",
      "         [[ 3.9074e-02,  3.9399e-02, -1.9123e-03],\n",
      "          [-4.4322e-03,  3.4901e-02, -3.4402e-02],\n",
      "          [ 3.9688e-02, -1.0565e-02, -1.8902e-02]],\n",
      "\n",
      "         [[ 2.0078e-03,  1.2251e-02,  4.1924e-03],\n",
      "          [ 2.6819e-02, -3.3452e-02, -2.8991e-03],\n",
      "          [-2.8941e-03, -2.8713e-02, -3.1885e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5174e-02, -1.4391e-02,  3.2181e-03],\n",
      "          [-1.7959e-02,  3.8239e-02,  1.5129e-02],\n",
      "          [-2.0376e-02, -5.4884e-03, -3.5850e-02]],\n",
      "\n",
      "         [[ 1.9121e-02, -2.0874e-02,  3.2313e-02],\n",
      "          [ 2.2568e-02, -1.4787e-02,  4.8981e-03],\n",
      "          [-6.6139e-03, -3.4788e-02, -2.8846e-02]],\n",
      "\n",
      "         [[-2.2224e-02,  3.9703e-02, -2.9214e-02],\n",
      "          [ 1.8705e-02, -1.6683e-02,  1.4396e-02],\n",
      "          [ 2.9694e-02,  2.8352e-02, -3.5431e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6922e-02, -2.1370e-02,  3.1303e-02],\n",
      "          [-3.1396e-02,  7.4406e-03, -2.5140e-02],\n",
      "          [-3.6634e-02,  2.4759e-02,  3.1901e-02]],\n",
      "\n",
      "         [[-3.6710e-02, -2.7335e-02, -1.8692e-02],\n",
      "          [-3.4080e-02,  2.8885e-03,  3.4782e-02],\n",
      "          [ 1.2316e-02, -2.0094e-02, -1.4192e-02]],\n",
      "\n",
      "         [[ 5.9790e-03, -2.6108e-02, -3.6259e-02],\n",
      "          [ 1.0062e-03,  6.7195e-04, -2.4824e-02],\n",
      "          [-2.7398e-02,  3.9637e-02,  4.8781e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.0951e-03, -1.8056e-02,  2.4873e-02],\n",
      "          [ 4.3215e-03,  3.1922e-02, -9.8132e-03],\n",
      "          [-2.4452e-02,  2.7589e-02, -1.6425e-02]],\n",
      "\n",
      "         [[ 3.5258e-02, -6.3068e-04,  6.0803e-03],\n",
      "          [-2.1733e-02, -4.0713e-02, -2.3346e-02],\n",
      "          [ 1.4600e-02, -3.4830e-02, -6.7888e-03]],\n",
      "\n",
      "         [[-2.6517e-03,  7.9925e-03, -4.1332e-02],\n",
      "          [-1.1192e-02, -3.1470e-03,  5.0490e-03],\n",
      "          [-1.1639e-02,  4.0370e-02, -6.7748e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2800e-03, -2.7242e-02,  1.7896e-02],\n",
      "          [-2.2464e-02, -2.6448e-02, -1.9594e-02],\n",
      "          [-3.4007e-02, -3.3984e-02, -4.5332e-03]],\n",
      "\n",
      "         [[-4.0893e-02,  3.0472e-02, -3.2116e-02],\n",
      "          [ 1.5337e-02,  1.7230e-02, -1.6488e-02],\n",
      "          [ 8.5983e-03,  3.9056e-02, -3.9164e-02]],\n",
      "\n",
      "         [[ 8.0135e-04,  2.7982e-02,  3.9009e-02],\n",
      "          [ 1.1515e-02,  3.6631e-02, -2.2268e-02],\n",
      "          [ 3.7838e-02,  6.0574e-03, -2.6760e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.9328e-02, -4.1282e-02, -3.3312e-02],\n",
      "          [-3.9293e-03,  2.8724e-02, -2.3066e-02],\n",
      "          [-1.7960e-02, -2.4176e-02,  2.1752e-02]],\n",
      "\n",
      "         [[ 3.0680e-02,  2.7347e-03,  2.2395e-02],\n",
      "          [ 3.8378e-02, -5.7892e-03, -1.7680e-02],\n",
      "          [-2.3822e-02,  2.9930e-02,  2.5211e-02]],\n",
      "\n",
      "         [[-2.7993e-02,  2.3801e-02,  1.8861e-02],\n",
      "          [ 1.9229e-02,  1.4367e-02, -6.3834e-03],\n",
      "          [ 1.9023e-02, -2.6450e-02, -4.7563e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6383e-02,  2.8450e-02,  1.8835e-03],\n",
      "          [-4.1347e-02, -7.9833e-03,  7.2630e-03],\n",
      "          [ 1.2182e-02, -9.1189e-03, -1.5474e-02]],\n",
      "\n",
      "         [[ 2.1410e-02, -2.9369e-02, -3.4685e-03],\n",
      "          [ 2.4973e-03,  3.6579e-02, -3.5097e-02],\n",
      "          [-1.8109e-02,  2.8707e-02,  2.4108e-02]],\n",
      "\n",
      "         [[-3.2650e-02, -2.2576e-02, -2.4820e-02],\n",
      "          [ 2.1351e-02,  3.2036e-02, -4.1144e-03],\n",
      "          [-7.6043e-03, -3.2879e-02,  1.2024e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4075e-02, -2.4116e-02,  1.0881e-02],\n",
      "          [ 1.2131e-02, -2.4269e-02, -1.8343e-02],\n",
      "          [-2.0884e-02, -2.1574e-02, -3.7269e-02]],\n",
      "\n",
      "         [[-2.5927e-02,  8.4433e-03,  1.2043e-02],\n",
      "          [-1.0393e-02,  2.3815e-03,  3.9315e-02],\n",
      "          [ 2.2199e-02, -1.6253e-02,  3.8563e-02]],\n",
      "\n",
      "         [[-7.7548e-03,  1.2891e-02, -7.5451e-03],\n",
      "          [ 2.6352e-02,  4.3531e-03, -4.6209e-03],\n",
      "          [ 2.2693e-02,  1.9086e-02,  2.3433e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6578e-02,  3.0303e-02,  1.8323e-02],\n",
      "          [-2.8471e-02, -9.1166e-03,  3.8636e-02],\n",
      "          [-3.0304e-02,  3.1211e-02,  1.1481e-02]],\n",
      "\n",
      "         [[ 3.8115e-02, -3.1445e-02,  3.8422e-02],\n",
      "          [ 9.5602e-03, -1.3793e-02,  1.5124e-03],\n",
      "          [-1.2546e-03,  1.4378e-02, -3.7479e-02]],\n",
      "\n",
      "         [[-8.5480e-03, -3.3755e-02,  3.9378e-02],\n",
      "          [-3.3292e-02, -3.1013e-02,  3.7920e-02],\n",
      "          [ 3.2425e-02, -3.7433e-03, -7.2325e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.1136e-02,  2.0662e-03,  3.2954e-02],\n",
      "          [ 3.8221e-02,  3.2591e-02, -1.9723e-02],\n",
      "          [-3.6354e-03, -2.2733e-02, -1.4256e-02]],\n",
      "\n",
      "         [[ 3.6986e-02, -2.1011e-02,  3.5608e-03],\n",
      "          [ 4.0688e-02,  3.6245e-02, -2.5776e-02],\n",
      "          [-1.2418e-02, -2.9308e-02, -3.0637e-02]],\n",
      "\n",
      "         [[ 3.4138e-02, -5.1218e-04, -3.7936e-02],\n",
      "          [ 2.8925e-02, -2.6731e-02, -3.3962e-02],\n",
      "          [-2.2420e-02, -8.7394e-03, -1.7843e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8503e-03, -3.7830e-03,  3.6578e-02],\n",
      "          [ 1.3623e-02, -3.1210e-02, -2.9402e-02],\n",
      "          [ 9.8786e-03,  2.5480e-02, -3.8446e-02]],\n",
      "\n",
      "         [[ 1.5279e-02, -1.8596e-02,  1.5777e-02],\n",
      "          [-2.1703e-02,  3.5037e-02,  3.8981e-02],\n",
      "          [-2.9041e-02, -3.6852e-02,  1.2029e-02]],\n",
      "\n",
      "         [[ 3.3245e-02,  1.8279e-02, -2.0314e-02],\n",
      "          [ 3.5362e-02, -4.1239e-02,  3.4754e-02],\n",
      "          [-1.5011e-02, -2.8811e-03, -7.4118e-05]]]])\n",
      "Layer: layer1.1.conv1.bias, Biases: tensor([-0.0115, -0.0095,  0.0103,  0.0080,  0.0048,  0.0409, -0.0041, -0.0258,\n",
      "        -0.0365,  0.0316, -0.0301,  0.0210, -0.0243, -0.0278,  0.0066,  0.0317,\n",
      "        -0.0375,  0.0274, -0.0415, -0.0084, -0.0118, -0.0296, -0.0323, -0.0174,\n",
      "        -0.0334,  0.0004, -0.0279, -0.0194, -0.0208,  0.0123, -0.0120,  0.0242])\n",
      "Layer: layer1.1.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer1.1.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer1.1.conv2.weight:, Weights: tensor([[[[ 0.0359, -0.0433, -0.0100],\n",
      "          [-0.0587,  0.0282, -0.0128],\n",
      "          [ 0.0152,  0.0194,  0.0522]],\n",
      "\n",
      "         [[-0.0059, -0.0174,  0.0556],\n",
      "          [-0.0046,  0.0108,  0.0058],\n",
      "          [-0.0311,  0.0340, -0.0487]],\n",
      "\n",
      "         [[ 0.0295,  0.0287,  0.0385],\n",
      "          [-0.0416,  0.0414,  0.0544],\n",
      "          [-0.0010, -0.0558, -0.0028]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0182, -0.0313,  0.0584],\n",
      "          [ 0.0293,  0.0450,  0.0095],\n",
      "          [-0.0014, -0.0386,  0.0236]],\n",
      "\n",
      "         [[-0.0186, -0.0061,  0.0032],\n",
      "          [ 0.0444,  0.0219, -0.0579],\n",
      "          [ 0.0009,  0.0428, -0.0035]],\n",
      "\n",
      "         [[ 0.0495, -0.0252, -0.0432],\n",
      "          [ 0.0535, -0.0210,  0.0436],\n",
      "          [ 0.0444, -0.0390, -0.0529]]],\n",
      "\n",
      "\n",
      "        [[[-0.0070, -0.0329,  0.0431],\n",
      "          [ 0.0290,  0.0500, -0.0268],\n",
      "          [ 0.0113,  0.0014, -0.0432]],\n",
      "\n",
      "         [[-0.0288,  0.0272,  0.0047],\n",
      "          [ 0.0522,  0.0046,  0.0173],\n",
      "          [ 0.0210, -0.0396, -0.0442]],\n",
      "\n",
      "         [[-0.0372, -0.0211,  0.0187],\n",
      "          [-0.0316, -0.0469, -0.0173],\n",
      "          [-0.0501, -0.0049, -0.0555]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0553,  0.0524,  0.0210],\n",
      "          [ 0.0405, -0.0301,  0.0493],\n",
      "          [ 0.0212,  0.0284,  0.0512]],\n",
      "\n",
      "         [[-0.0510,  0.0217,  0.0102],\n",
      "          [ 0.0443,  0.0129, -0.0054],\n",
      "          [ 0.0442,  0.0325,  0.0153]],\n",
      "\n",
      "         [[-0.0196,  0.0408, -0.0262],\n",
      "          [ 0.0011,  0.0572,  0.0268],\n",
      "          [ 0.0096,  0.0587, -0.0169]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0385, -0.0227,  0.0428],\n",
      "          [ 0.0326, -0.0120, -0.0535],\n",
      "          [ 0.0432, -0.0585,  0.0026]],\n",
      "\n",
      "         [[-0.0037, -0.0491,  0.0039],\n",
      "          [-0.0428, -0.0190,  0.0566],\n",
      "          [ 0.0072,  0.0228, -0.0336]],\n",
      "\n",
      "         [[ 0.0261,  0.0533, -0.0015],\n",
      "          [-0.0272,  0.0270,  0.0223],\n",
      "          [-0.0569, -0.0271, -0.0122]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0342,  0.0478, -0.0157],\n",
      "          [ 0.0333,  0.0193, -0.0216],\n",
      "          [-0.0425, -0.0120,  0.0481]],\n",
      "\n",
      "         [[ 0.0303,  0.0460, -0.0383],\n",
      "          [-0.0550, -0.0139, -0.0560],\n",
      "          [ 0.0382, -0.0121, -0.0359]],\n",
      "\n",
      "         [[-0.0051, -0.0148,  0.0007],\n",
      "          [ 0.0309, -0.0372,  0.0227],\n",
      "          [ 0.0022,  0.0349,  0.0063]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0277,  0.0018, -0.0205],\n",
      "          [-0.0553, -0.0306, -0.0407],\n",
      "          [ 0.0018, -0.0398,  0.0105]],\n",
      "\n",
      "         [[-0.0554, -0.0275, -0.0470],\n",
      "          [ 0.0207, -0.0312,  0.0563],\n",
      "          [-0.0055, -0.0322, -0.0090]],\n",
      "\n",
      "         [[ 0.0525, -0.0511, -0.0269],\n",
      "          [ 0.0507, -0.0031, -0.0135],\n",
      "          [ 0.0158,  0.0293, -0.0243]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0251, -0.0404,  0.0024],\n",
      "          [ 0.0008,  0.0150,  0.0005],\n",
      "          [-0.0285, -0.0282,  0.0027]],\n",
      "\n",
      "         [[-0.0168, -0.0100, -0.0162],\n",
      "          [-0.0167,  0.0532,  0.0083],\n",
      "          [ 0.0450,  0.0335,  0.0467]],\n",
      "\n",
      "         [[-0.0078, -0.0492, -0.0329],\n",
      "          [-0.0066,  0.0143, -0.0145],\n",
      "          [-0.0541, -0.0325,  0.0486]]],\n",
      "\n",
      "\n",
      "        [[[-0.0346, -0.0387,  0.0400],\n",
      "          [-0.0281, -0.0029,  0.0541],\n",
      "          [ 0.0515,  0.0504, -0.0397]],\n",
      "\n",
      "         [[ 0.0056, -0.0022,  0.0011],\n",
      "          [ 0.0567,  0.0335, -0.0513],\n",
      "          [ 0.0580,  0.0548, -0.0454]],\n",
      "\n",
      "         [[-0.0489,  0.0472, -0.0188],\n",
      "          [-0.0468,  0.0246,  0.0044],\n",
      "          [ 0.0356, -0.0414,  0.0538]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0428,  0.0566,  0.0195],\n",
      "          [-0.0067,  0.0561, -0.0180],\n",
      "          [ 0.0399,  0.0414, -0.0354]],\n",
      "\n",
      "         [[-0.0244, -0.0470,  0.0243],\n",
      "          [ 0.0149,  0.0280,  0.0051],\n",
      "          [ 0.0026,  0.0460, -0.0286]],\n",
      "\n",
      "         [[ 0.0417, -0.0271,  0.0538],\n",
      "          [-0.0211, -0.0166, -0.0422],\n",
      "          [ 0.0053, -0.0012, -0.0412]]],\n",
      "\n",
      "\n",
      "        [[[-0.0373,  0.0053, -0.0174],\n",
      "          [ 0.0209,  0.0211, -0.0145],\n",
      "          [-0.0368, -0.0190,  0.0387]],\n",
      "\n",
      "         [[ 0.0126, -0.0071, -0.0029],\n",
      "          [ 0.0484,  0.0228,  0.0574],\n",
      "          [-0.0530,  0.0063, -0.0295]],\n",
      "\n",
      "         [[ 0.0316,  0.0247,  0.0543],\n",
      "          [ 0.0454,  0.0241, -0.0072],\n",
      "          [ 0.0526,  0.0020, -0.0211]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0224, -0.0243, -0.0580],\n",
      "          [-0.0519,  0.0172,  0.0031],\n",
      "          [-0.0148,  0.0264,  0.0198]],\n",
      "\n",
      "         [[-0.0507, -0.0071,  0.0051],\n",
      "          [-0.0128,  0.0463, -0.0381],\n",
      "          [ 0.0270,  0.0315, -0.0455]],\n",
      "\n",
      "         [[-0.0484,  0.0316, -0.0286],\n",
      "          [ 0.0431,  0.0037, -0.0057],\n",
      "          [ 0.0492, -0.0143,  0.0046]]]])\n",
      "Layer: layer1.1.conv2.bias, Biases: tensor([-0.0401, -0.0034,  0.0532,  0.0534, -0.0256, -0.0251,  0.0523,  0.0514,\n",
      "        -0.0099, -0.0067, -0.0408, -0.0516,  0.0037, -0.0458,  0.0250,  0.0461,\n",
      "        -0.0241, -0.0369, -0.0550, -0.0049, -0.0250,  0.0586,  0.0296,  0.0461,\n",
      "         0.0509,  0.0039, -0.0346, -0.0110, -0.0479, -0.0326, -0.0530,  0.0205,\n",
      "        -0.0455,  0.0006,  0.0435, -0.0080,  0.0450,  0.0096, -0.0161,  0.0170,\n",
      "         0.0527,  0.0286, -0.0502, -0.0141, -0.0148, -0.0274, -0.0039, -0.0540,\n",
      "         0.0445, -0.0385,  0.0286,  0.0161,  0.0174, -0.0457, -0.0416, -0.0471,\n",
      "         0.0333,  0.0391,  0.0126,  0.0218,  0.0256,  0.0210, -0.0333,  0.0152])\n",
      "Layer: layer1.1.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer1.1.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer1.2.conv1.weight:, Weights: tensor([[[[-0.0094,  0.0190,  0.0314],\n",
      "          [ 0.0120, -0.0100,  0.0312],\n",
      "          [ 0.0327, -0.0049,  0.0322]],\n",
      "\n",
      "         [[-0.0254,  0.0215, -0.0008],\n",
      "          [-0.0026, -0.0119,  0.0397],\n",
      "          [-0.0082, -0.0299, -0.0178]],\n",
      "\n",
      "         [[-0.0153,  0.0265,  0.0348],\n",
      "          [ 0.0119, -0.0057, -0.0002],\n",
      "          [-0.0028, -0.0413, -0.0131]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0306,  0.0380,  0.0030],\n",
      "          [-0.0414, -0.0113,  0.0060],\n",
      "          [ 0.0149,  0.0366, -0.0395]],\n",
      "\n",
      "         [[-0.0124,  0.0268,  0.0227],\n",
      "          [-0.0153,  0.0118,  0.0270],\n",
      "          [-0.0003, -0.0041,  0.0045]],\n",
      "\n",
      "         [[-0.0174, -0.0414,  0.0208],\n",
      "          [ 0.0123, -0.0287,  0.0069],\n",
      "          [-0.0137,  0.0367, -0.0205]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0372,  0.0174,  0.0048],\n",
      "          [ 0.0115,  0.0062,  0.0229],\n",
      "          [-0.0190, -0.0115, -0.0199]],\n",
      "\n",
      "         [[ 0.0079, -0.0224,  0.0221],\n",
      "          [-0.0082,  0.0406,  0.0157],\n",
      "          [-0.0389,  0.0065,  0.0162]],\n",
      "\n",
      "         [[-0.0270,  0.0061,  0.0146],\n",
      "          [-0.0395, -0.0368, -0.0021],\n",
      "          [ 0.0154, -0.0227, -0.0223]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0121,  0.0118,  0.0034],\n",
      "          [ 0.0192, -0.0329,  0.0024],\n",
      "          [-0.0167,  0.0231,  0.0007]],\n",
      "\n",
      "         [[ 0.0106,  0.0310, -0.0111],\n",
      "          [-0.0373,  0.0011,  0.0342],\n",
      "          [ 0.0365, -0.0175, -0.0080]],\n",
      "\n",
      "         [[-0.0225,  0.0388,  0.0113],\n",
      "          [-0.0176, -0.0222, -0.0367],\n",
      "          [ 0.0245, -0.0147, -0.0374]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0071, -0.0154,  0.0308],\n",
      "          [-0.0226,  0.0397,  0.0160],\n",
      "          [-0.0025,  0.0074, -0.0372]],\n",
      "\n",
      "         [[ 0.0245,  0.0214,  0.0243],\n",
      "          [ 0.0009, -0.0208,  0.0054],\n",
      "          [ 0.0115, -0.0306,  0.0159]],\n",
      "\n",
      "         [[ 0.0395,  0.0404,  0.0138],\n",
      "          [ 0.0378, -0.0212, -0.0012],\n",
      "          [-0.0234, -0.0186, -0.0104]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0370, -0.0245,  0.0330],\n",
      "          [ 0.0146,  0.0274,  0.0349],\n",
      "          [-0.0377, -0.0121, -0.0265]],\n",
      "\n",
      "         [[-0.0198,  0.0377,  0.0215],\n",
      "          [-0.0223,  0.0188, -0.0223],\n",
      "          [-0.0364, -0.0047,  0.0186]],\n",
      "\n",
      "         [[ 0.0188, -0.0191,  0.0415],\n",
      "          [ 0.0320,  0.0217,  0.0375],\n",
      "          [-0.0058, -0.0296, -0.0102]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0257, -0.0116,  0.0145],\n",
      "          [-0.0247, -0.0118, -0.0242],\n",
      "          [ 0.0138,  0.0241,  0.0334]],\n",
      "\n",
      "         [[-0.0085,  0.0270, -0.0222],\n",
      "          [-0.0158,  0.0196, -0.0151],\n",
      "          [ 0.0092, -0.0304,  0.0180]],\n",
      "\n",
      "         [[-0.0389,  0.0322, -0.0005],\n",
      "          [ 0.0171,  0.0184,  0.0123],\n",
      "          [ 0.0128,  0.0068, -0.0284]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0039, -0.0306,  0.0405],\n",
      "          [ 0.0306,  0.0368,  0.0171],\n",
      "          [-0.0216,  0.0221, -0.0267]],\n",
      "\n",
      "         [[ 0.0206,  0.0232, -0.0189],\n",
      "          [-0.0023,  0.0067,  0.0301],\n",
      "          [ 0.0046,  0.0311, -0.0329]],\n",
      "\n",
      "         [[ 0.0170, -0.0164,  0.0199],\n",
      "          [ 0.0276,  0.0228,  0.0342],\n",
      "          [-0.0205,  0.0246, -0.0363]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0054,  0.0025,  0.0353],\n",
      "          [ 0.0210, -0.0274,  0.0412],\n",
      "          [ 0.0364, -0.0112,  0.0402]],\n",
      "\n",
      "         [[ 0.0331, -0.0273, -0.0210],\n",
      "          [ 0.0245, -0.0006,  0.0256],\n",
      "          [-0.0148, -0.0100, -0.0336]],\n",
      "\n",
      "         [[ 0.0269, -0.0119,  0.0345],\n",
      "          [-0.0092,  0.0161,  0.0284],\n",
      "          [ 0.0323,  0.0148, -0.0095]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0407, -0.0053, -0.0142],\n",
      "          [-0.0256,  0.0005, -0.0090],\n",
      "          [-0.0320,  0.0078,  0.0188]],\n",
      "\n",
      "         [[-0.0407,  0.0138,  0.0385],\n",
      "          [-0.0105, -0.0194, -0.0341],\n",
      "          [-0.0368,  0.0373, -0.0313]],\n",
      "\n",
      "         [[-0.0082,  0.0168, -0.0394],\n",
      "          [ 0.0031, -0.0232,  0.0061],\n",
      "          [ 0.0390,  0.0279,  0.0234]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0224, -0.0309, -0.0205],\n",
      "          [-0.0326, -0.0221,  0.0050],\n",
      "          [ 0.0005, -0.0367,  0.0107]],\n",
      "\n",
      "         [[-0.0264,  0.0122,  0.0173],\n",
      "          [ 0.0267, -0.0384,  0.0125],\n",
      "          [-0.0067,  0.0190,  0.0005]],\n",
      "\n",
      "         [[-0.0330,  0.0144,  0.0151],\n",
      "          [ 0.0304,  0.0086, -0.0011],\n",
      "          [-0.0231, -0.0153,  0.0192]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0392, -0.0362, -0.0311],\n",
      "          [ 0.0320, -0.0042,  0.0060],\n",
      "          [ 0.0389,  0.0002,  0.0243]],\n",
      "\n",
      "         [[-0.0168,  0.0413,  0.0074],\n",
      "          [-0.0121, -0.0109,  0.0360],\n",
      "          [ 0.0354, -0.0355, -0.0173]],\n",
      "\n",
      "         [[ 0.0340, -0.0114, -0.0415],\n",
      "          [-0.0092, -0.0005, -0.0202],\n",
      "          [ 0.0011,  0.0219, -0.0352]]]])\n",
      "Layer: layer1.2.conv1.bias, Biases: tensor([-0.0013, -0.0345,  0.0155,  0.0178, -0.0305,  0.0035, -0.0315, -0.0067,\n",
      "         0.0344, -0.0134,  0.0260,  0.0314,  0.0038,  0.0205,  0.0125,  0.0140,\n",
      "        -0.0186,  0.0066, -0.0185, -0.0094,  0.0102, -0.0104,  0.0263,  0.0220,\n",
      "         0.0324,  0.0208,  0.0215, -0.0148,  0.0365, -0.0273, -0.0171, -0.0183])\n",
      "Layer: layer1.2.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer1.2.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer1.2.conv2.weight:, Weights: tensor([[[[ 1.2272e-02,  3.4874e-02, -5.1870e-02],\n",
      "          [ 4.7153e-02,  6.4152e-03,  5.1035e-02],\n",
      "          [ 2.7738e-02, -3.9153e-02,  1.5627e-02]],\n",
      "\n",
      "         [[ 2.5941e-02, -4.4843e-02,  2.9224e-02],\n",
      "          [-5.0457e-02,  1.6378e-02, -2.4157e-02],\n",
      "          [-4.0384e-02, -1.7317e-02, -3.2696e-02]],\n",
      "\n",
      "         [[ 9.5775e-03,  2.0149e-02,  1.5921e-02],\n",
      "          [ 3.6438e-02, -4.7272e-02, -4.7044e-02],\n",
      "          [-5.8884e-02,  1.9648e-02, -5.7103e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6058e-02, -4.3877e-02,  4.6578e-02],\n",
      "          [ 1.8633e-02,  4.6567e-02,  6.6561e-03],\n",
      "          [-1.5810e-02, -1.4927e-02,  2.9165e-02]],\n",
      "\n",
      "         [[-2.7348e-02,  3.5028e-02, -3.7575e-02],\n",
      "          [-2.8291e-02,  3.4407e-02,  1.5137e-02],\n",
      "          [-7.2415e-04, -2.0539e-02,  5.2163e-02]],\n",
      "\n",
      "         [[-4.0052e-02, -3.1100e-03, -7.0191e-03],\n",
      "          [-1.9917e-02, -2.6509e-02, -1.7930e-02],\n",
      "          [ 8.4760e-03, -1.9511e-02, -6.2496e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.0961e-02,  1.4434e-02, -3.2431e-02],\n",
      "          [-2.8083e-02, -2.3262e-02, -3.0966e-04],\n",
      "          [-5.2345e-02, -4.3756e-02, -3.3921e-02]],\n",
      "\n",
      "         [[ 9.7596e-03, -7.0280e-03, -3.2804e-02],\n",
      "          [ 1.0637e-02, -4.6339e-02, -3.4939e-02],\n",
      "          [ 4.9171e-02,  4.0712e-02, -7.7134e-03]],\n",
      "\n",
      "         [[-5.5038e-02, -5.5623e-02, -1.0109e-02],\n",
      "          [ 5.3229e-02,  2.7287e-02,  3.7795e-02],\n",
      "          [-1.9477e-03, -2.1793e-03,  2.5014e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5344e-02, -5.0479e-02, -5.3579e-02],\n",
      "          [-4.9628e-02, -1.3075e-02, -1.5982e-02],\n",
      "          [-2.6671e-02,  1.3259e-02, -8.5665e-03]],\n",
      "\n",
      "         [[-4.3178e-02, -8.4307e-03, -5.6104e-02],\n",
      "          [-5.0118e-02, -2.9389e-02,  4.8423e-02],\n",
      "          [-3.4792e-02, -8.2730e-03,  5.3839e-03]],\n",
      "\n",
      "         [[-3.9738e-02, -2.4834e-02,  2.3661e-02],\n",
      "          [-3.8056e-02, -3.1427e-02,  3.9190e-02],\n",
      "          [ 1.9177e-02, -4.8309e-02, -2.1810e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3650e-02, -3.1355e-02, -3.0371e-02],\n",
      "          [ 1.3561e-02,  5.7819e-02, -2.3744e-02],\n",
      "          [ 3.9532e-02, -5.0540e-02, -6.6174e-03]],\n",
      "\n",
      "         [[-3.0514e-02,  4.1118e-02,  5.7582e-02],\n",
      "          [-2.7041e-03,  1.8739e-02, -2.7649e-02],\n",
      "          [ 3.5092e-02, -2.6415e-02,  4.1518e-02]],\n",
      "\n",
      "         [[-3.3665e-02, -4.2964e-02,  1.1146e-02],\n",
      "          [ 1.5959e-03,  3.1634e-02,  1.8352e-02],\n",
      "          [ 3.8699e-02, -4.8259e-02, -1.2352e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0543e-02,  2.9020e-02,  5.0813e-02],\n",
      "          [-3.4621e-02, -1.2793e-02, -4.5650e-02],\n",
      "          [ 2.5685e-02,  2.7987e-02,  4.3612e-02]],\n",
      "\n",
      "         [[ 3.6577e-02, -5.3430e-03,  1.3114e-02],\n",
      "          [-4.0274e-02,  3.4100e-02, -4.4839e-02],\n",
      "          [-2.3751e-02, -5.5646e-02, -2.5116e-02]],\n",
      "\n",
      "         [[ 3.0629e-02,  3.2823e-02,  5.5241e-02],\n",
      "          [-2.6295e-02,  4.2468e-02,  5.3641e-02],\n",
      "          [ 3.3781e-02,  5.1131e-02, -9.4367e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2160e-02, -3.3929e-03,  3.8583e-02],\n",
      "          [-2.8615e-02, -4.6180e-02,  4.9333e-02],\n",
      "          [-2.9601e-02, -4.8211e-03, -3.5853e-02]],\n",
      "\n",
      "         [[ 2.9898e-02,  2.0841e-02, -4.7770e-02],\n",
      "          [-5.1011e-02, -2.1104e-02, -4.1420e-02],\n",
      "          [-5.0391e-02,  5.0924e-02,  4.1283e-02]],\n",
      "\n",
      "         [[ 4.2561e-02,  2.3776e-03,  4.1470e-02],\n",
      "          [ 2.3360e-02,  4.2307e-02, -7.5126e-03],\n",
      "          [ 2.0214e-02, -5.5708e-03,  5.4825e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0210e-02,  2.5323e-02,  4.3694e-02],\n",
      "          [ 2.4432e-02,  5.3322e-02, -3.2692e-02],\n",
      "          [-1.3889e-02,  3.2639e-02,  5.6131e-02]],\n",
      "\n",
      "         [[ 2.9282e-02,  3.7814e-02, -5.1943e-03],\n",
      "          [-4.1603e-02,  4.5929e-02,  1.7845e-02],\n",
      "          [-1.3584e-02, -3.6661e-02, -2.4559e-02]],\n",
      "\n",
      "         [[-3.5704e-02,  5.8342e-02,  2.2486e-03],\n",
      "          [ 4.4527e-02, -1.2858e-02, -7.0554e-03],\n",
      "          [-2.5083e-02, -4.4721e-02,  3.3804e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0843e-02,  3.6965e-02, -2.5882e-02],\n",
      "          [-7.3869e-03, -1.6715e-04, -2.4026e-02],\n",
      "          [-2.9421e-02,  4.9525e-02,  3.6140e-02]],\n",
      "\n",
      "         [[-3.3240e-03,  1.5056e-02, -5.5512e-02],\n",
      "          [-5.7405e-02,  8.0788e-04, -1.2701e-02],\n",
      "          [-2.3977e-02,  1.1449e-03, -4.9663e-02]],\n",
      "\n",
      "         [[ 2.3728e-02,  8.8342e-03,  2.2064e-02],\n",
      "          [ 4.1059e-02,  1.9307e-02, -3.6974e-02],\n",
      "          [-4.9641e-03,  2.6016e-02,  4.5108e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3755e-02,  3.9544e-02,  3.4936e-02],\n",
      "          [-1.3075e-02,  1.7242e-02,  5.7477e-02],\n",
      "          [-1.1707e-02, -3.7637e-02,  5.1229e-02]],\n",
      "\n",
      "         [[ 2.9725e-02,  5.6449e-02, -2.2018e-02],\n",
      "          [ 1.3742e-02, -3.7043e-02, -4.5296e-02],\n",
      "          [-1.0165e-02, -3.7782e-02,  5.2082e-02]],\n",
      "\n",
      "         [[ 1.3196e-02, -1.7798e-02,  5.0015e-02],\n",
      "          [ 2.7461e-04, -1.1779e-02,  2.3725e-02],\n",
      "          [ 3.0922e-02, -5.2928e-02, -5.2981e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6592e-02, -3.9939e-02, -3.1746e-02],\n",
      "          [ 3.8140e-02, -5.5298e-02, -2.9551e-02],\n",
      "          [-1.1738e-02,  2.1758e-03,  5.4184e-03]],\n",
      "\n",
      "         [[ 3.0936e-02,  3.2380e-02, -2.6437e-02],\n",
      "          [-3.5305e-02, -3.9020e-02,  1.9441e-02],\n",
      "          [ 2.3514e-02, -1.5993e-02, -4.3869e-02]],\n",
      "\n",
      "         [[ 4.9651e-02,  1.1670e-02, -3.1314e-02],\n",
      "          [ 4.6676e-02,  5.5042e-02, -2.7810e-03],\n",
      "          [-5.3717e-02, -3.8365e-02,  3.6020e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6092e-02, -4.2412e-02, -2.0808e-03],\n",
      "          [ 5.4058e-02,  2.4447e-02, -8.1877e-05],\n",
      "          [ 3.4102e-02, -5.5268e-02,  3.1293e-02]],\n",
      "\n",
      "         [[ 1.6599e-02, -2.9076e-02, -2.2518e-02],\n",
      "          [ 2.7337e-02,  2.9538e-02,  3.4812e-03],\n",
      "          [ 1.6210e-02, -4.7325e-02,  4.2182e-02]],\n",
      "\n",
      "         [[-5.7979e-02, -3.3638e-02,  2.7403e-02],\n",
      "          [ 3.8009e-05, -4.0988e-02, -1.8252e-02],\n",
      "          [-4.6646e-02,  6.2563e-04, -2.0155e-02]]]])\n",
      "Layer: layer1.2.conv2.bias, Biases: tensor([ 0.0250, -0.0278, -0.0111, -0.0125, -0.0244,  0.0362, -0.0465, -0.0409,\n",
      "        -0.0194,  0.0529,  0.0422,  0.0309,  0.0050,  0.0054, -0.0278, -0.0486,\n",
      "        -0.0124,  0.0408,  0.0322, -0.0462, -0.0064, -0.0010,  0.0102,  0.0486,\n",
      "         0.0071,  0.0523, -0.0059, -0.0079, -0.0532, -0.0287,  0.0165, -0.0081,\n",
      "        -0.0265,  0.0446, -0.0435,  0.0317, -0.0145, -0.0530, -0.0220, -0.0117,\n",
      "         0.0076,  0.0157, -0.0361, -0.0485,  0.0178, -0.0228, -0.0488,  0.0567,\n",
      "        -0.0033,  0.0501, -0.0265,  0.0364,  0.0403,  0.0414, -0.0358,  0.0537,\n",
      "        -0.0487,  0.0217, -0.0407,  0.0090, -0.0396,  0.0533,  0.0362,  0.0303])\n",
      "Layer: layer1.2.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer1.2.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer2.0.conv1.weight:, Weights: tensor([[[[ 3.5633e-02, -1.0360e-02, -1.5363e-02],\n",
      "          [ 3.2958e-03, -2.4325e-03, -2.1780e-02],\n",
      "          [-2.9514e-02, -2.9472e-02,  7.3734e-03]],\n",
      "\n",
      "         [[-8.8013e-03, -2.0233e-02, -1.7091e-02],\n",
      "          [ 2.6558e-02,  1.0528e-02,  2.5287e-02],\n",
      "          [ 1.1885e-02, -2.9994e-02, -2.0345e-02]],\n",
      "\n",
      "         [[ 8.0853e-03, -1.0125e-02, -8.8371e-03],\n",
      "          [ 3.9116e-02,  3.4643e-02, -2.7091e-02],\n",
      "          [-3.0162e-02,  5.9905e-03, -1.0471e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2627e-02,  2.1061e-02,  3.7130e-02],\n",
      "          [-2.0725e-02,  1.1458e-02, -1.6322e-02],\n",
      "          [ 1.5352e-02, -1.2199e-02,  8.8853e-03]],\n",
      "\n",
      "         [[ 3.1504e-02, -1.9977e-02, -3.7374e-02],\n",
      "          [ 9.7647e-03,  5.6741e-03,  2.8505e-02],\n",
      "          [ 3.5945e-02,  1.6612e-02,  5.7518e-04]],\n",
      "\n",
      "         [[ 1.3000e-02, -3.1107e-02, -2.5932e-03],\n",
      "          [-1.0068e-02, -3.4094e-02, -3.6116e-02],\n",
      "          [-3.3188e-02, -3.6411e-02, -1.6814e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6071e-02, -9.7426e-03, -5.4929e-04],\n",
      "          [-3.5351e-02, -4.0385e-02,  2.3328e-02],\n",
      "          [ 1.0214e-02,  2.1280e-02,  1.0266e-02]],\n",
      "\n",
      "         [[-1.7991e-02,  3.6484e-02, -2.5978e-02],\n",
      "          [ 2.7666e-02, -3.4625e-02, -4.1344e-03],\n",
      "          [-3.8854e-02,  1.9245e-02, -2.1864e-02]],\n",
      "\n",
      "         [[ 3.9147e-02, -1.6387e-02,  3.9455e-03],\n",
      "          [-1.5042e-02,  8.0538e-03, -9.7105e-03],\n",
      "          [-1.6784e-02, -3.2919e-02,  2.7042e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9494e-02, -3.8675e-02,  3.3067e-02],\n",
      "          [-3.3576e-02, -8.4800e-03,  3.8935e-02],\n",
      "          [-6.4940e-03, -1.7819e-02, -2.3379e-02]],\n",
      "\n",
      "         [[ 9.3330e-03,  1.6522e-03, -9.0186e-03],\n",
      "          [-2.7161e-02,  3.4655e-02, -1.0163e-02],\n",
      "          [-1.1170e-02,  1.5960e-02, -3.9796e-02]],\n",
      "\n",
      "         [[ 2.1057e-02,  2.5357e-02, -2.0450e-02],\n",
      "          [-1.2065e-02,  3.4166e-02, -3.3565e-02],\n",
      "          [-3.3663e-02,  2.6109e-02, -2.2572e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5411e-02, -8.1578e-03,  8.0188e-04],\n",
      "          [ 3.6527e-02, -8.7108e-03, -3.2316e-02],\n",
      "          [ 2.4139e-02,  3.0513e-02, -3.9822e-02]],\n",
      "\n",
      "         [[ 2.7028e-02, -1.6460e-02, -2.8716e-02],\n",
      "          [ 3.8781e-02, -8.2585e-03, -2.9496e-02],\n",
      "          [-2.7433e-02,  4.2957e-03,  3.4873e-02]],\n",
      "\n",
      "         [[-3.0510e-02, -7.9333e-03,  2.9017e-02],\n",
      "          [ 1.8860e-02,  2.0210e-02,  1.4787e-02],\n",
      "          [ 9.1207e-03,  8.3505e-03, -2.1074e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1500e-02,  3.5383e-02,  3.7779e-02],\n",
      "          [ 2.9293e-02,  3.8551e-02,  7.5079e-03],\n",
      "          [ 3.4846e-02,  1.8116e-02, -4.0373e-02]],\n",
      "\n",
      "         [[ 4.0022e-02,  3.6795e-03,  1.9821e-02],\n",
      "          [ 1.3036e-02,  2.2632e-03,  3.6989e-02],\n",
      "          [ 2.3758e-02, -1.7265e-02, -4.0331e-02]],\n",
      "\n",
      "         [[-1.6902e-02,  2.3480e-02, -2.3973e-02],\n",
      "          [-3.6007e-02, -2.1763e-02,  6.1133e-03],\n",
      "          [-3.3976e-02,  1.3152e-02, -2.8707e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.4064e-02,  1.3606e-02, -1.0891e-02],\n",
      "          [ 1.3725e-03, -5.5760e-03,  7.4079e-03],\n",
      "          [-3.9367e-03,  4.1463e-03, -1.1811e-02]],\n",
      "\n",
      "         [[-4.0634e-02,  1.9755e-02, -3.8467e-02],\n",
      "          [-2.5169e-02, -3.1894e-02,  3.9203e-02],\n",
      "          [-2.7796e-02, -3.5161e-02,  2.2512e-02]],\n",
      "\n",
      "         [[-4.0913e-02, -2.5874e-02,  1.1973e-02],\n",
      "          [-1.4007e-03,  4.3536e-03,  3.9653e-03],\n",
      "          [ 2.3968e-02,  7.8261e-03, -1.2705e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0579e-03,  2.4302e-02, -1.6826e-02],\n",
      "          [ 3.4952e-02, -3.9011e-02,  1.6529e-03],\n",
      "          [ 1.8936e-02, -1.7011e-02,  6.4014e-03]],\n",
      "\n",
      "         [[ 4.9822e-03,  3.8327e-02, -3.4556e-02],\n",
      "          [ 1.7666e-02, -5.8300e-03, -1.6620e-02],\n",
      "          [ 3.0289e-02,  1.2842e-02,  7.3362e-03]],\n",
      "\n",
      "         [[ 2.2080e-03,  1.5416e-02,  1.5370e-02],\n",
      "          [ 3.7080e-02,  8.3682e-03, -2.9643e-02],\n",
      "          [ 1.1812e-05, -1.6874e-02,  3.1243e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2116e-02,  3.1017e-02, -1.4388e-02],\n",
      "          [ 1.1027e-02, -3.5487e-02,  3.4181e-02],\n",
      "          [-2.2387e-02, -3.2337e-02, -1.1932e-02]],\n",
      "\n",
      "         [[ 3.1985e-02, -1.9611e-02,  8.7296e-04],\n",
      "          [ 2.6979e-02, -3.9674e-02,  3.3058e-02],\n",
      "          [ 1.4319e-02, -3.5425e-02,  4.0917e-02]],\n",
      "\n",
      "         [[-3.4874e-02, -4.1524e-02, -8.2928e-03],\n",
      "          [ 3.5665e-02,  3.6232e-02,  1.2487e-02],\n",
      "          [ 8.3867e-04,  3.7844e-02,  4.1401e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0516e-02,  3.9198e-02,  2.8262e-02],\n",
      "          [-4.1304e-02,  4.1204e-02, -4.1438e-02],\n",
      "          [ 7.1515e-03, -3.8981e-02, -3.2049e-02]],\n",
      "\n",
      "         [[ 4.1151e-02, -2.1978e-02, -5.7754e-03],\n",
      "          [-3.7025e-02, -2.7493e-02,  4.0098e-02],\n",
      "          [-2.1104e-02, -3.4893e-02,  2.3889e-02]],\n",
      "\n",
      "         [[ 2.3492e-02, -3.1970e-02, -2.5649e-02],\n",
      "          [-3.7234e-02, -1.2065e-02, -3.7925e-02],\n",
      "          [-1.1801e-02, -1.2640e-02,  1.5519e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0240e-03, -3.4166e-02,  1.5234e-02],\n",
      "          [ 9.9456e-04,  2.1945e-02,  3.2225e-02],\n",
      "          [-3.9046e-02,  2.5304e-02, -1.8314e-02]],\n",
      "\n",
      "         [[ 3.8678e-02,  2.2087e-02, -3.9535e-02],\n",
      "          [ 5.1545e-03, -1.9993e-02,  1.9522e-02],\n",
      "          [-3.3252e-02,  1.8335e-02,  3.4027e-02]],\n",
      "\n",
      "         [[-3.0926e-02,  4.3051e-03,  2.9606e-02],\n",
      "          [ 3.3860e-02, -1.0797e-03,  2.0183e-02],\n",
      "          [-1.0128e-02, -1.1404e-02, -2.4257e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6745e-02, -2.2129e-02, -2.4864e-02],\n",
      "          [ 2.1979e-02, -9.2032e-03,  2.4938e-03],\n",
      "          [-2.9112e-02, -6.1451e-03, -1.8200e-02]],\n",
      "\n",
      "         [[ 6.5093e-03, -1.7559e-02, -3.1513e-02],\n",
      "          [ 4.5311e-03,  1.9810e-02, -2.4703e-02],\n",
      "          [ 3.9318e-02, -2.4086e-02, -4.1701e-03]],\n",
      "\n",
      "         [[ 2.1392e-02, -3.3472e-03,  2.8610e-03],\n",
      "          [ 9.3330e-03,  3.2270e-02, -2.7056e-02],\n",
      "          [ 3.9348e-02,  3.8811e-03,  5.8634e-03]]]])\n",
      "Layer: layer2.0.conv1.bias, Biases: tensor([-0.0034, -0.0404, -0.0037,  0.0352,  0.0229,  0.0268, -0.0169,  0.0333,\n",
      "        -0.0343, -0.0162, -0.0131,  0.0349,  0.0040, -0.0083,  0.0362,  0.0225,\n",
      "         0.0217,  0.0011, -0.0293,  0.0077, -0.0365,  0.0047, -0.0338, -0.0169,\n",
      "        -0.0028, -0.0055, -0.0101,  0.0383, -0.0372, -0.0384,  0.0024, -0.0017,\n",
      "         0.0187,  0.0353, -0.0077, -0.0272,  0.0119,  0.0165,  0.0166,  0.0274,\n",
      "        -0.0217, -0.0414,  0.0337, -0.0270,  0.0103, -0.0298, -0.0238, -0.0288,\n",
      "         0.0042, -0.0345, -0.0395,  0.0233, -0.0012, -0.0193,  0.0128, -0.0194,\n",
      "        -0.0166,  0.0162,  0.0025, -0.0373,  0.0283,  0.0381, -0.0097, -0.0242])\n",
      "Layer: layer2.0.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer2.0.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer2.0.conv2.weight:, Weights: tensor([[[[-0.0223, -0.0133,  0.0057],\n",
      "          [ 0.0051,  0.0143, -0.0336],\n",
      "          [ 0.0231,  0.0275, -0.0153]],\n",
      "\n",
      "         [[-0.0090,  0.0276,  0.0366],\n",
      "          [-0.0392,  0.0273, -0.0183],\n",
      "          [-0.0225,  0.0382,  0.0272]],\n",
      "\n",
      "         [[-0.0038, -0.0362,  0.0043],\n",
      "          [ 0.0269, -0.0273,  0.0019],\n",
      "          [-0.0020, -0.0221, -0.0210]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0189, -0.0301, -0.0112],\n",
      "          [-0.0252,  0.0313,  0.0122],\n",
      "          [-0.0252, -0.0062, -0.0128]],\n",
      "\n",
      "         [[-0.0375,  0.0161,  0.0080],\n",
      "          [-0.0247,  0.0036, -0.0127],\n",
      "          [-0.0161, -0.0413, -0.0039]],\n",
      "\n",
      "         [[ 0.0210,  0.0251,  0.0413],\n",
      "          [-0.0168,  0.0130,  0.0215],\n",
      "          [ 0.0107,  0.0313, -0.0137]]],\n",
      "\n",
      "\n",
      "        [[[-0.0061, -0.0120, -0.0131],\n",
      "          [-0.0282,  0.0095, -0.0071],\n",
      "          [ 0.0243, -0.0117,  0.0414]],\n",
      "\n",
      "         [[ 0.0019,  0.0342,  0.0235],\n",
      "          [ 0.0357,  0.0124,  0.0147],\n",
      "          [-0.0006, -0.0102, -0.0365]],\n",
      "\n",
      "         [[-0.0187,  0.0385,  0.0407],\n",
      "          [-0.0309, -0.0134,  0.0021],\n",
      "          [-0.0022,  0.0381,  0.0011]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0084,  0.0053,  0.0328],\n",
      "          [ 0.0109,  0.0244,  0.0225],\n",
      "          [ 0.0346, -0.0020,  0.0298]],\n",
      "\n",
      "         [[ 0.0261, -0.0355, -0.0375],\n",
      "          [ 0.0384, -0.0181,  0.0224],\n",
      "          [ 0.0358, -0.0271,  0.0118]],\n",
      "\n",
      "         [[-0.0086, -0.0104, -0.0084],\n",
      "          [-0.0194, -0.0013, -0.0018],\n",
      "          [-0.0138,  0.0318,  0.0201]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0389, -0.0301, -0.0104],\n",
      "          [ 0.0354,  0.0286,  0.0262],\n",
      "          [-0.0132, -0.0021, -0.0415]],\n",
      "\n",
      "         [[-0.0193, -0.0001, -0.0167],\n",
      "          [ 0.0385,  0.0058,  0.0224],\n",
      "          [-0.0326,  0.0254,  0.0374]],\n",
      "\n",
      "         [[ 0.0164, -0.0152,  0.0360],\n",
      "          [ 0.0350, -0.0267, -0.0084],\n",
      "          [ 0.0325,  0.0343,  0.0074]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0115,  0.0031, -0.0048],\n",
      "          [-0.0227, -0.0106, -0.0124],\n",
      "          [-0.0125,  0.0027, -0.0140]],\n",
      "\n",
      "         [[-0.0145, -0.0004,  0.0178],\n",
      "          [-0.0290, -0.0409,  0.0386],\n",
      "          [ 0.0150,  0.0182, -0.0160]],\n",
      "\n",
      "         [[-0.0304, -0.0365, -0.0287],\n",
      "          [ 0.0224, -0.0313,  0.0322],\n",
      "          [ 0.0344,  0.0109,  0.0193]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0406,  0.0249, -0.0093],\n",
      "          [ 0.0382, -0.0325,  0.0127],\n",
      "          [-0.0179, -0.0164,  0.0043]],\n",
      "\n",
      "         [[ 0.0358,  0.0409,  0.0017],\n",
      "          [ 0.0295, -0.0276,  0.0307],\n",
      "          [ 0.0239,  0.0291,  0.0038]],\n",
      "\n",
      "         [[-0.0085, -0.0374,  0.0027],\n",
      "          [ 0.0257, -0.0196, -0.0323],\n",
      "          [-0.0321,  0.0257,  0.0197]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0289,  0.0305, -0.0244],\n",
      "          [-0.0044, -0.0197,  0.0325],\n",
      "          [-0.0366,  0.0208,  0.0105]],\n",
      "\n",
      "         [[-0.0264, -0.0069,  0.0038],\n",
      "          [-0.0111, -0.0311,  0.0392],\n",
      "          [-0.0016,  0.0009,  0.0365]],\n",
      "\n",
      "         [[-0.0334, -0.0125, -0.0056],\n",
      "          [ 0.0191, -0.0282, -0.0131],\n",
      "          [-0.0164, -0.0185,  0.0312]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0095, -0.0143,  0.0370],\n",
      "          [ 0.0037,  0.0168,  0.0208],\n",
      "          [-0.0404, -0.0183,  0.0373]],\n",
      "\n",
      "         [[ 0.0145,  0.0227,  0.0115],\n",
      "          [ 0.0255, -0.0413, -0.0304],\n",
      "          [-0.0114, -0.0314,  0.0120]],\n",
      "\n",
      "         [[-0.0137,  0.0226,  0.0271],\n",
      "          [ 0.0208, -0.0368, -0.0065],\n",
      "          [ 0.0024, -0.0047,  0.0186]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0182, -0.0152,  0.0111],\n",
      "          [-0.0344, -0.0143, -0.0339],\n",
      "          [ 0.0257, -0.0323, -0.0094]],\n",
      "\n",
      "         [[-0.0210,  0.0137, -0.0092],\n",
      "          [-0.0369,  0.0368, -0.0081],\n",
      "          [-0.0337,  0.0063,  0.0095]],\n",
      "\n",
      "         [[-0.0173, -0.0364,  0.0352],\n",
      "          [-0.0360, -0.0194, -0.0182],\n",
      "          [-0.0372, -0.0098,  0.0008]]],\n",
      "\n",
      "\n",
      "        [[[-0.0155, -0.0269, -0.0062],\n",
      "          [ 0.0405, -0.0382, -0.0330],\n",
      "          [ 0.0210,  0.0330,  0.0377]],\n",
      "\n",
      "         [[ 0.0082,  0.0221,  0.0238],\n",
      "          [ 0.0104,  0.0323,  0.0159],\n",
      "          [ 0.0297, -0.0183,  0.0033]],\n",
      "\n",
      "         [[ 0.0214, -0.0093, -0.0346],\n",
      "          [-0.0084, -0.0373, -0.0165],\n",
      "          [-0.0021,  0.0287,  0.0229]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0226, -0.0169,  0.0155],\n",
      "          [-0.0342,  0.0045,  0.0109],\n",
      "          [ 0.0286, -0.0386, -0.0266]],\n",
      "\n",
      "         [[-0.0242,  0.0303,  0.0378],\n",
      "          [ 0.0277,  0.0208, -0.0049],\n",
      "          [ 0.0123, -0.0300, -0.0334]],\n",
      "\n",
      "         [[ 0.0076,  0.0267,  0.0330],\n",
      "          [-0.0135, -0.0175,  0.0084],\n",
      "          [-0.0234, -0.0068, -0.0221]]]])\n",
      "Layer: layer2.0.conv2.bias, Biases: tensor([ 0.0386, -0.0131,  0.0376,  0.0207,  0.0337, -0.0322, -0.0382, -0.0191,\n",
      "        -0.0130,  0.0205,  0.0399,  0.0206, -0.0254,  0.0269, -0.0048, -0.0282,\n",
      "         0.0152, -0.0370,  0.0276, -0.0109,  0.0384, -0.0248,  0.0176, -0.0357,\n",
      "        -0.0109,  0.0076,  0.0148, -0.0119,  0.0281,  0.0004,  0.0196,  0.0347,\n",
      "        -0.0382, -0.0358,  0.0014,  0.0336, -0.0208,  0.0238, -0.0255,  0.0068,\n",
      "        -0.0014, -0.0003, -0.0380,  0.0117, -0.0049, -0.0106,  0.0111, -0.0207,\n",
      "        -0.0072, -0.0036,  0.0319,  0.0169,  0.0148,  0.0306, -0.0402,  0.0091,\n",
      "         0.0174, -0.0108,  0.0002,  0.0089,  0.0091, -0.0357, -0.0197,  0.0023,\n",
      "        -0.0152,  0.0042,  0.0169,  0.0142, -0.0071, -0.0339, -0.0397, -0.0279,\n",
      "        -0.0237,  0.0082,  0.0139, -0.0211, -0.0280, -0.0109,  0.0340, -0.0021,\n",
      "         0.0006,  0.0304,  0.0109,  0.0283, -0.0308, -0.0247, -0.0298,  0.0034,\n",
      "         0.0215,  0.0377, -0.0271,  0.0260, -0.0364, -0.0357,  0.0096, -0.0013,\n",
      "         0.0307,  0.0284,  0.0353,  0.0105,  0.0117,  0.0191, -0.0030, -0.0366,\n",
      "        -0.0272, -0.0308,  0.0213, -0.0150, -0.0239, -0.0098, -0.0322,  0.0222,\n",
      "         0.0256,  0.0405,  0.0203, -0.0330,  0.0284, -0.0098,  0.0408,  0.0261,\n",
      "         0.0266, -0.0119, -0.0347,  0.0231,  0.0232,  0.0139, -0.0145,  0.0414])\n",
      "Layer: layer2.0.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Layer: layer2.0.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer2.0.identity_downsample.0.weight:, Weights: tensor([[[[ 0.0272]],\n",
      "\n",
      "         [[-0.0392]],\n",
      "\n",
      "         [[-0.0123]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0284]],\n",
      "\n",
      "         [[ 0.0990]],\n",
      "\n",
      "         [[ 0.1152]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0147]],\n",
      "\n",
      "         [[-0.0343]],\n",
      "\n",
      "         [[ 0.0555]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0476]],\n",
      "\n",
      "         [[ 0.0233]],\n",
      "\n",
      "         [[ 0.0340]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0192]],\n",
      "\n",
      "         [[ 0.0561]],\n",
      "\n",
      "         [[ 0.0631]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1227]],\n",
      "\n",
      "         [[ 0.1132]],\n",
      "\n",
      "         [[ 0.0770]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0117]],\n",
      "\n",
      "         [[-0.0455]],\n",
      "\n",
      "         [[ 0.0943]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0119]],\n",
      "\n",
      "         [[-0.0230]],\n",
      "\n",
      "         [[-0.0897]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0799]],\n",
      "\n",
      "         [[-0.0639]],\n",
      "\n",
      "         [[ 0.0063]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0888]],\n",
      "\n",
      "         [[-0.0332]],\n",
      "\n",
      "         [[ 0.0840]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1117]],\n",
      "\n",
      "         [[-0.0534]],\n",
      "\n",
      "         [[-0.0916]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0450]],\n",
      "\n",
      "         [[ 0.0608]],\n",
      "\n",
      "         [[-0.0697]]]])\n",
      "Layer: layer2.0.identity_downsample.0.bias, Biases: tensor([-0.0686, -0.1200,  0.0198,  0.1117, -0.0387,  0.0836, -0.0094,  0.0361,\n",
      "        -0.0765, -0.0683,  0.0023,  0.0395, -0.0158, -0.0102,  0.1124,  0.0982,\n",
      "         0.0057,  0.0041, -0.0634, -0.1208,  0.0431, -0.0441, -0.0230, -0.0669,\n",
      "        -0.0111,  0.0422, -0.0804, -0.1246, -0.0552, -0.0310,  0.0510, -0.0776,\n",
      "        -0.0279,  0.1201, -0.0533,  0.0498,  0.1199,  0.0194, -0.1222, -0.0146,\n",
      "         0.0884,  0.0094, -0.0205,  0.0875,  0.0283,  0.0117,  0.1110,  0.0782,\n",
      "         0.0007,  0.0111, -0.0318,  0.0778,  0.1036, -0.1249, -0.0992, -0.0349,\n",
      "         0.0611, -0.0811,  0.0420,  0.0298,  0.0598,  0.0632,  0.0163,  0.0013,\n",
      "        -0.0082,  0.0273,  0.0207, -0.0666,  0.0840,  0.0963,  0.0896,  0.0232,\n",
      "         0.0696, -0.1173,  0.0207, -0.0457, -0.0528,  0.1135, -0.0085, -0.1243,\n",
      "        -0.0483, -0.0136,  0.0841,  0.0020,  0.0873, -0.0750, -0.0509, -0.0908,\n",
      "         0.0293,  0.0516, -0.0475, -0.0055,  0.0733, -0.1121,  0.1023, -0.0991,\n",
      "        -0.0450,  0.0724, -0.0961, -0.0325, -0.0725, -0.0066,  0.1163,  0.1181,\n",
      "        -0.0107,  0.0903, -0.0911, -0.0378,  0.1213,  0.0598, -0.0754,  0.0193,\n",
      "         0.0276, -0.1104, -0.0006,  0.1213, -0.0859,  0.0031, -0.0999, -0.0425,\n",
      "        -0.0583,  0.0039, -0.0522,  0.0040, -0.0451,  0.1009,  0.0695, -0.0402])\n",
      "Layer: layer2.0.identity_downsample.1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Layer: layer2.0.identity_downsample.1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer2.1.conv1.weight:, Weights: tensor([[[[ 1.2304e-03,  1.8619e-02,  2.5854e-02],\n",
      "          [ 1.4899e-03, -2.1450e-02,  2.9388e-02],\n",
      "          [-2.5849e-02,  2.6164e-02,  2.8294e-02]],\n",
      "\n",
      "         [[-1.9996e-02,  1.9482e-02, -1.2608e-02],\n",
      "          [-7.9763e-03, -6.9524e-03,  1.8559e-02],\n",
      "          [-2.1169e-02, -8.4300e-04,  9.4009e-03]],\n",
      "\n",
      "         [[-9.9554e-03, -1.4240e-02, -1.9654e-02],\n",
      "          [-2.0108e-02,  2.2623e-02, -1.4926e-02],\n",
      "          [ 1.3536e-02,  2.5995e-02,  2.8125e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.1922e-03,  2.3043e-02,  4.4668e-03],\n",
      "          [ 1.6052e-02, -3.5710e-03,  2.3882e-02],\n",
      "          [-3.0194e-03,  2.5404e-02,  3.1047e-03]],\n",
      "\n",
      "         [[ 1.0558e-02, -1.1485e-02,  1.3224e-02],\n",
      "          [-2.6039e-02,  1.7838e-02, -6.1439e-04],\n",
      "          [-5.8824e-04,  2.0739e-02,  6.7031e-03]],\n",
      "\n",
      "         [[-5.5475e-03, -2.7271e-02, -4.3559e-03],\n",
      "          [ 4.6917e-03,  3.3151e-03, -6.8218e-03],\n",
      "          [-2.7766e-02,  2.6764e-02, -1.8404e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8627e-02,  2.5610e-02, -2.7858e-02],\n",
      "          [-1.4434e-02,  8.9050e-03, -9.8769e-04],\n",
      "          [ 1.4006e-02, -2.2161e-02, -2.4505e-02]],\n",
      "\n",
      "         [[ 5.9284e-03, -2.4136e-02,  5.2568e-03],\n",
      "          [ 3.8971e-03, -5.5934e-03, -3.7674e-03],\n",
      "          [-1.0896e-02,  4.6821e-03,  3.7247e-04]],\n",
      "\n",
      "         [[ 2.5413e-02,  2.9380e-02, -4.9612e-03],\n",
      "          [ 8.5512e-03,  2.5288e-02, -2.3711e-02],\n",
      "          [-2.9186e-02, -2.4142e-03,  2.3401e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6205e-02, -2.3767e-02,  1.1505e-02],\n",
      "          [-3.9120e-03, -2.4136e-02,  1.5305e-02],\n",
      "          [-2.2498e-02, -3.0930e-03, -5.1543e-03]],\n",
      "\n",
      "         [[-1.1159e-02, -1.7454e-02, -2.8882e-02],\n",
      "          [-1.5153e-02, -2.2923e-04,  2.1838e-03],\n",
      "          [-9.5280e-03, -1.1347e-02, -9.5191e-03]],\n",
      "\n",
      "         [[ 1.3078e-02,  1.0098e-02,  1.8107e-02],\n",
      "          [-1.5991e-02,  1.4182e-02, -1.1496e-02],\n",
      "          [ 1.1973e-02,  1.3684e-02, -2.2797e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5895e-02,  2.1153e-02,  2.1255e-02],\n",
      "          [-1.6992e-02, -2.5254e-03, -1.7348e-02],\n",
      "          [-1.8646e-02, -7.1372e-03, -2.1884e-02]],\n",
      "\n",
      "         [[-1.1981e-02,  6.0466e-04,  9.0151e-03],\n",
      "          [ 2.0909e-02, -8.3581e-05,  5.1050e-03],\n",
      "          [-2.6637e-02,  1.2871e-02,  1.4594e-02]],\n",
      "\n",
      "         [[-2.8302e-02,  1.4367e-02,  1.2405e-03],\n",
      "          [ 1.0320e-02, -2.5639e-02, -1.9566e-02],\n",
      "          [-2.5839e-03, -1.3719e-02,  5.7286e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6218e-02,  2.1407e-02,  1.4895e-02],\n",
      "          [ 4.7506e-03,  1.3060e-02,  3.2025e-03],\n",
      "          [-1.3842e-02, -1.4576e-02,  5.5424e-03]],\n",
      "\n",
      "         [[ 2.3716e-02,  2.1003e-02, -2.5522e-02],\n",
      "          [-5.2027e-03, -5.5330e-03, -2.3552e-04],\n",
      "          [-2.0074e-02, -2.8134e-02, -1.9636e-02]],\n",
      "\n",
      "         [[-2.3428e-02,  1.5052e-02, -7.9785e-03],\n",
      "          [ 4.5586e-03, -1.8125e-02, -8.8484e-03],\n",
      "          [ 2.1805e-02, -1.9798e-02, -2.1958e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.4928e-02, -1.7449e-02,  1.4049e-02],\n",
      "          [ 6.9136e-03,  8.1036e-03, -1.9017e-02],\n",
      "          [ 7.4637e-03,  1.3831e-02,  1.2781e-02]],\n",
      "\n",
      "         [[ 1.3434e-02,  3.9391e-03, -2.8540e-02],\n",
      "          [ 2.4646e-02, -2.2471e-02, -1.3927e-02],\n",
      "          [-1.2276e-02,  2.6025e-03,  2.4508e-03]],\n",
      "\n",
      "         [[ 5.6342e-03,  1.0245e-02, -2.4659e-02],\n",
      "          [-1.9720e-02,  1.7517e-02, -1.1873e-02],\n",
      "          [-1.2135e-02, -2.7953e-02,  7.9912e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7516e-02, -9.6686e-03, -2.2083e-02],\n",
      "          [-5.4301e-03,  2.0743e-03,  2.0707e-02],\n",
      "          [ 8.0911e-03,  2.7705e-02, -1.4386e-02]],\n",
      "\n",
      "         [[ 2.6269e-02,  2.8470e-02, -3.2904e-03],\n",
      "          [-1.5734e-02, -2.6573e-02, -1.3553e-02],\n",
      "          [ 1.1235e-02, -2.2050e-03, -1.4992e-02]],\n",
      "\n",
      "         [[-1.0759e-02, -5.1008e-03,  2.1196e-02],\n",
      "          [-1.3210e-02, -2.7965e-02, -1.6269e-03],\n",
      "          [-7.6127e-03, -2.0057e-02,  2.0176e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5980e-02,  1.8516e-02, -1.9774e-02],\n",
      "          [ 1.6025e-02, -1.7125e-03,  2.2338e-02],\n",
      "          [ 1.8648e-02,  1.9942e-03,  1.5819e-03]],\n",
      "\n",
      "         [[ 1.6882e-02, -6.9820e-03,  1.4280e-02],\n",
      "          [-1.4527e-02, -4.1783e-03,  2.0931e-03],\n",
      "          [-2.6496e-02, -1.7390e-02,  1.8737e-02]],\n",
      "\n",
      "         [[-1.6769e-02, -5.2667e-03,  7.5314e-03],\n",
      "          [ 1.5168e-02, -1.9760e-02, -1.0193e-02],\n",
      "          [ 2.2016e-02,  3.0734e-03,  2.0315e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.6638e-03, -1.2534e-02,  2.9529e-03],\n",
      "          [ 1.1365e-02,  1.5681e-02, -6.8077e-03],\n",
      "          [ 2.5700e-02, -1.7377e-02, -1.2387e-02]],\n",
      "\n",
      "         [[ 1.3237e-02,  2.3624e-02,  2.3665e-02],\n",
      "          [-6.0904e-03,  1.9444e-02,  2.1922e-02],\n",
      "          [-2.8876e-02, -4.4990e-03, -2.5483e-02]],\n",
      "\n",
      "         [[ 2.5968e-03,  1.4311e-02,  2.3107e-02],\n",
      "          [ 5.1468e-03,  2.1176e-02, -1.6650e-02],\n",
      "          [-1.8600e-03,  1.8046e-02,  2.8915e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.5345e-03,  3.7959e-03,  2.0558e-04],\n",
      "          [ 7.5730e-03,  8.5307e-03,  1.2586e-02],\n",
      "          [ 2.3411e-02, -1.0727e-02, -1.3707e-02]],\n",
      "\n",
      "         [[-7.0047e-03, -5.5989e-04,  3.2019e-03],\n",
      "          [ 2.0307e-02, -2.5178e-02,  5.4549e-03],\n",
      "          [ 4.0238e-03, -2.7288e-02, -3.7036e-03]],\n",
      "\n",
      "         [[-1.5224e-02, -1.5829e-02,  9.8512e-03],\n",
      "          [ 1.5182e-03,  2.7462e-02,  2.8786e-02],\n",
      "          [-1.3604e-02,  9.4736e-03,  2.1477e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985e-02,  2.8813e-02, -1.1624e-03],\n",
      "          [ 2.3046e-02,  5.9355e-04, -1.0283e-02],\n",
      "          [ 2.3984e-02, -2.0561e-02,  2.2404e-04]],\n",
      "\n",
      "         [[ 2.5477e-02,  5.3307e-03,  2.4255e-02],\n",
      "          [ 1.2400e-02,  2.5931e-02,  1.0653e-02],\n",
      "          [ 2.9121e-02, -2.7713e-02, -5.0108e-03]],\n",
      "\n",
      "         [[ 1.0500e-02, -1.1607e-02, -1.1192e-04],\n",
      "          [-4.6101e-03,  1.8661e-02, -2.7035e-02],\n",
      "          [ 2.9440e-02,  1.3523e-02, -2.3498e-02]]]])\n",
      "Layer: layer2.1.conv1.bias, Biases: tensor([-0.0145,  0.0045,  0.0053, -0.0220, -0.0184,  0.0060, -0.0143,  0.0138,\n",
      "        -0.0017,  0.0064, -0.0017,  0.0268, -0.0284, -0.0032, -0.0057, -0.0032,\n",
      "         0.0282, -0.0074, -0.0161, -0.0077, -0.0292, -0.0022, -0.0260, -0.0081,\n",
      "         0.0219,  0.0080,  0.0119, -0.0091, -0.0006,  0.0230,  0.0278, -0.0082,\n",
      "         0.0290,  0.0169,  0.0151, -0.0037,  0.0225,  0.0282,  0.0143, -0.0273,\n",
      "        -0.0020, -0.0271,  0.0247, -0.0064,  0.0031,  0.0282,  0.0197,  0.0198,\n",
      "         0.0199,  0.0121, -0.0264,  0.0176, -0.0153,  0.0027,  0.0028,  0.0140,\n",
      "        -0.0072, -0.0105, -0.0099,  0.0013,  0.0096,  0.0126,  0.0061, -0.0279])\n",
      "Layer: layer2.1.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer2.1.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer2.1.conv2.weight:, Weights: tensor([[[[-0.0332, -0.0214, -0.0073],\n",
      "          [ 0.0190, -0.0407,  0.0088],\n",
      "          [-0.0286, -0.0338, -0.0243]],\n",
      "\n",
      "         [[ 0.0009, -0.0313,  0.0167],\n",
      "          [-0.0007, -0.0176, -0.0006],\n",
      "          [-0.0373,  0.0273, -0.0168]],\n",
      "\n",
      "         [[-0.0101,  0.0243,  0.0363],\n",
      "          [ 0.0228, -0.0247,  0.0397],\n",
      "          [ 0.0078, -0.0065,  0.0066]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0084, -0.0401, -0.0031],\n",
      "          [ 0.0165, -0.0373, -0.0336],\n",
      "          [ 0.0364, -0.0384,  0.0113]],\n",
      "\n",
      "         [[ 0.0096, -0.0125, -0.0051],\n",
      "          [ 0.0285,  0.0194, -0.0054],\n",
      "          [-0.0074,  0.0076, -0.0027]],\n",
      "\n",
      "         [[ 0.0044, -0.0319, -0.0402],\n",
      "          [-0.0380, -0.0333, -0.0125],\n",
      "          [-0.0109,  0.0399, -0.0365]]],\n",
      "\n",
      "\n",
      "        [[[-0.0128,  0.0250,  0.0310],\n",
      "          [-0.0265, -0.0049, -0.0205],\n",
      "          [ 0.0151,  0.0116, -0.0023]],\n",
      "\n",
      "         [[ 0.0246, -0.0251,  0.0165],\n",
      "          [-0.0333, -0.0168, -0.0042],\n",
      "          [-0.0096,  0.0169, -0.0408]],\n",
      "\n",
      "         [[ 0.0185, -0.0383,  0.0225],\n",
      "          [-0.0401,  0.0244, -0.0166],\n",
      "          [-0.0371,  0.0153,  0.0055]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0023, -0.0382, -0.0233],\n",
      "          [-0.0191, -0.0170, -0.0175],\n",
      "          [ 0.0415,  0.0224, -0.0132]],\n",
      "\n",
      "         [[-0.0156, -0.0021,  0.0078],\n",
      "          [ 0.0155, -0.0304, -0.0190],\n",
      "          [-0.0302, -0.0174, -0.0367]],\n",
      "\n",
      "         [[-0.0311, -0.0380,  0.0154],\n",
      "          [-0.0365,  0.0130, -0.0315],\n",
      "          [ 0.0215, -0.0347, -0.0204]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0324, -0.0077, -0.0231],\n",
      "          [ 0.0173, -0.0294, -0.0330],\n",
      "          [ 0.0294, -0.0206,  0.0104]],\n",
      "\n",
      "         [[-0.0103, -0.0143,  0.0355],\n",
      "          [ 0.0069,  0.0017,  0.0045],\n",
      "          [ 0.0012, -0.0355, -0.0004]],\n",
      "\n",
      "         [[-0.0029, -0.0081, -0.0274],\n",
      "          [-0.0073,  0.0072, -0.0351],\n",
      "          [ 0.0377,  0.0268,  0.0201]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0396, -0.0378, -0.0124],\n",
      "          [-0.0397, -0.0386, -0.0345],\n",
      "          [ 0.0008,  0.0205, -0.0052]],\n",
      "\n",
      "         [[-0.0088,  0.0203,  0.0036],\n",
      "          [ 0.0110, -0.0046, -0.0255],\n",
      "          [ 0.0225,  0.0331,  0.0235]],\n",
      "\n",
      "         [[-0.0157, -0.0013, -0.0033],\n",
      "          [-0.0276, -0.0122, -0.0394],\n",
      "          [ 0.0096,  0.0245,  0.0350]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0396, -0.0099, -0.0279],\n",
      "          [ 0.0335,  0.0321, -0.0215],\n",
      "          [-0.0274, -0.0075,  0.0203]],\n",
      "\n",
      "         [[ 0.0380,  0.0060, -0.0145],\n",
      "          [ 0.0013,  0.0261, -0.0040],\n",
      "          [-0.0346,  0.0036,  0.0173]],\n",
      "\n",
      "         [[ 0.0106, -0.0356,  0.0109],\n",
      "          [-0.0163, -0.0144,  0.0147],\n",
      "          [-0.0174, -0.0042,  0.0046]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0150,  0.0404, -0.0386],\n",
      "          [ 0.0190,  0.0324, -0.0048],\n",
      "          [ 0.0313,  0.0166, -0.0291]],\n",
      "\n",
      "         [[-0.0320, -0.0249, -0.0216],\n",
      "          [ 0.0217,  0.0200, -0.0300],\n",
      "          [ 0.0012,  0.0044,  0.0119]],\n",
      "\n",
      "         [[ 0.0069,  0.0112, -0.0327],\n",
      "          [-0.0279,  0.0346,  0.0162],\n",
      "          [-0.0050,  0.0037,  0.0299]]],\n",
      "\n",
      "\n",
      "        [[[-0.0327, -0.0147,  0.0101],\n",
      "          [ 0.0329, -0.0017, -0.0342],\n",
      "          [ 0.0382,  0.0019,  0.0082]],\n",
      "\n",
      "         [[-0.0378, -0.0251, -0.0158],\n",
      "          [ 0.0152, -0.0346,  0.0298],\n",
      "          [-0.0153,  0.0117,  0.0267]],\n",
      "\n",
      "         [[ 0.0351, -0.0357, -0.0090],\n",
      "          [-0.0109, -0.0407,  0.0079],\n",
      "          [-0.0259,  0.0141, -0.0176]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0246,  0.0356, -0.0086],\n",
      "          [ 0.0137, -0.0155, -0.0237],\n",
      "          [-0.0377,  0.0227, -0.0285]],\n",
      "\n",
      "         [[ 0.0161,  0.0373,  0.0416],\n",
      "          [-0.0355, -0.0114,  0.0119],\n",
      "          [-0.0019, -0.0168,  0.0348]],\n",
      "\n",
      "         [[ 0.0077, -0.0383, -0.0007],\n",
      "          [-0.0288,  0.0220, -0.0073],\n",
      "          [-0.0358,  0.0113,  0.0264]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0029,  0.0223, -0.0012],\n",
      "          [ 0.0035, -0.0361, -0.0366],\n",
      "          [ 0.0370, -0.0041, -0.0053]],\n",
      "\n",
      "         [[-0.0183, -0.0339, -0.0078],\n",
      "          [ 0.0296, -0.0374,  0.0166],\n",
      "          [-0.0385, -0.0191, -0.0331]],\n",
      "\n",
      "         [[ 0.0059,  0.0029,  0.0309],\n",
      "          [ 0.0046, -0.0365, -0.0004],\n",
      "          [ 0.0051, -0.0087,  0.0273]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0384,  0.0411,  0.0106],\n",
      "          [ 0.0329,  0.0221, -0.0410],\n",
      "          [-0.0259, -0.0378,  0.0053]],\n",
      "\n",
      "         [[-0.0009, -0.0007, -0.0380],\n",
      "          [-0.0319,  0.0025, -0.0044],\n",
      "          [-0.0028,  0.0123, -0.0185]],\n",
      "\n",
      "         [[-0.0084, -0.0414, -0.0071],\n",
      "          [-0.0402, -0.0005, -0.0099],\n",
      "          [-0.0308, -0.0364,  0.0186]]]])\n",
      "Layer: layer2.1.conv2.bias, Biases: tensor([-0.0065, -0.0161, -0.0201,  0.0005,  0.0153, -0.0147,  0.0347,  0.0008,\n",
      "        -0.0135, -0.0335, -0.0052, -0.0346, -0.0002,  0.0190, -0.0341,  0.0042,\n",
      "         0.0358,  0.0068, -0.0046,  0.0059,  0.0123,  0.0276, -0.0398, -0.0326,\n",
      "        -0.0087, -0.0319,  0.0212, -0.0413,  0.0174,  0.0121,  0.0171, -0.0361,\n",
      "        -0.0192, -0.0396, -0.0285, -0.0406, -0.0036,  0.0173, -0.0358,  0.0339,\n",
      "         0.0186,  0.0085, -0.0061, -0.0360, -0.0209, -0.0056, -0.0011,  0.0087,\n",
      "         0.0277, -0.0144, -0.0153,  0.0266,  0.0029, -0.0378, -0.0200, -0.0207,\n",
      "         0.0308, -0.0210, -0.0116, -0.0300,  0.0264,  0.0008, -0.0075,  0.0288,\n",
      "         0.0105,  0.0359, -0.0331, -0.0372,  0.0005, -0.0280,  0.0331, -0.0324,\n",
      "         0.0364,  0.0359,  0.0279, -0.0164, -0.0003,  0.0177,  0.0158, -0.0260,\n",
      "        -0.0276, -0.0102,  0.0111,  0.0188, -0.0234, -0.0141, -0.0110,  0.0350,\n",
      "        -0.0303, -0.0001, -0.0304, -0.0058, -0.0187,  0.0348,  0.0222,  0.0342,\n",
      "         0.0198,  0.0109,  0.0332, -0.0037,  0.0380, -0.0300, -0.0368,  0.0372,\n",
      "         0.0012,  0.0268,  0.0406,  0.0196, -0.0328, -0.0329, -0.0192,  0.0323,\n",
      "         0.0397, -0.0372, -0.0186, -0.0199, -0.0107,  0.0360,  0.0106, -0.0210,\n",
      "        -0.0144,  0.0099,  0.0299,  0.0162,  0.0211, -0.0077,  0.0414, -0.0188])\n",
      "Layer: layer2.1.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Layer: layer2.1.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer2.2.conv1.weight:, Weights: tensor([[[[-0.0239,  0.0283,  0.0150],\n",
      "          [-0.0163, -0.0116,  0.0094],\n",
      "          [-0.0055,  0.0198,  0.0169]],\n",
      "\n",
      "         [[-0.0225, -0.0140,  0.0169],\n",
      "          [ 0.0175, -0.0197,  0.0003],\n",
      "          [ 0.0021,  0.0160, -0.0043]],\n",
      "\n",
      "         [[ 0.0066, -0.0221, -0.0045],\n",
      "          [ 0.0167,  0.0121, -0.0091],\n",
      "          [ 0.0099,  0.0183, -0.0070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0285,  0.0112,  0.0156],\n",
      "          [ 0.0202,  0.0137,  0.0153],\n",
      "          [ 0.0032, -0.0193,  0.0054]],\n",
      "\n",
      "         [[ 0.0284,  0.0261,  0.0026],\n",
      "          [ 0.0057,  0.0113, -0.0166],\n",
      "          [ 0.0035,  0.0113,  0.0269]],\n",
      "\n",
      "         [[ 0.0071, -0.0148, -0.0176],\n",
      "          [-0.0239, -0.0076, -0.0249],\n",
      "          [ 0.0224, -0.0005,  0.0055]]],\n",
      "\n",
      "\n",
      "        [[[-0.0019,  0.0281, -0.0222],\n",
      "          [ 0.0168,  0.0261, -0.0142],\n",
      "          [ 0.0176, -0.0198,  0.0201]],\n",
      "\n",
      "         [[ 0.0186, -0.0259, -0.0233],\n",
      "          [ 0.0202, -0.0234, -0.0086],\n",
      "          [ 0.0206,  0.0244, -0.0243]],\n",
      "\n",
      "         [[ 0.0060,  0.0058, -0.0260],\n",
      "          [-0.0077, -0.0119,  0.0079],\n",
      "          [-0.0288,  0.0284, -0.0179]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0198,  0.0274, -0.0238],\n",
      "          [-0.0032,  0.0274,  0.0014],\n",
      "          [ 0.0109, -0.0087,  0.0253]],\n",
      "\n",
      "         [[-0.0037,  0.0136,  0.0075],\n",
      "          [-0.0018, -0.0283,  0.0154],\n",
      "          [ 0.0060,  0.0110, -0.0021]],\n",
      "\n",
      "         [[-0.0102,  0.0116,  0.0211],\n",
      "          [-0.0228,  0.0223,  0.0175],\n",
      "          [ 0.0213, -0.0160, -0.0112]]],\n",
      "\n",
      "\n",
      "        [[[-0.0261, -0.0067,  0.0089],\n",
      "          [-0.0256,  0.0192, -0.0069],\n",
      "          [-0.0226,  0.0163,  0.0031]],\n",
      "\n",
      "         [[ 0.0274, -0.0054, -0.0066],\n",
      "          [-0.0195,  0.0116,  0.0035],\n",
      "          [ 0.0175,  0.0056, -0.0250]],\n",
      "\n",
      "         [[ 0.0290,  0.0001,  0.0196],\n",
      "          [-0.0272, -0.0100, -0.0147],\n",
      "          [-0.0164,  0.0188, -0.0202]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0164, -0.0168,  0.0014],\n",
      "          [-0.0247,  0.0183,  0.0193],\n",
      "          [ 0.0249, -0.0141, -0.0017]],\n",
      "\n",
      "         [[ 0.0284,  0.0138,  0.0092],\n",
      "          [-0.0167,  0.0268, -0.0044],\n",
      "          [ 0.0197, -0.0018,  0.0086]],\n",
      "\n",
      "         [[-0.0095,  0.0019,  0.0181],\n",
      "          [ 0.0027, -0.0204, -0.0180],\n",
      "          [ 0.0222, -0.0260, -0.0064]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0211, -0.0064, -0.0252],\n",
      "          [-0.0207,  0.0202,  0.0131],\n",
      "          [-0.0107,  0.0143, -0.0114]],\n",
      "\n",
      "         [[-0.0141, -0.0201,  0.0171],\n",
      "          [ 0.0061, -0.0039, -0.0136],\n",
      "          [ 0.0034, -0.0237, -0.0137]],\n",
      "\n",
      "         [[ 0.0146,  0.0192,  0.0205],\n",
      "          [ 0.0142,  0.0091,  0.0153],\n",
      "          [ 0.0221, -0.0270,  0.0101]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0121, -0.0034, -0.0217],\n",
      "          [ 0.0283, -0.0166,  0.0147],\n",
      "          [ 0.0099, -0.0010,  0.0050]],\n",
      "\n",
      "         [[-0.0210,  0.0290,  0.0270],\n",
      "          [-0.0140, -0.0143,  0.0127],\n",
      "          [ 0.0044,  0.0107,  0.0008]],\n",
      "\n",
      "         [[-0.0128,  0.0078,  0.0268],\n",
      "          [-0.0088,  0.0022,  0.0293],\n",
      "          [ 0.0244,  0.0007, -0.0187]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0202,  0.0011, -0.0056],\n",
      "          [ 0.0187,  0.0157, -0.0087],\n",
      "          [ 0.0101,  0.0262, -0.0151]],\n",
      "\n",
      "         [[-0.0206,  0.0198, -0.0091],\n",
      "          [ 0.0259,  0.0091, -0.0209],\n",
      "          [ 0.0274, -0.0255, -0.0266]],\n",
      "\n",
      "         [[-0.0146,  0.0290, -0.0052],\n",
      "          [ 0.0151,  0.0130, -0.0134],\n",
      "          [ 0.0290,  0.0014,  0.0173]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0142,  0.0076,  0.0290],\n",
      "          [ 0.0116, -0.0233, -0.0118],\n",
      "          [-0.0203, -0.0245, -0.0163]],\n",
      "\n",
      "         [[-0.0207,  0.0290, -0.0163],\n",
      "          [ 0.0008, -0.0017, -0.0042],\n",
      "          [-0.0219,  0.0102, -0.0149]],\n",
      "\n",
      "         [[ 0.0127,  0.0268, -0.0292],\n",
      "          [ 0.0130,  0.0208,  0.0133],\n",
      "          [ 0.0121, -0.0242, -0.0267]]],\n",
      "\n",
      "\n",
      "        [[[-0.0165, -0.0245, -0.0123],\n",
      "          [ 0.0133,  0.0016, -0.0226],\n",
      "          [-0.0258,  0.0052,  0.0234]],\n",
      "\n",
      "         [[ 0.0020,  0.0076,  0.0095],\n",
      "          [ 0.0179, -0.0079,  0.0110],\n",
      "          [ 0.0116,  0.0228,  0.0128]],\n",
      "\n",
      "         [[-0.0243,  0.0034, -0.0055],\n",
      "          [ 0.0206,  0.0198,  0.0052],\n",
      "          [-0.0065, -0.0014, -0.0222]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0279, -0.0051, -0.0221],\n",
      "          [-0.0283, -0.0181, -0.0211],\n",
      "          [ 0.0105,  0.0034, -0.0050]],\n",
      "\n",
      "         [[-0.0293,  0.0255, -0.0123],\n",
      "          [-0.0030, -0.0124,  0.0005],\n",
      "          [ 0.0288, -0.0182,  0.0145]],\n",
      "\n",
      "         [[ 0.0034,  0.0149,  0.0045],\n",
      "          [ 0.0036, -0.0073,  0.0047],\n",
      "          [ 0.0291, -0.0082,  0.0079]]]])\n",
      "Layer: layer2.2.conv1.bias, Biases: tensor([-3.8229e-03, -2.8106e-02,  1.4816e-02, -5.9361e-03, -1.7103e-02,\n",
      "         5.8300e-04, -2.4915e-02, -9.9519e-03, -8.1481e-03,  2.5490e-02,\n",
      "        -1.3772e-02,  1.6090e-02,  2.7947e-02,  2.6496e-02,  2.7127e-02,\n",
      "        -2.8813e-02,  9.1571e-04,  1.4284e-02,  2.0535e-02, -2.2690e-02,\n",
      "        -2.8607e-02,  1.9977e-02,  2.2361e-02,  1.8920e-02,  2.3009e-02,\n",
      "         2.8203e-02, -1.9264e-02,  1.6862e-02,  1.1557e-02, -2.1129e-02,\n",
      "        -1.4992e-02, -1.6052e-03,  2.7585e-02,  2.3912e-02, -2.5841e-02,\n",
      "        -2.4444e-02, -2.5629e-02, -2.8167e-03,  7.0258e-03, -1.1701e-02,\n",
      "        -4.5971e-03,  2.1173e-02, -2.3745e-02, -6.0634e-03, -9.7052e-03,\n",
      "         2.1136e-02, -1.5415e-02, -9.0479e-03, -2.4591e-02, -1.4277e-02,\n",
      "         1.2895e-02, -6.9061e-03,  1.9414e-02,  1.9305e-02, -1.6360e-05,\n",
      "         8.3066e-03, -1.9866e-02,  2.1951e-02, -1.3660e-02, -1.9023e-03,\n",
      "        -2.6754e-02,  1.0171e-03,  1.0723e-02,  1.9663e-02])\n",
      "Layer: layer2.2.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer2.2.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer2.2.conv2.weight:, Weights: tensor([[[[-0.0223, -0.0023,  0.0291],\n",
      "          [ 0.0360,  0.0187,  0.0199],\n",
      "          [-0.0036, -0.0366, -0.0228]],\n",
      "\n",
      "         [[-0.0204, -0.0402,  0.0367],\n",
      "          [-0.0317,  0.0140,  0.0309],\n",
      "          [ 0.0223,  0.0221,  0.0411]],\n",
      "\n",
      "         [[-0.0018,  0.0187, -0.0039],\n",
      "          [ 0.0395, -0.0371,  0.0053],\n",
      "          [ 0.0036, -0.0317,  0.0126]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0087,  0.0271,  0.0151],\n",
      "          [-0.0016,  0.0118, -0.0316],\n",
      "          [ 0.0332,  0.0365, -0.0231]],\n",
      "\n",
      "         [[-0.0162, -0.0119, -0.0020],\n",
      "          [-0.0374,  0.0414,  0.0349],\n",
      "          [ 0.0367, -0.0294,  0.0311]],\n",
      "\n",
      "         [[-0.0243, -0.0326,  0.0220],\n",
      "          [ 0.0314,  0.0129,  0.0084],\n",
      "          [ 0.0241,  0.0090, -0.0326]]],\n",
      "\n",
      "\n",
      "        [[[-0.0013,  0.0398,  0.0264],\n",
      "          [ 0.0312, -0.0378, -0.0174],\n",
      "          [-0.0243, -0.0124, -0.0323]],\n",
      "\n",
      "         [[ 0.0386,  0.0295,  0.0192],\n",
      "          [-0.0188, -0.0102,  0.0360],\n",
      "          [ 0.0122, -0.0414, -0.0282]],\n",
      "\n",
      "         [[-0.0041, -0.0017,  0.0150],\n",
      "          [-0.0114, -0.0059,  0.0179],\n",
      "          [-0.0341, -0.0225, -0.0353]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0095, -0.0200, -0.0042],\n",
      "          [-0.0063, -0.0341,  0.0042],\n",
      "          [ 0.0298, -0.0040,  0.0270]],\n",
      "\n",
      "         [[ 0.0220,  0.0339,  0.0338],\n",
      "          [ 0.0105, -0.0181,  0.0202],\n",
      "          [-0.0387,  0.0411, -0.0397]],\n",
      "\n",
      "         [[ 0.0251, -0.0121, -0.0379],\n",
      "          [ 0.0180, -0.0417, -0.0094],\n",
      "          [-0.0160,  0.0198, -0.0128]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0058, -0.0201, -0.0350],\n",
      "          [-0.0154, -0.0249,  0.0261],\n",
      "          [-0.0227,  0.0131,  0.0007]],\n",
      "\n",
      "         [[-0.0273, -0.0089, -0.0037],\n",
      "          [ 0.0270, -0.0127, -0.0256],\n",
      "          [ 0.0385,  0.0333,  0.0143]],\n",
      "\n",
      "         [[-0.0346,  0.0074, -0.0222],\n",
      "          [-0.0148, -0.0343, -0.0101],\n",
      "          [-0.0287,  0.0204, -0.0151]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0090,  0.0038, -0.0015],\n",
      "          [-0.0350, -0.0347, -0.0233],\n",
      "          [-0.0316,  0.0120,  0.0288]],\n",
      "\n",
      "         [[-0.0051,  0.0218, -0.0311],\n",
      "          [-0.0112,  0.0024, -0.0178],\n",
      "          [-0.0289, -0.0208, -0.0014]],\n",
      "\n",
      "         [[-0.0004,  0.0314, -0.0403],\n",
      "          [-0.0065,  0.0170,  0.0040],\n",
      "          [ 0.0092, -0.0115,  0.0117]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0129, -0.0093,  0.0263],\n",
      "          [ 0.0283, -0.0126, -0.0412],\n",
      "          [ 0.0239, -0.0167,  0.0024]],\n",
      "\n",
      "         [[-0.0076, -0.0241,  0.0119],\n",
      "          [-0.0079,  0.0204, -0.0182],\n",
      "          [-0.0279,  0.0200, -0.0380]],\n",
      "\n",
      "         [[-0.0279, -0.0311, -0.0281],\n",
      "          [ 0.0313, -0.0033, -0.0197],\n",
      "          [-0.0054,  0.0360,  0.0384]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0118, -0.0246, -0.0208],\n",
      "          [ 0.0338, -0.0020,  0.0099],\n",
      "          [-0.0258, -0.0289, -0.0025]],\n",
      "\n",
      "         [[ 0.0390,  0.0042, -0.0284],\n",
      "          [ 0.0064,  0.0342, -0.0026],\n",
      "          [-0.0033,  0.0142, -0.0141]],\n",
      "\n",
      "         [[-0.0330,  0.0195, -0.0146],\n",
      "          [ 0.0383, -0.0188,  0.0287],\n",
      "          [-0.0330,  0.0257, -0.0224]]],\n",
      "\n",
      "\n",
      "        [[[-0.0246, -0.0376, -0.0409],\n",
      "          [ 0.0152, -0.0176,  0.0378],\n",
      "          [-0.0019,  0.0006, -0.0371]],\n",
      "\n",
      "         [[-0.0045,  0.0259, -0.0032],\n",
      "          [ 0.0073, -0.0314, -0.0026],\n",
      "          [ 0.0140,  0.0087,  0.0045]],\n",
      "\n",
      "         [[-0.0047, -0.0112,  0.0170],\n",
      "          [-0.0188, -0.0137, -0.0199],\n",
      "          [ 0.0113,  0.0187,  0.0043]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0314,  0.0330,  0.0200],\n",
      "          [ 0.0090,  0.0267,  0.0179],\n",
      "          [ 0.0265,  0.0123,  0.0376]],\n",
      "\n",
      "         [[-0.0170,  0.0258, -0.0284],\n",
      "          [-0.0367, -0.0063,  0.0308],\n",
      "          [ 0.0088, -0.0381,  0.0396]],\n",
      "\n",
      "         [[-0.0354, -0.0150,  0.0096],\n",
      "          [-0.0302, -0.0277, -0.0186],\n",
      "          [-0.0134, -0.0080,  0.0056]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0361, -0.0260, -0.0035],\n",
      "          [ 0.0042, -0.0389,  0.0131],\n",
      "          [ 0.0290,  0.0172, -0.0174]],\n",
      "\n",
      "         [[-0.0403,  0.0050,  0.0349],\n",
      "          [ 0.0055, -0.0286,  0.0052],\n",
      "          [-0.0034, -0.0130, -0.0117]],\n",
      "\n",
      "         [[-0.0398,  0.0255,  0.0126],\n",
      "          [ 0.0077, -0.0254,  0.0029],\n",
      "          [ 0.0364,  0.0237, -0.0082]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0406,  0.0050, -0.0078],\n",
      "          [-0.0080, -0.0016, -0.0410],\n",
      "          [-0.0104,  0.0004,  0.0046]],\n",
      "\n",
      "         [[ 0.0359, -0.0284,  0.0377],\n",
      "          [-0.0393,  0.0071, -0.0020],\n",
      "          [-0.0389,  0.0258, -0.0245]],\n",
      "\n",
      "         [[ 0.0153,  0.0342, -0.0068],\n",
      "          [-0.0148, -0.0332,  0.0303],\n",
      "          [ 0.0288, -0.0194,  0.0397]]]])\n",
      "Layer: layer2.2.conv2.bias, Biases: tensor([ 0.0097, -0.0376, -0.0027, -0.0123, -0.0152,  0.0005,  0.0220,  0.0074,\n",
      "        -0.0150,  0.0080,  0.0310,  0.0010, -0.0073,  0.0059,  0.0354, -0.0310,\n",
      "        -0.0120, -0.0112, -0.0357,  0.0159, -0.0364, -0.0297, -0.0082, -0.0013,\n",
      "         0.0292,  0.0063, -0.0065,  0.0285, -0.0386, -0.0070,  0.0150, -0.0303,\n",
      "        -0.0368,  0.0143, -0.0404, -0.0016,  0.0145,  0.0352, -0.0023, -0.0045,\n",
      "         0.0095,  0.0318,  0.0196,  0.0245,  0.0119, -0.0364,  0.0036, -0.0046,\n",
      "         0.0314,  0.0074,  0.0085, -0.0217,  0.0160,  0.0250, -0.0297, -0.0136,\n",
      "         0.0341, -0.0085,  0.0156,  0.0025, -0.0272, -0.0329,  0.0350, -0.0286,\n",
      "        -0.0165,  0.0210,  0.0151,  0.0382,  0.0172, -0.0144,  0.0317,  0.0296,\n",
      "         0.0332,  0.0352,  0.0371, -0.0341, -0.0387, -0.0346, -0.0349,  0.0018,\n",
      "         0.0079, -0.0031,  0.0334, -0.0162,  0.0193, -0.0104, -0.0350,  0.0005,\n",
      "         0.0079,  0.0364,  0.0137, -0.0354,  0.0173,  0.0114,  0.0333,  0.0334,\n",
      "         0.0410, -0.0197, -0.0040, -0.0326,  0.0084,  0.0018,  0.0247, -0.0176,\n",
      "         0.0099, -0.0187, -0.0065,  0.0371,  0.0063, -0.0184, -0.0383, -0.0037,\n",
      "        -0.0289, -0.0226,  0.0263,  0.0346,  0.0400, -0.0353,  0.0173,  0.0335,\n",
      "        -0.0091, -0.0269, -0.0120, -0.0256,  0.0203,  0.0411, -0.0195,  0.0188])\n",
      "Layer: layer2.2.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Layer: layer2.2.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer2.3.conv1.weight:, Weights: tensor([[[[-1.7602e-02,  7.2205e-03, -5.0786e-03],\n",
      "          [ 3.0588e-03, -2.0658e-02,  1.5918e-02],\n",
      "          [ 1.6834e-02, -1.2714e-02, -3.1873e-04]],\n",
      "\n",
      "         [[ 2.3765e-02,  1.7642e-02,  1.0644e-02],\n",
      "          [ 1.5709e-02, -1.1595e-02,  1.4202e-02],\n",
      "          [-2.3269e-02, -1.0747e-02,  1.1074e-02]],\n",
      "\n",
      "         [[-2.3673e-02, -1.9719e-02,  2.4564e-02],\n",
      "          [-2.4849e-02, -2.4455e-02, -2.5604e-02],\n",
      "          [-1.8902e-03, -2.6163e-02,  7.0554e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.3009e-03,  1.5023e-02, -1.8164e-03],\n",
      "          [-1.7881e-03,  1.8337e-03,  5.2279e-03],\n",
      "          [ 2.8657e-02, -1.6811e-02,  2.6257e-02]],\n",
      "\n",
      "         [[-2.2336e-02,  1.8576e-02,  8.5955e-03],\n",
      "          [ 2.7367e-02, -2.8280e-02,  8.2888e-04],\n",
      "          [ 1.3272e-02, -1.5253e-02, -1.3439e-02]],\n",
      "\n",
      "         [[-2.1601e-02,  1.0605e-02,  2.6414e-02],\n",
      "          [ 2.1841e-02, -2.6126e-02,  1.1578e-02],\n",
      "          [ 8.1408e-03,  2.8444e-02, -1.6268e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5597e-03,  1.2661e-02,  8.8859e-03],\n",
      "          [ 6.0700e-03, -6.5564e-03,  1.7283e-03],\n",
      "          [ 2.0469e-02, -8.2001e-03,  5.6102e-03]],\n",
      "\n",
      "         [[-2.0644e-02, -1.0609e-02,  2.7354e-02],\n",
      "          [-2.0864e-02, -1.9747e-02, -2.6269e-02],\n",
      "          [ 1.4281e-02, -9.3883e-03, -7.5581e-03]],\n",
      "\n",
      "         [[-2.3726e-02,  9.1978e-03,  2.0460e-02],\n",
      "          [ 2.8829e-02,  8.1834e-03,  1.7877e-03],\n",
      "          [-2.6307e-02,  2.2585e-02, -1.1539e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.8760e-03, -4.6903e-03, -1.8186e-02],\n",
      "          [ 1.5497e-02,  4.4511e-04,  1.1249e-02],\n",
      "          [ 2.2839e-02,  6.2236e-04, -2.5535e-02]],\n",
      "\n",
      "         [[-2.5879e-02, -1.4731e-02,  1.4524e-02],\n",
      "          [ 1.1206e-02,  1.5689e-02,  1.4308e-02],\n",
      "          [-5.8774e-03,  2.2584e-02, -2.3923e-02]],\n",
      "\n",
      "         [[-2.1238e-02,  1.0095e-02,  1.9419e-02],\n",
      "          [ 2.6163e-02, -1.4041e-02, -1.1932e-02],\n",
      "          [-1.3710e-02, -1.9099e-02, -2.8786e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2599e-02,  1.5191e-02,  2.8124e-02],\n",
      "          [ 2.1041e-02,  1.1952e-02, -2.8901e-02],\n",
      "          [-2.8814e-02, -3.9055e-04,  2.2800e-02]],\n",
      "\n",
      "         [[-1.6171e-02, -1.7332e-02,  5.4335e-03],\n",
      "          [ 1.9606e-02,  1.2657e-02,  5.1311e-04],\n",
      "          [-1.1415e-02, -1.9040e-02,  7.8182e-03]],\n",
      "\n",
      "         [[-2.8162e-02, -3.5558e-03,  2.2760e-02],\n",
      "          [-2.3378e-02, -2.3323e-02, -2.7951e-02],\n",
      "          [-6.2797e-03,  5.4999e-03, -9.3161e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5258e-03,  6.4275e-03, -1.7279e-02],\n",
      "          [ 3.7702e-03,  1.4416e-02,  2.7896e-04],\n",
      "          [ 7.5239e-05,  2.6758e-03,  2.0662e-02]],\n",
      "\n",
      "         [[-2.7076e-02,  1.7203e-02,  2.1494e-02],\n",
      "          [ 1.2227e-02, -6.7733e-03,  1.5482e-02],\n",
      "          [-2.6017e-02, -2.7198e-02, -1.7065e-02]],\n",
      "\n",
      "         [[ 1.0477e-03, -4.5002e-03,  4.6325e-03],\n",
      "          [-1.6799e-02,  6.4524e-03,  2.2001e-02],\n",
      "          [ 1.0177e-02, -4.3029e-03, -2.4499e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.3562e-02, -2.5537e-03, -1.6854e-02],\n",
      "          [-2.7684e-03,  1.9704e-02,  2.4753e-02],\n",
      "          [ 5.9222e-03,  3.5477e-03,  6.1210e-03]],\n",
      "\n",
      "         [[-2.5759e-02,  6.3618e-04,  1.8252e-02],\n",
      "          [ 2.2582e-02,  5.8468e-03,  6.5430e-03],\n",
      "          [ 1.8007e-02, -2.7448e-02,  2.1906e-02]],\n",
      "\n",
      "         [[-1.2664e-02,  2.0285e-03,  8.1927e-03],\n",
      "          [-2.8443e-02,  7.9156e-03,  3.0803e-03],\n",
      "          [ 2.5644e-02,  2.2257e-02,  2.0467e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.2225e-03,  7.8405e-03, -2.9132e-02],\n",
      "          [ 6.2961e-03,  2.5541e-02, -1.3275e-02],\n",
      "          [ 2.4127e-02,  2.5094e-02,  1.3325e-03]],\n",
      "\n",
      "         [[-1.5708e-02, -4.8240e-03,  1.3618e-02],\n",
      "          [-2.4689e-03,  1.7803e-02,  2.3877e-02],\n",
      "          [ 1.5590e-02, -1.6728e-02, -3.6454e-03]],\n",
      "\n",
      "         [[ 4.2964e-03, -3.8619e-03,  7.5149e-03],\n",
      "          [-1.0213e-02, -2.7269e-02,  2.3866e-02],\n",
      "          [ 1.8791e-02,  2.6542e-02, -4.5759e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.3393e-03, -1.5748e-02, -1.7734e-02],\n",
      "          [ 4.8598e-03,  1.0971e-02, -1.2229e-02],\n",
      "          [-9.4835e-04, -1.6583e-02,  7.6148e-03]],\n",
      "\n",
      "         [[ 9.9960e-03, -1.7772e-02, -1.4788e-04],\n",
      "          [-4.1291e-03, -1.0436e-02,  6.8684e-03],\n",
      "          [ 1.2225e-02, -1.1795e-02,  1.8053e-03]],\n",
      "\n",
      "         [[ 1.3352e-02,  1.3022e-02,  7.5648e-03],\n",
      "          [-2.8123e-02,  1.0265e-02,  5.4982e-03],\n",
      "          [-7.7622e-03, -2.5743e-02,  2.1616e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8188e-02, -1.0289e-02,  1.1424e-02],\n",
      "          [-1.5729e-02,  6.3736e-03,  2.3499e-02],\n",
      "          [-1.6413e-02,  1.0413e-02, -1.7818e-02]],\n",
      "\n",
      "         [[-1.9679e-02,  3.2364e-03,  2.1964e-02],\n",
      "          [ 5.9676e-03,  2.8238e-02,  1.5916e-02],\n",
      "          [ 7.7827e-03,  3.2785e-03,  1.6524e-03]],\n",
      "\n",
      "         [[ 1.8017e-04,  6.0900e-03,  9.2327e-04],\n",
      "          [ 7.3568e-03,  5.8688e-03, -4.5835e-03],\n",
      "          [ 2.1282e-02, -2.4150e-02,  2.0233e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5386e-03,  3.4054e-03, -7.4666e-03],\n",
      "          [-1.5904e-02,  2.8922e-02,  3.8439e-03],\n",
      "          [ 1.3385e-02,  6.7120e-03, -1.1052e-02]],\n",
      "\n",
      "         [[ 7.0904e-03, -7.9548e-03,  2.6618e-02],\n",
      "          [-2.1385e-02,  1.4939e-02,  1.5024e-02],\n",
      "          [ 2.2717e-02, -2.5372e-02,  1.4226e-02]],\n",
      "\n",
      "         [[ 3.8951e-03, -2.7941e-02,  1.7312e-02],\n",
      "          [-2.1559e-02, -2.0926e-02, -2.3163e-02],\n",
      "          [-1.9949e-02, -1.7993e-02,  1.8200e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3077e-02, -1.7528e-02,  2.3201e-02],\n",
      "          [-2.4932e-02, -1.2363e-02,  1.4140e-02],\n",
      "          [-1.3637e-02, -1.7312e-03,  2.2195e-02]],\n",
      "\n",
      "         [[-1.3726e-02, -2.6579e-02,  2.9064e-02],\n",
      "          [-2.8486e-02, -7.4418e-03, -4.4726e-03],\n",
      "          [ 4.7910e-03,  2.8021e-03,  1.9021e-02]],\n",
      "\n",
      "         [[-1.0592e-02, -1.4764e-02, -1.9398e-02],\n",
      "          [ 2.0834e-02, -8.3391e-03, -7.0689e-03],\n",
      "          [ 2.8761e-02, -2.6076e-02,  9.6806e-03]]]])\n",
      "Layer: layer2.3.conv1.bias, Biases: tensor([-0.0020,  0.0217, -0.0136,  0.0253, -0.0065, -0.0178, -0.0148, -0.0221,\n",
      "         0.0195,  0.0196,  0.0136, -0.0002, -0.0072, -0.0281, -0.0088, -0.0174,\n",
      "         0.0008,  0.0255,  0.0177, -0.0281, -0.0218, -0.0254,  0.0179, -0.0182,\n",
      "         0.0013, -0.0068, -0.0255,  0.0272,  0.0136, -0.0014, -0.0073, -0.0129,\n",
      "         0.0019,  0.0027, -0.0195, -0.0132, -0.0168,  0.0083,  0.0051,  0.0029,\n",
      "         0.0102, -0.0034,  0.0174, -0.0038,  0.0147, -0.0063,  0.0233,  0.0245,\n",
      "         0.0177, -0.0258, -0.0216,  0.0037, -0.0282, -0.0101, -0.0104,  0.0276,\n",
      "         0.0179, -0.0195, -0.0023, -0.0076, -0.0119, -0.0077, -0.0192,  0.0223])\n",
      "Layer: layer2.3.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer2.3.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer2.3.conv2.weight:, Weights: tensor([[[[-0.0370,  0.0141, -0.0015],\n",
      "          [ 0.0087, -0.0155,  0.0394],\n",
      "          [ 0.0254,  0.0012,  0.0004]],\n",
      "\n",
      "         [[-0.0267,  0.0231, -0.0075],\n",
      "          [-0.0185,  0.0339, -0.0313],\n",
      "          [-0.0193,  0.0104, -0.0271]],\n",
      "\n",
      "         [[ 0.0192,  0.0179,  0.0338],\n",
      "          [ 0.0241, -0.0266,  0.0148],\n",
      "          [-0.0405, -0.0327,  0.0287]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0232, -0.0099,  0.0356],\n",
      "          [-0.0064,  0.0120,  0.0165],\n",
      "          [-0.0176, -0.0132,  0.0047]],\n",
      "\n",
      "         [[ 0.0042, -0.0238,  0.0408],\n",
      "          [ 0.0030,  0.0055, -0.0343],\n",
      "          [-0.0131, -0.0338, -0.0306]],\n",
      "\n",
      "         [[ 0.0368, -0.0040,  0.0350],\n",
      "          [ 0.0297,  0.0368,  0.0244],\n",
      "          [-0.0115, -0.0004, -0.0018]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0089, -0.0337, -0.0227],\n",
      "          [-0.0380, -0.0159, -0.0385],\n",
      "          [-0.0295, -0.0135,  0.0062]],\n",
      "\n",
      "         [[ 0.0231, -0.0173,  0.0183],\n",
      "          [ 0.0053,  0.0405,  0.0117],\n",
      "          [ 0.0064, -0.0037, -0.0166]],\n",
      "\n",
      "         [[ 0.0272, -0.0255,  0.0096],\n",
      "          [-0.0398, -0.0394,  0.0353],\n",
      "          [ 0.0272,  0.0296,  0.0131]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0344, -0.0096, -0.0032],\n",
      "          [ 0.0064,  0.0086, -0.0223],\n",
      "          [ 0.0199, -0.0235,  0.0402]],\n",
      "\n",
      "         [[-0.0376,  0.0372,  0.0115],\n",
      "          [ 0.0161, -0.0053, -0.0383],\n",
      "          [ 0.0284,  0.0017, -0.0197]],\n",
      "\n",
      "         [[ 0.0098, -0.0092,  0.0241],\n",
      "          [ 0.0399, -0.0160,  0.0055],\n",
      "          [-0.0343,  0.0161, -0.0270]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0333, -0.0296,  0.0381],\n",
      "          [-0.0042,  0.0281, -0.0160],\n",
      "          [-0.0210,  0.0183, -0.0128]],\n",
      "\n",
      "         [[ 0.0381,  0.0243, -0.0036],\n",
      "          [-0.0362,  0.0305,  0.0374],\n",
      "          [ 0.0089, -0.0101, -0.0247]],\n",
      "\n",
      "         [[-0.0333, -0.0413,  0.0218],\n",
      "          [-0.0365,  0.0061, -0.0363],\n",
      "          [ 0.0132, -0.0038,  0.0042]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0380,  0.0200, -0.0031],\n",
      "          [-0.0028, -0.0102, -0.0232],\n",
      "          [ 0.0246, -0.0193, -0.0185]],\n",
      "\n",
      "         [[-0.0223, -0.0191,  0.0346],\n",
      "          [ 0.0288, -0.0122,  0.0106],\n",
      "          [-0.0294,  0.0074, -0.0053]],\n",
      "\n",
      "         [[ 0.0138,  0.0273,  0.0320],\n",
      "          [ 0.0002, -0.0339,  0.0223],\n",
      "          [ 0.0262, -0.0105, -0.0391]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0327,  0.0139, -0.0155],\n",
      "          [ 0.0175, -0.0301, -0.0404],\n",
      "          [ 0.0047,  0.0296, -0.0402]],\n",
      "\n",
      "         [[-0.0079, -0.0369, -0.0050],\n",
      "          [-0.0288,  0.0389,  0.0256],\n",
      "          [ 0.0384, -0.0126, -0.0086]],\n",
      "\n",
      "         [[ 0.0191, -0.0391,  0.0402],\n",
      "          [ 0.0391, -0.0165, -0.0163],\n",
      "          [ 0.0285,  0.0055, -0.0314]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0247,  0.0352, -0.0138],\n",
      "          [ 0.0294, -0.0195, -0.0064],\n",
      "          [ 0.0042, -0.0191, -0.0366]],\n",
      "\n",
      "         [[-0.0210,  0.0285, -0.0070],\n",
      "          [ 0.0285, -0.0392,  0.0198],\n",
      "          [-0.0339,  0.0290,  0.0139]],\n",
      "\n",
      "         [[-0.0088, -0.0183, -0.0153],\n",
      "          [ 0.0226,  0.0290,  0.0407],\n",
      "          [-0.0143,  0.0236,  0.0129]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0293,  0.0212, -0.0289],\n",
      "          [ 0.0074, -0.0001, -0.0217],\n",
      "          [-0.0189, -0.0103, -0.0210]],\n",
      "\n",
      "         [[-0.0256,  0.0110, -0.0325],\n",
      "          [ 0.0412, -0.0347,  0.0365],\n",
      "          [-0.0010, -0.0291,  0.0039]],\n",
      "\n",
      "         [[-0.0245,  0.0245, -0.0196],\n",
      "          [ 0.0120, -0.0028,  0.0201],\n",
      "          [-0.0061, -0.0318, -0.0302]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0340, -0.0089,  0.0202],\n",
      "          [ 0.0402,  0.0066,  0.0209],\n",
      "          [-0.0041,  0.0378,  0.0087]],\n",
      "\n",
      "         [[ 0.0007,  0.0190, -0.0143],\n",
      "          [ 0.0110,  0.0264,  0.0164],\n",
      "          [-0.0324, -0.0013,  0.0301]],\n",
      "\n",
      "         [[ 0.0330,  0.0314, -0.0372],\n",
      "          [-0.0167,  0.0140,  0.0321],\n",
      "          [-0.0023, -0.0213,  0.0254]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0391,  0.0321,  0.0069],\n",
      "          [ 0.0362,  0.0152,  0.0372],\n",
      "          [-0.0239,  0.0100, -0.0244]],\n",
      "\n",
      "         [[ 0.0026,  0.0123, -0.0211],\n",
      "          [-0.0267,  0.0063,  0.0212],\n",
      "          [ 0.0007, -0.0015, -0.0361]],\n",
      "\n",
      "         [[ 0.0166,  0.0371,  0.0335],\n",
      "          [-0.0320,  0.0191,  0.0251],\n",
      "          [-0.0361, -0.0086,  0.0040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0007, -0.0086, -0.0027],\n",
      "          [ 0.0206, -0.0375, -0.0088],\n",
      "          [-0.0417,  0.0240, -0.0269]],\n",
      "\n",
      "         [[ 0.0044,  0.0415,  0.0223],\n",
      "          [ 0.0378, -0.0137, -0.0415],\n",
      "          [ 0.0365, -0.0254,  0.0298]],\n",
      "\n",
      "         [[ 0.0290,  0.0203, -0.0075],\n",
      "          [ 0.0187, -0.0388,  0.0116],\n",
      "          [-0.0294, -0.0215,  0.0222]]]])\n",
      "Layer: layer2.3.conv2.bias, Biases: tensor([ 0.0301, -0.0366, -0.0106,  0.0303, -0.0415,  0.0130, -0.0339, -0.0213,\n",
      "        -0.0155, -0.0386, -0.0318, -0.0044,  0.0403,  0.0345,  0.0068, -0.0056,\n",
      "         0.0157, -0.0282, -0.0392, -0.0229, -0.0249, -0.0104, -0.0353,  0.0151,\n",
      "         0.0295, -0.0346, -0.0294,  0.0269,  0.0082,  0.0325, -0.0344,  0.0013,\n",
      "        -0.0361,  0.0219, -0.0096, -0.0360, -0.0107, -0.0068, -0.0015, -0.0044,\n",
      "        -0.0350, -0.0322, -0.0229, -0.0380, -0.0137, -0.0332,  0.0083,  0.0333,\n",
      "         0.0309,  0.0071, -0.0122,  0.0413,  0.0283,  0.0181, -0.0200, -0.0214,\n",
      "         0.0075, -0.0393,  0.0326, -0.0079, -0.0006,  0.0373, -0.0357,  0.0383,\n",
      "         0.0349, -0.0412, -0.0058,  0.0098, -0.0353,  0.0063, -0.0055, -0.0316,\n",
      "         0.0316,  0.0349, -0.0352,  0.0121,  0.0168,  0.0162, -0.0228, -0.0299,\n",
      "         0.0317,  0.0255,  0.0109,  0.0221,  0.0158,  0.0376, -0.0396,  0.0367,\n",
      "         0.0396,  0.0315, -0.0072, -0.0229, -0.0334, -0.0147,  0.0340,  0.0294,\n",
      "        -0.0083,  0.0265, -0.0289,  0.0314, -0.0344,  0.0189, -0.0289, -0.0254,\n",
      "         0.0303,  0.0336,  0.0235,  0.0015,  0.0157, -0.0106,  0.0042,  0.0040,\n",
      "         0.0362, -0.0237, -0.0334, -0.0389,  0.0338,  0.0392,  0.0398, -0.0304,\n",
      "        -0.0096,  0.0393,  0.0363,  0.0363, -0.0218, -0.0328, -0.0256, -0.0089])\n",
      "Layer: layer2.3.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Layer: layer2.3.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.0.conv1.weight:, Weights: tensor([[[[ 0.0137,  0.0284,  0.0016],\n",
      "          [ 0.0139, -0.0078, -0.0194],\n",
      "          [-0.0080, -0.0262,  0.0035]],\n",
      "\n",
      "         [[ 0.0255,  0.0229, -0.0012],\n",
      "          [-0.0229, -0.0139, -0.0282],\n",
      "          [-0.0008,  0.0192, -0.0022]],\n",
      "\n",
      "         [[ 0.0224,  0.0092, -0.0073],\n",
      "          [-0.0264,  0.0132,  0.0073],\n",
      "          [ 0.0225, -0.0050, -0.0175]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0200, -0.0157, -0.0143],\n",
      "          [ 0.0049, -0.0025,  0.0250],\n",
      "          [-0.0283,  0.0110, -0.0058]],\n",
      "\n",
      "         [[ 0.0123,  0.0254, -0.0219],\n",
      "          [-0.0053, -0.0177,  0.0202],\n",
      "          [-0.0227,  0.0158, -0.0041]],\n",
      "\n",
      "         [[-0.0255,  0.0212,  0.0082],\n",
      "          [-0.0121,  0.0108,  0.0186],\n",
      "          [ 0.0281,  0.0089, -0.0068]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0234,  0.0123,  0.0024],\n",
      "          [ 0.0224, -0.0111,  0.0158],\n",
      "          [ 0.0087,  0.0049,  0.0002]],\n",
      "\n",
      "         [[-0.0222,  0.0162,  0.0206],\n",
      "          [-0.0200,  0.0136, -0.0128],\n",
      "          [-0.0166,  0.0200, -0.0272]],\n",
      "\n",
      "         [[-0.0183,  0.0057,  0.0120],\n",
      "          [-0.0145,  0.0254, -0.0187],\n",
      "          [-0.0111, -0.0186,  0.0035]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0044,  0.0237, -0.0050],\n",
      "          [-0.0261, -0.0228, -0.0285],\n",
      "          [-0.0050, -0.0021,  0.0242]],\n",
      "\n",
      "         [[ 0.0279, -0.0204, -0.0074],\n",
      "          [-0.0208, -0.0012,  0.0182],\n",
      "          [ 0.0177,  0.0225,  0.0129]],\n",
      "\n",
      "         [[-0.0083,  0.0165,  0.0039],\n",
      "          [ 0.0158, -0.0018,  0.0174],\n",
      "          [-0.0196,  0.0275, -0.0251]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0066,  0.0215, -0.0215],\n",
      "          [ 0.0207,  0.0090, -0.0104],\n",
      "          [-0.0223,  0.0285, -0.0090]],\n",
      "\n",
      "         [[ 0.0174,  0.0269, -0.0098],\n",
      "          [ 0.0290,  0.0235,  0.0078],\n",
      "          [ 0.0251,  0.0092, -0.0116]],\n",
      "\n",
      "         [[ 0.0144,  0.0279, -0.0249],\n",
      "          [-0.0245, -0.0082, -0.0079],\n",
      "          [-0.0234, -0.0037, -0.0024]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0228,  0.0063,  0.0226],\n",
      "          [-0.0040, -0.0038,  0.0229],\n",
      "          [ 0.0210, -0.0231,  0.0230]],\n",
      "\n",
      "         [[-0.0008, -0.0150,  0.0037],\n",
      "          [ 0.0253, -0.0019, -0.0218],\n",
      "          [ 0.0020,  0.0164, -0.0005]],\n",
      "\n",
      "         [[ 0.0028,  0.0045,  0.0232],\n",
      "          [ 0.0025,  0.0074,  0.0174],\n",
      "          [-0.0230,  0.0064,  0.0045]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0058,  0.0078, -0.0118],\n",
      "          [-0.0270, -0.0129,  0.0247],\n",
      "          [ 0.0248,  0.0114, -0.0026]],\n",
      "\n",
      "         [[-0.0110,  0.0138,  0.0014],\n",
      "          [-0.0057,  0.0014, -0.0047],\n",
      "          [-0.0126,  0.0126, -0.0098]],\n",
      "\n",
      "         [[ 0.0266,  0.0122, -0.0225],\n",
      "          [-0.0061, -0.0135, -0.0140],\n",
      "          [-0.0174,  0.0047,  0.0235]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0157, -0.0232, -0.0242],\n",
      "          [ 0.0205, -0.0283, -0.0289],\n",
      "          [ 0.0212, -0.0140,  0.0031]],\n",
      "\n",
      "         [[-0.0136, -0.0023,  0.0143],\n",
      "          [ 0.0264, -0.0144, -0.0227],\n",
      "          [-0.0081, -0.0104,  0.0147]],\n",
      "\n",
      "         [[ 0.0004,  0.0189,  0.0121],\n",
      "          [-0.0244, -0.0090, -0.0151],\n",
      "          [ 0.0185, -0.0139,  0.0028]]],\n",
      "\n",
      "\n",
      "        [[[-0.0004, -0.0136, -0.0034],\n",
      "          [ 0.0289, -0.0067, -0.0221],\n",
      "          [ 0.0272, -0.0287,  0.0199]],\n",
      "\n",
      "         [[ 0.0135, -0.0201,  0.0005],\n",
      "          [-0.0090,  0.0046, -0.0063],\n",
      "          [ 0.0004,  0.0029, -0.0135]],\n",
      "\n",
      "         [[-0.0081,  0.0243,  0.0049],\n",
      "          [ 0.0074,  0.0286, -0.0082],\n",
      "          [-0.0279, -0.0120, -0.0194]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0171, -0.0201,  0.0127],\n",
      "          [-0.0104, -0.0210, -0.0167],\n",
      "          [-0.0218,  0.0141,  0.0116]],\n",
      "\n",
      "         [[-0.0192, -0.0011,  0.0277],\n",
      "          [-0.0094,  0.0204,  0.0058],\n",
      "          [-0.0003, -0.0282, -0.0091]],\n",
      "\n",
      "         [[-0.0095, -0.0023, -0.0139],\n",
      "          [ 0.0075,  0.0239,  0.0101],\n",
      "          [ 0.0181,  0.0176, -0.0269]]],\n",
      "\n",
      "\n",
      "        [[[-0.0193,  0.0010,  0.0196],\n",
      "          [ 0.0082,  0.0166, -0.0014],\n",
      "          [-0.0169, -0.0250, -0.0039]],\n",
      "\n",
      "         [[-0.0247, -0.0084, -0.0073],\n",
      "          [ 0.0140,  0.0014, -0.0056],\n",
      "          [ 0.0167,  0.0033, -0.0174]],\n",
      "\n",
      "         [[ 0.0191, -0.0084, -0.0108],\n",
      "          [-0.0238,  0.0285,  0.0037],\n",
      "          [-0.0291,  0.0244,  0.0251]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0193, -0.0290,  0.0164],\n",
      "          [-0.0086, -0.0120,  0.0254],\n",
      "          [-0.0080, -0.0246, -0.0086]],\n",
      "\n",
      "         [[ 0.0004,  0.0249,  0.0077],\n",
      "          [-0.0121, -0.0002,  0.0021],\n",
      "          [ 0.0256,  0.0059, -0.0146]],\n",
      "\n",
      "         [[ 0.0223,  0.0103, -0.0007],\n",
      "          [-0.0187, -0.0290,  0.0200],\n",
      "          [-0.0286,  0.0291,  0.0033]]]])\n",
      "Layer: layer3.0.conv1.bias, Biases: tensor([-2.2540e-02,  7.4186e-03, -1.9804e-02, -2.0733e-02, -5.2349e-03,\n",
      "         2.5647e-04,  1.1240e-02,  8.8536e-04,  2.0982e-02,  2.2775e-02,\n",
      "        -2.2517e-02, -3.0045e-03, -2.8390e-02,  2.3618e-03, -1.7681e-02,\n",
      "        -2.1255e-02, -1.3309e-02, -1.8135e-02,  3.7569e-03,  1.7669e-02,\n",
      "         7.9458e-03, -2.2929e-02, -1.0123e-02,  1.1945e-02, -2.5089e-02,\n",
      "        -1.5162e-02, -2.0547e-02, -1.0325e-02, -1.9462e-02,  1.8404e-03,\n",
      "        -2.7762e-02,  2.4424e-02,  2.0204e-02, -1.1384e-02, -1.7111e-02,\n",
      "        -1.7989e-02, -1.4031e-02, -5.5446e-03,  1.8714e-02, -9.6466e-03,\n",
      "         1.0386e-02, -8.9800e-03,  6.4749e-03,  1.3092e-02,  1.8399e-03,\n",
      "         1.5420e-03,  1.9196e-02,  2.5604e-02,  6.1896e-04,  7.4923e-05,\n",
      "         1.5688e-02,  1.1525e-02,  9.0020e-03, -1.5267e-02, -8.8846e-03,\n",
      "        -2.4300e-04, -2.4385e-02,  5.0928e-03, -2.2580e-02,  9.8017e-03,\n",
      "         2.4932e-02,  2.5340e-02,  4.5080e-03, -1.8847e-02, -2.6152e-02,\n",
      "         1.2322e-02, -6.5791e-03,  9.1132e-03,  9.5861e-03,  1.2909e-02,\n",
      "         1.4729e-02, -1.5585e-02, -1.0836e-02, -2.9224e-02, -2.9136e-02,\n",
      "        -1.3788e-02,  1.7589e-02,  2.4596e-05, -1.6314e-02, -9.6749e-03,\n",
      "        -2.8188e-02, -2.0539e-02, -2.2142e-02, -4.9811e-04, -2.0600e-02,\n",
      "         2.9896e-03, -2.8048e-02, -8.6673e-03, -3.5608e-03, -5.0534e-03,\n",
      "        -2.4631e-02, -2.5221e-03, -1.2998e-02, -1.6333e-02, -1.7905e-02,\n",
      "         7.5561e-03,  1.0338e-02,  1.0002e-02,  1.7142e-02, -2.6487e-02,\n",
      "         5.5487e-03, -5.1776e-03, -2.3990e-02, -1.2264e-02,  2.7685e-02,\n",
      "         1.1328e-02, -2.5772e-02, -7.8261e-03,  1.5358e-02, -9.3032e-04,\n",
      "         1.2749e-02,  2.9161e-02,  1.4399e-02,  9.0638e-03, -2.2620e-02,\n",
      "        -2.3852e-02,  1.9214e-02, -2.6547e-02,  2.6845e-02, -2.0322e-02,\n",
      "        -1.6762e-02,  1.5610e-02, -1.9578e-02,  1.5490e-02, -1.1955e-02,\n",
      "        -2.2342e-02, -4.7621e-03,  2.0988e-02])\n",
      "Layer: layer3.0.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Layer: layer3.0.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.0.conv2.weight:, Weights: tensor([[[[-1.5532e-02, -1.9269e-02,  2.7154e-02],\n",
      "          [ 2.4897e-02,  2.2736e-02, -8.1076e-04],\n",
      "          [-1.1905e-02, -2.0192e-02,  1.1421e-03]],\n",
      "\n",
      "         [[-1.7545e-02, -1.9364e-02,  1.1931e-02],\n",
      "          [-4.2821e-03,  2.3717e-02,  2.7601e-02],\n",
      "          [ 1.2134e-02,  7.8802e-03, -2.6081e-02]],\n",
      "\n",
      "         [[ 2.6491e-02,  1.7384e-02, -2.6364e-02],\n",
      "          [-4.2805e-03, -2.5442e-03,  1.8582e-02],\n",
      "          [ 1.6988e-02,  1.0031e-02, -3.3391e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7713e-02,  9.6984e-03,  9.2154e-03],\n",
      "          [ 1.3518e-02, -2.0569e-02,  2.8374e-02],\n",
      "          [-2.5091e-02, -1.0551e-02, -9.0424e-03]],\n",
      "\n",
      "         [[-2.2977e-02, -1.7879e-02,  1.3476e-02],\n",
      "          [-1.1081e-02, -2.7729e-02,  1.5465e-03],\n",
      "          [-6.5969e-03,  2.9248e-02, -8.4042e-03]],\n",
      "\n",
      "         [[-1.6564e-02,  5.3513e-03,  7.9810e-03],\n",
      "          [-2.8209e-02,  5.9657e-03, -2.2858e-02],\n",
      "          [ 1.9148e-02,  1.9253e-02,  9.3539e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8154e-02, -8.8304e-03,  1.4564e-02],\n",
      "          [ 2.4745e-02, -3.9831e-03, -2.9141e-02],\n",
      "          [-2.8443e-02, -2.5926e-02,  2.6848e-02]],\n",
      "\n",
      "         [[-1.2586e-02, -7.3690e-04,  2.2049e-02],\n",
      "          [ 1.4875e-02, -1.0936e-04,  2.0078e-02],\n",
      "          [-2.1819e-02, -1.2242e-03,  7.5595e-03]],\n",
      "\n",
      "         [[ 2.7308e-02, -1.5328e-02, -2.0393e-02],\n",
      "          [-4.1656e-03, -1.4408e-02, -2.2516e-02],\n",
      "          [ 2.6286e-02,  5.4778e-03, -1.4220e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.6076e-03, -8.2518e-03, -2.6217e-02],\n",
      "          [-1.5537e-02, -2.8170e-02, -1.3148e-03],\n",
      "          [-2.4203e-02,  9.0787e-03,  2.4940e-02]],\n",
      "\n",
      "         [[ 2.6849e-02, -2.5922e-02, -1.5133e-02],\n",
      "          [ 2.6565e-02, -2.6579e-02,  2.8041e-02],\n",
      "          [-3.3285e-03,  1.0561e-02, -1.9327e-02]],\n",
      "\n",
      "         [[ 3.6869e-03,  8.2427e-03,  2.8315e-02],\n",
      "          [ 2.4149e-02,  2.4112e-02, -2.0023e-02],\n",
      "          [-7.3944e-03, -2.5580e-02,  1.6174e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.8469e-03, -4.5624e-03, -1.5044e-02],\n",
      "          [-1.6528e-02, -7.2664e-03, -7.1512e-03],\n",
      "          [-2.5862e-02,  6.3106e-03,  2.7545e-02]],\n",
      "\n",
      "         [[ 2.0031e-02,  1.7157e-02, -9.2544e-03],\n",
      "          [-1.5694e-02,  5.4526e-03,  2.1413e-03],\n",
      "          [ 1.0815e-02,  1.1414e-02,  2.5426e-02]],\n",
      "\n",
      "         [[-1.0904e-02, -1.6556e-02,  2.5858e-02],\n",
      "          [-2.0062e-02,  3.9808e-03, -8.6111e-03],\n",
      "          [ 3.5945e-03,  8.2259e-03,  1.2607e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0691e-04, -2.4113e-02, -9.5070e-03],\n",
      "          [-1.3360e-02,  2.1777e-02,  2.7229e-02],\n",
      "          [-2.3073e-02,  1.9349e-02,  1.7635e-02]],\n",
      "\n",
      "         [[-1.7655e-02, -3.5903e-04, -7.8647e-03],\n",
      "          [ 1.3438e-03,  2.4710e-02,  4.8746e-03],\n",
      "          [ 1.2039e-02,  2.7247e-02, -2.7808e-02]],\n",
      "\n",
      "         [[ 1.1237e-02, -8.0599e-03,  1.0914e-02],\n",
      "          [ 2.6133e-02,  1.9611e-02, -7.2628e-03],\n",
      "          [ 1.5695e-02,  2.8075e-02, -1.6638e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.3503e-02,  2.3084e-02, -4.5470e-03],\n",
      "          [ 2.6531e-02, -2.1432e-03, -1.7799e-02],\n",
      "          [-2.3490e-02,  1.9202e-03, -1.0095e-02]],\n",
      "\n",
      "         [[ 2.7528e-02,  1.2425e-02, -1.6433e-02],\n",
      "          [ 2.0372e-02,  2.6030e-02,  1.5266e-02],\n",
      "          [ 2.8830e-02, -4.6833e-03,  1.5417e-03]],\n",
      "\n",
      "         [[-5.5779e-03,  2.4518e-02,  2.6968e-02],\n",
      "          [ 2.5894e-02, -2.4060e-02, -3.1652e-04],\n",
      "          [ 2.7505e-02,  1.2912e-02, -1.9580e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9853e-03, -2.7022e-02, -1.0672e-02],\n",
      "          [ 1.3320e-02,  2.4617e-02,  4.2167e-03],\n",
      "          [-8.2397e-03,  9.2673e-03,  1.8560e-02]],\n",
      "\n",
      "         [[-1.3941e-02,  1.8627e-02,  2.0324e-02],\n",
      "          [ 2.3951e-02,  1.3661e-02,  2.6886e-02],\n",
      "          [-5.4932e-03,  2.0008e-02,  1.2466e-02]],\n",
      "\n",
      "         [[-1.9191e-02, -2.4511e-02, -1.6557e-02],\n",
      "          [-2.7309e-02,  1.4687e-02, -2.3035e-02],\n",
      "          [-4.3928e-03, -1.7951e-02, -7.3626e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0126e-02, -2.7881e-02,  1.2758e-02],\n",
      "          [ 2.5886e-02, -2.3616e-02,  1.6792e-02],\n",
      "          [ 2.6501e-02, -2.5255e-02, -6.8096e-04]],\n",
      "\n",
      "         [[-2.4953e-03, -9.8237e-05, -3.5815e-03],\n",
      "          [-3.4855e-04,  7.8936e-03,  1.9873e-03],\n",
      "          [ 5.7558e-03, -5.7372e-03, -1.0680e-02]],\n",
      "\n",
      "         [[ 2.6538e-02,  8.2040e-03,  2.5467e-02],\n",
      "          [ 2.0172e-02, -2.1508e-02,  2.8987e-02],\n",
      "          [-6.3979e-05, -2.6460e-02, -9.1896e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7789e-02, -1.0631e-02, -6.9061e-03],\n",
      "          [ 2.6370e-02,  2.8765e-02,  1.2674e-02],\n",
      "          [-1.3948e-02,  2.4089e-03,  1.7587e-02]],\n",
      "\n",
      "         [[-1.4610e-02,  1.1659e-02, -2.0322e-02],\n",
      "          [ 1.0657e-02, -1.1120e-02,  2.7630e-02],\n",
      "          [-2.7935e-02, -1.9801e-02, -2.1622e-02]],\n",
      "\n",
      "         [[-2.9647e-03, -2.8184e-02, -2.4754e-02],\n",
      "          [-1.8394e-02,  7.6760e-03, -2.3229e-02],\n",
      "          [ 2.0680e-02,  2.7734e-02, -1.6604e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8302e-03,  1.2807e-02, -5.5737e-03],\n",
      "          [ 1.8360e-02, -1.0656e-02, -2.6267e-02],\n",
      "          [ 2.3922e-02, -4.0698e-03, -1.6562e-02]],\n",
      "\n",
      "         [[ 1.0487e-02, -2.5953e-03,  5.7800e-03],\n",
      "          [-5.4454e-03, -1.9325e-02, -2.5954e-02],\n",
      "          [ 2.2720e-02, -2.5559e-02, -1.4001e-02]],\n",
      "\n",
      "         [[-1.9249e-02, -2.5502e-03, -1.1910e-04],\n",
      "          [ 1.5131e-02,  2.6749e-02,  1.3995e-02],\n",
      "          [-6.0421e-04,  2.1074e-02, -2.4805e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9912e-02, -2.6850e-02,  6.6773e-03],\n",
      "          [ 3.8676e-03,  2.8867e-02,  2.0131e-04],\n",
      "          [-1.3854e-02,  2.9330e-02,  5.6102e-03]],\n",
      "\n",
      "         [[ 8.4879e-03, -2.1809e-02,  2.2768e-02],\n",
      "          [ 2.0614e-02, -1.7655e-02,  8.4401e-03],\n",
      "          [-1.0775e-02, -3.2536e-03, -1.6997e-02]],\n",
      "\n",
      "         [[-2.1070e-02, -2.7720e-04,  1.1697e-02],\n",
      "          [ 1.9867e-02,  4.3623e-03,  1.9955e-02],\n",
      "          [ 8.1409e-03,  1.3514e-02,  2.2014e-03]]]])\n",
      "Layer: layer3.0.conv2.bias, Biases: tensor([-1.0795e-02, -1.5789e-02,  5.0604e-03,  1.9919e-02, -2.1085e-02,\n",
      "        -2.4350e-02, -1.8471e-02, -1.9361e-02, -4.9150e-03,  5.7933e-03,\n",
      "        -1.7008e-02, -1.4466e-04,  2.1971e-02, -2.5761e-02, -8.7527e-03,\n",
      "         1.1313e-02, -2.5178e-02, -1.1374e-03,  9.6093e-03,  2.0583e-03,\n",
      "         2.7963e-02, -9.8707e-03,  5.0329e-03, -1.3336e-02, -1.1020e-02,\n",
      "        -1.2350e-02, -1.9634e-02, -1.0644e-02, -3.7908e-03,  2.4685e-02,\n",
      "        -3.6736e-03,  2.4608e-02, -1.9364e-02, -2.3384e-02,  1.7392e-02,\n",
      "         2.0189e-02,  1.9176e-02, -1.3834e-02, -5.7627e-03, -1.6114e-02,\n",
      "        -1.0612e-02, -1.7915e-02, -4.9209e-03, -7.9053e-03,  1.6967e-02,\n",
      "        -1.2546e-02,  1.5184e-03,  2.4338e-03,  1.1800e-02, -1.2872e-02,\n",
      "        -8.0457e-03,  1.6706e-02,  9.9376e-03, -2.0073e-02, -2.4519e-02,\n",
      "        -2.2346e-02, -1.2096e-02,  1.6849e-02, -1.4092e-02, -1.2411e-02,\n",
      "        -2.4159e-02,  1.7769e-02,  2.8870e-02, -4.9159e-03,  9.6920e-03,\n",
      "        -2.4188e-02, -5.8771e-03, -1.1176e-02,  2.7332e-03, -2.5687e-02,\n",
      "        -2.5938e-02,  9.2847e-03,  1.5617e-02, -1.9180e-04, -1.9194e-02,\n",
      "         5.7286e-03, -2.5106e-03, -1.3852e-02,  2.3754e-02,  5.6436e-03,\n",
      "         4.5838e-03, -3.9631e-03,  1.1184e-03,  2.4201e-02, -1.5560e-02,\n",
      "        -7.3537e-03, -2.8688e-02,  1.8840e-02, -1.0126e-02, -7.7375e-03,\n",
      "        -5.6602e-03, -1.3398e-02,  1.8300e-02, -4.0542e-04,  2.1326e-02,\n",
      "         2.9418e-02,  1.7909e-03, -1.7750e-02, -2.1569e-02, -4.3960e-03,\n",
      "        -5.8500e-03,  1.2754e-02, -1.9346e-02, -1.6217e-02, -2.8629e-02,\n",
      "        -1.8826e-02,  4.0667e-03, -5.5949e-03, -4.3712e-03,  7.1390e-03,\n",
      "         1.1213e-02, -2.3377e-02,  2.0056e-02,  6.9699e-03,  7.0284e-03,\n",
      "        -1.5014e-02,  4.4855e-03,  7.0965e-03,  1.4189e-02, -2.7890e-02,\n",
      "        -3.1919e-03, -4.9439e-04, -1.0088e-02, -2.4642e-02, -1.3180e-02,\n",
      "         1.3463e-02, -2.6603e-02,  2.3779e-02, -6.5619e-03,  2.5854e-02,\n",
      "        -2.6782e-02,  9.0952e-04, -4.0411e-03, -1.3331e-02,  2.2187e-02,\n",
      "         2.0522e-02,  2.0392e-02, -2.5686e-02,  2.8310e-03, -1.4062e-02,\n",
      "         4.0761e-03, -1.4980e-02, -1.2567e-02, -9.2754e-04,  5.1591e-03,\n",
      "        -2.1550e-02, -3.6860e-03, -7.7805e-03, -9.7443e-03, -1.2619e-03,\n",
      "         2.1876e-03,  1.4760e-02,  2.8391e-02, -1.3375e-02,  3.4883e-03,\n",
      "         1.3293e-02, -9.9320e-04, -2.4659e-02,  5.1785e-03,  7.3267e-03,\n",
      "         2.4497e-02,  1.9512e-02,  2.6130e-02, -1.7498e-02, -1.1809e-02,\n",
      "         2.7624e-03, -2.1244e-02,  2.1416e-02,  2.7506e-02,  1.0521e-02,\n",
      "         1.2182e-02, -2.2869e-02, -2.3096e-02,  1.6717e-03,  2.7918e-02,\n",
      "        -2.9044e-02,  1.9171e-02, -1.6179e-02, -6.6715e-03, -1.0281e-02,\n",
      "         1.5069e-02,  1.6771e-02, -2.0396e-03,  7.3157e-04, -7.0042e-03,\n",
      "        -1.5263e-02, -1.0012e-02,  1.2153e-02,  3.7304e-03,  4.5290e-03,\n",
      "        -4.4978e-03,  3.9149e-03,  4.4219e-06,  8.0590e-04,  2.2951e-02,\n",
      "         1.8861e-02,  1.2109e-02, -8.7835e-03, -2.9046e-02,  1.2335e-02,\n",
      "         2.3442e-02,  1.6841e-02,  2.6158e-03, -2.7682e-02,  1.6907e-02,\n",
      "        -1.7389e-02, -1.5558e-02,  2.1827e-02,  2.2961e-02, -1.6151e-03,\n",
      "        -1.7491e-02,  1.9152e-02, -1.8310e-02,  8.3545e-03, -2.4176e-02,\n",
      "         2.3094e-03,  2.0808e-03,  2.2331e-02,  1.5845e-02,  5.1923e-03,\n",
      "         2.0257e-02,  2.3540e-02, -1.6426e-02,  2.1853e-02, -2.6502e-02,\n",
      "        -2.5573e-02,  2.8915e-02, -2.6471e-02, -1.9716e-02, -2.4687e-02,\n",
      "        -7.6392e-03,  5.6582e-03,  6.5767e-03,  6.8829e-03, -1.6524e-02,\n",
      "         6.7890e-03, -1.5785e-02,  1.4101e-02, -3.9364e-03,  2.7605e-03,\n",
      "         2.6791e-02, -2.7401e-02,  1.2731e-02, -1.6481e-04, -6.6876e-03,\n",
      "         1.9726e-02, -2.6985e-02, -1.7788e-02, -6.6663e-04, -3.5577e-03,\n",
      "         2.1282e-02, -2.8492e-02,  1.9341e-02,  2.8458e-02,  1.8850e-02,\n",
      "        -1.5460e-02])\n",
      "Layer: layer3.0.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])\n",
      "Layer: layer3.0.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.0.identity_downsample.0.weight:, Weights: tensor([[[[-0.0547]],\n",
      "\n",
      "         [[ 0.0872]],\n",
      "\n",
      "         [[-0.0796]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0783]],\n",
      "\n",
      "         [[ 0.0554]],\n",
      "\n",
      "         [[-0.0412]]],\n",
      "\n",
      "\n",
      "        [[[-0.0590]],\n",
      "\n",
      "         [[-0.0178]],\n",
      "\n",
      "         [[ 0.0753]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0164]],\n",
      "\n",
      "         [[ 0.0313]],\n",
      "\n",
      "         [[-0.0582]]],\n",
      "\n",
      "\n",
      "        [[[-0.0159]],\n",
      "\n",
      "         [[-0.0638]],\n",
      "\n",
      "         [[-0.0181]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0198]],\n",
      "\n",
      "         [[ 0.0542]],\n",
      "\n",
      "         [[ 0.0733]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0439]],\n",
      "\n",
      "         [[-0.0148]],\n",
      "\n",
      "         [[-0.0566]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0156]],\n",
      "\n",
      "         [[-0.0387]],\n",
      "\n",
      "         [[ 0.0552]]],\n",
      "\n",
      "\n",
      "        [[[-0.0036]],\n",
      "\n",
      "         [[ 0.0003]],\n",
      "\n",
      "         [[ 0.0149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0219]],\n",
      "\n",
      "         [[ 0.0079]],\n",
      "\n",
      "         [[ 0.0470]]],\n",
      "\n",
      "\n",
      "        [[[-0.0099]],\n",
      "\n",
      "         [[-0.0771]],\n",
      "\n",
      "         [[-0.0803]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0623]],\n",
      "\n",
      "         [[ 0.0828]],\n",
      "\n",
      "         [[-0.0527]]]])\n",
      "Layer: layer3.0.identity_downsample.0.bias, Biases: tensor([ 0.0515, -0.0789,  0.0588,  0.0696, -0.0129,  0.0346, -0.0688,  0.0700,\n",
      "         0.0459, -0.0777, -0.0647,  0.0371, -0.0607,  0.0590,  0.0730, -0.0619,\n",
      "        -0.0683,  0.0656,  0.0541,  0.0773,  0.0289,  0.0796, -0.0093, -0.0189,\n",
      "        -0.0883,  0.0224,  0.0201,  0.0257,  0.0197, -0.0203, -0.0245,  0.0003,\n",
      "        -0.0567, -0.0334, -0.0353,  0.0032,  0.0789,  0.0423, -0.0723,  0.0326,\n",
      "         0.0779, -0.0328, -0.0604, -0.0441,  0.0462,  0.0457,  0.0576, -0.0430,\n",
      "         0.0740,  0.0805,  0.0369,  0.0380,  0.0722, -0.0745, -0.0083, -0.0258,\n",
      "         0.0579,  0.0368,  0.0879,  0.0525, -0.0490,  0.0876, -0.0170,  0.0857,\n",
      "        -0.0857,  0.0818,  0.0632, -0.0257,  0.0166, -0.0349,  0.0589, -0.0147,\n",
      "        -0.0490, -0.0210,  0.0103, -0.0234,  0.0461,  0.0390, -0.0865, -0.0660,\n",
      "         0.0322, -0.0206, -0.0328, -0.0324,  0.0402, -0.0541, -0.0662, -0.0727,\n",
      "         0.0303, -0.0752,  0.0763,  0.0155,  0.0349, -0.0311, -0.0299,  0.0585,\n",
      "        -0.0596,  0.0437,  0.0431,  0.0579, -0.0376,  0.0251,  0.0217,  0.0321,\n",
      "         0.0285,  0.0006, -0.0474, -0.0295, -0.0361, -0.0733,  0.0692,  0.0241,\n",
      "        -0.0805,  0.0797, -0.0200,  0.0083, -0.0192, -0.0597,  0.0002,  0.0363,\n",
      "        -0.0819,  0.0620, -0.0529,  0.0138,  0.0449,  0.0537, -0.0378,  0.0844,\n",
      "        -0.0135,  0.0550, -0.0651, -0.0809, -0.0228, -0.0030, -0.0559,  0.0877,\n",
      "         0.0317, -0.0134, -0.0035,  0.0062,  0.0143,  0.0152, -0.0128,  0.0469,\n",
      "        -0.0755,  0.0007, -0.0670,  0.0096, -0.0741,  0.0437, -0.0641,  0.0621,\n",
      "        -0.0649,  0.0618,  0.0009, -0.0720, -0.0149, -0.0159, -0.0818,  0.0869,\n",
      "         0.0658,  0.0228, -0.0386, -0.0576,  0.0556, -0.0765,  0.0318, -0.0490,\n",
      "         0.0467, -0.0047, -0.0473,  0.0767,  0.0386,  0.0814,  0.0007, -0.0778,\n",
      "        -0.0489,  0.0312, -0.0744,  0.0178,  0.0045, -0.0087,  0.0292, -0.0285,\n",
      "         0.0548, -0.0520,  0.0835, -0.0193, -0.0406, -0.0025, -0.0786, -0.0824,\n",
      "        -0.0500,  0.0018, -0.0543,  0.0198, -0.0242,  0.0596, -0.0423,  0.0234,\n",
      "        -0.0578,  0.0846,  0.0021,  0.0081, -0.0629,  0.0174,  0.0655,  0.0881,\n",
      "         0.0312,  0.0571,  0.0527,  0.0743,  0.0583, -0.0248,  0.0033,  0.0330,\n",
      "        -0.0028, -0.0835,  0.0651,  0.0086,  0.0322,  0.0171, -0.0517, -0.0462,\n",
      "         0.0409, -0.0311, -0.0527,  0.0200,  0.0366,  0.0384,  0.0326,  0.0340,\n",
      "        -0.0493, -0.0563, -0.0345, -0.0758, -0.0809,  0.0829, -0.0201,  0.0648,\n",
      "         0.0702,  0.0616,  0.0522, -0.0641,  0.0738,  0.0432,  0.0824, -0.0840,\n",
      "         0.0540, -0.0724, -0.0680, -0.0315, -0.0285, -0.0629, -0.0242, -0.0433])\n",
      "Layer: layer3.0.identity_downsample.1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])\n",
      "Layer: layer3.0.identity_downsample.1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.1.conv1.weight:, Weights: tensor([[[[ 9.9351e-03, -3.7716e-03,  1.9866e-02],\n",
      "          [-1.2225e-02,  1.2127e-02, -2.3928e-03],\n",
      "          [ 1.0920e-02,  1.2205e-02, -2.0011e-03]],\n",
      "\n",
      "         [[-2.0529e-02,  1.6177e-03,  1.3254e-03],\n",
      "          [ 1.7388e-02,  1.2102e-02,  1.5683e-02],\n",
      "          [-2.0782e-03, -7.2013e-03, -1.8678e-02]],\n",
      "\n",
      "         [[ 7.2290e-03, -1.5581e-02,  8.9036e-03],\n",
      "          [-1.8923e-02, -4.8745e-03, -8.7770e-03],\n",
      "          [-1.0515e-02, -7.8245e-03,  1.5724e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2538e-02, -1.4725e-02,  8.9474e-03],\n",
      "          [ 6.5754e-03, -1.5388e-02,  1.0238e-02],\n",
      "          [-9.1744e-03, -7.1916e-03, -2.8732e-03]],\n",
      "\n",
      "         [[ 1.2918e-02,  4.1647e-03,  6.0128e-03],\n",
      "          [-1.4792e-02,  4.9538e-03,  1.0645e-02],\n",
      "          [-8.0993e-03, -1.4094e-02, -1.7856e-02]],\n",
      "\n",
      "         [[-3.1767e-03, -4.9097e-03,  8.8398e-03],\n",
      "          [ 1.7119e-02, -1.6131e-02,  1.6226e-03],\n",
      "          [ 1.6346e-02, -7.2330e-03, -5.6847e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9730e-03,  1.4804e-02, -1.6585e-02],\n",
      "          [ 1.3522e-02, -2.0619e-02,  7.1527e-03],\n",
      "          [-3.7878e-03, -7.2188e-03, -5.2877e-04]],\n",
      "\n",
      "         [[ 1.1449e-02, -8.2514e-03, -1.1683e-02],\n",
      "          [-1.3766e-02,  1.8837e-02,  9.3011e-03],\n",
      "          [ 8.2152e-03,  1.9021e-02, -6.9114e-03]],\n",
      "\n",
      "         [[ 1.7899e-02,  1.7496e-02,  1.3023e-02],\n",
      "          [-5.9439e-03, -8.9773e-04,  6.1493e-03],\n",
      "          [-3.2017e-04, -6.4149e-03,  2.4974e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8626e-02, -1.9663e-02,  1.4611e-02],\n",
      "          [-7.8401e-03, -1.6704e-02, -1.1157e-02],\n",
      "          [-1.3541e-02,  8.7638e-03,  1.5368e-02]],\n",
      "\n",
      "         [[-1.7075e-02, -1.5318e-02,  9.2070e-03],\n",
      "          [ 2.0475e-02, -1.7962e-02,  5.2902e-03],\n",
      "          [ 1.1441e-02,  1.2580e-02, -1.3797e-02]],\n",
      "\n",
      "         [[ 8.1132e-03, -1.2801e-02,  4.3613e-03],\n",
      "          [ 8.3063e-03,  1.1835e-02,  1.0873e-02],\n",
      "          [ 1.2297e-02, -1.8479e-02, -4.7746e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.2023e-02, -5.3185e-03,  1.3964e-02],\n",
      "          [ 4.0413e-03, -1.1695e-02, -2.0234e-02],\n",
      "          [-2.0197e-02, -1.9527e-02,  7.8383e-03]],\n",
      "\n",
      "         [[-5.0871e-03, -1.1462e-02, -1.6944e-02],\n",
      "          [ 1.7076e-02,  3.2562e-03, -1.2617e-02],\n",
      "          [-1.6592e-02,  1.1499e-02, -1.0189e-02]],\n",
      "\n",
      "         [[ 1.0197e-02, -1.1482e-02, -1.8238e-02],\n",
      "          [-5.3131e-03,  1.6422e-02,  3.1155e-03],\n",
      "          [-1.3848e-02, -1.1727e-02, -3.5732e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7802e-02,  8.0175e-03,  1.3571e-02],\n",
      "          [ 1.3754e-02,  1.9024e-02,  5.6709e-03],\n",
      "          [ 1.4323e-02,  5.0298e-04, -4.1586e-03]],\n",
      "\n",
      "         [[-1.8091e-02,  6.0347e-03, -1.6780e-03],\n",
      "          [ 3.2797e-03, -9.9462e-03, -1.0886e-02],\n",
      "          [-1.2383e-02, -1.1155e-03, -2.4602e-03]],\n",
      "\n",
      "         [[-1.6599e-02,  8.8754e-03, -4.6106e-03],\n",
      "          [ 8.7335e-03, -1.8793e-02,  1.2812e-02],\n",
      "          [-1.2220e-02, -1.3255e-02, -9.4842e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2569e-02,  5.5358e-03,  5.6601e-03],\n",
      "          [ 8.5148e-03, -2.0807e-02,  2.0518e-02],\n",
      "          [ 9.5121e-03,  1.1998e-02, -4.6134e-03]],\n",
      "\n",
      "         [[ 1.4284e-02, -1.7834e-02, -6.9189e-03],\n",
      "          [ 1.0716e-02,  1.6098e-02, -1.8523e-02],\n",
      "          [-1.9185e-02, -3.5198e-04,  3.8199e-04]],\n",
      "\n",
      "         [[-6.1241e-03, -7.8173e-04, -4.4526e-03],\n",
      "          [ 6.0847e-03,  4.1667e-03, -7.8457e-03],\n",
      "          [-1.4150e-03,  1.3785e-02, -1.6487e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7761e-02, -1.4509e-02,  4.7810e-03],\n",
      "          [ 9.7269e-03, -9.8474e-03, -4.3891e-03],\n",
      "          [ 1.2362e-02,  1.9566e-02,  1.4085e-02]],\n",
      "\n",
      "         [[ 1.3975e-03, -1.2057e-03, -1.1848e-02],\n",
      "          [-4.9600e-03,  1.3528e-02, -9.8596e-03],\n",
      "          [-1.0293e-02,  9.1150e-03, -1.9574e-02]],\n",
      "\n",
      "         [[-1.8410e-02, -1.2614e-02,  1.3534e-02],\n",
      "          [ 1.3171e-02, -1.8764e-02, -1.9822e-02],\n",
      "          [-2.0509e-02, -1.3237e-02, -4.8276e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.2949e-02, -5.0234e-03, -2.8775e-03],\n",
      "          [-1.4149e-02,  5.2939e-03,  1.6366e-02],\n",
      "          [ 7.4202e-03, -1.6489e-02,  1.3764e-02]],\n",
      "\n",
      "         [[ 1.2971e-02,  4.3796e-03,  1.1064e-02],\n",
      "          [ 6.3540e-03,  1.8299e-02, -4.9068e-03],\n",
      "          [ 2.4967e-03, -8.9766e-03, -4.4293e-03]],\n",
      "\n",
      "         [[-1.2537e-02, -2.6949e-03, -3.2997e-03],\n",
      "          [-1.2353e-02, -1.5908e-02,  6.8428e-04],\n",
      "          [-7.0143e-03,  8.2176e-03,  1.6304e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.0366e-03,  7.4790e-03, -8.4361e-03],\n",
      "          [-4.3285e-05, -5.7272e-03,  1.4838e-02],\n",
      "          [ 1.5381e-02,  7.7671e-03, -2.0083e-02]],\n",
      "\n",
      "         [[-4.6507e-04, -9.7169e-03, -1.6006e-03],\n",
      "          [-1.8065e-02, -5.5729e-03,  4.0211e-03],\n",
      "          [ 3.5799e-03,  6.5812e-03,  1.2256e-02]],\n",
      "\n",
      "         [[ 5.3204e-03, -4.0080e-03,  1.5157e-02],\n",
      "          [-9.6297e-03,  1.1511e-02,  1.8256e-02],\n",
      "          [ 1.9406e-02, -4.9658e-03, -3.3192e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6443e-02,  7.6560e-03, -1.3375e-02],\n",
      "          [ 6.0934e-03, -1.5711e-02,  1.4948e-02],\n",
      "          [-4.3470e-03,  1.8902e-02,  8.7264e-03]],\n",
      "\n",
      "         [[ 2.0508e-02, -1.5758e-02,  1.3024e-02],\n",
      "          [-1.9662e-02,  5.8306e-03, -1.4153e-02],\n",
      "          [-1.8825e-02, -3.8156e-03,  8.3575e-03]],\n",
      "\n",
      "         [[-3.4448e-03,  4.2969e-03, -1.3750e-02],\n",
      "          [-2.2580e-03, -5.0897e-03,  4.5673e-03],\n",
      "          [ 1.3981e-02, -1.3180e-02, -7.0648e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9180e-02, -1.0996e-02, -1.0672e-02],\n",
      "          [-1.7679e-02, -9.3632e-03, -9.4273e-03],\n",
      "          [-9.6552e-03,  1.7403e-02,  1.8394e-02]],\n",
      "\n",
      "         [[-6.8267e-03, -2.0143e-02, -1.3599e-02],\n",
      "          [ 9.3211e-03, -2.5601e-03, -1.6426e-02],\n",
      "          [ 1.8429e-03,  1.2563e-02, -1.0879e-02]],\n",
      "\n",
      "         [[ 9.6443e-04,  8.8796e-03,  1.8824e-02],\n",
      "          [ 9.4911e-03, -1.6199e-02, -1.3106e-02],\n",
      "          [ 1.2771e-02, -1.5067e-02,  1.3194e-02]]]])\n",
      "Layer: layer3.1.conv1.bias, Biases: tensor([-0.0010,  0.0145, -0.0120,  0.0101, -0.0106,  0.0061,  0.0147,  0.0139,\n",
      "        -0.0136,  0.0132,  0.0019, -0.0178,  0.0131, -0.0060, -0.0026,  0.0073,\n",
      "        -0.0137, -0.0149,  0.0007, -0.0151,  0.0068,  0.0073,  0.0029, -0.0137,\n",
      "        -0.0065, -0.0023, -0.0057,  0.0066, -0.0158, -0.0167,  0.0043, -0.0033,\n",
      "        -0.0160, -0.0164,  0.0169, -0.0178,  0.0107,  0.0091,  0.0200, -0.0007,\n",
      "         0.0035, -0.0040, -0.0103,  0.0097, -0.0103,  0.0056, -0.0189,  0.0124,\n",
      "         0.0056,  0.0124, -0.0101, -0.0042, -0.0106,  0.0067, -0.0022,  0.0023,\n",
      "         0.0184, -0.0057,  0.0059,  0.0207,  0.0083, -0.0116,  0.0172, -0.0111,\n",
      "        -0.0084,  0.0147,  0.0071,  0.0171, -0.0076, -0.0002, -0.0018, -0.0087,\n",
      "        -0.0206,  0.0046, -0.0082,  0.0048, -0.0205,  0.0019,  0.0150, -0.0116,\n",
      "        -0.0179,  0.0117, -0.0119, -0.0033, -0.0183, -0.0164, -0.0079, -0.0151,\n",
      "         0.0086,  0.0049, -0.0092, -0.0198, -0.0187,  0.0155, -0.0152, -0.0150,\n",
      "        -0.0167, -0.0109, -0.0005,  0.0021, -0.0042,  0.0149, -0.0141,  0.0190,\n",
      "        -0.0015,  0.0173, -0.0040,  0.0172, -0.0208, -0.0111,  0.0104, -0.0095,\n",
      "        -0.0119, -0.0142, -0.0011, -0.0012, -0.0017,  0.0019, -0.0179, -0.0082,\n",
      "        -0.0018,  0.0131,  0.0017,  0.0201,  0.0082, -0.0148,  0.0207,  0.0066])\n",
      "Layer: layer3.1.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Layer: layer3.1.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.1.conv2.weight:, Weights: tensor([[[[ 1.2329e-02,  2.6479e-02,  1.1824e-02],\n",
      "          [ 1.7613e-02,  1.1362e-02,  1.2945e-02],\n",
      "          [ 1.5941e-02,  2.6185e-02,  2.2931e-02]],\n",
      "\n",
      "         [[-1.4622e-02,  1.0709e-02,  1.5473e-02],\n",
      "          [ 2.9307e-03, -2.4225e-02, -1.8272e-02],\n",
      "          [-1.4399e-02,  1.4386e-02, -2.6801e-02]],\n",
      "\n",
      "         [[-1.4399e-02, -2.6767e-02,  2.2452e-02],\n",
      "          [ 1.8057e-02,  1.3336e-02,  2.4965e-02],\n",
      "          [ 2.1227e-02, -2.4830e-02,  1.1684e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3387e-02, -1.9709e-02, -1.6651e-03],\n",
      "          [ 2.4305e-02,  1.9674e-02,  2.6353e-02],\n",
      "          [-2.8443e-02,  2.5624e-02, -1.6589e-02]],\n",
      "\n",
      "         [[ 1.7848e-02, -2.2858e-02, -1.2552e-02],\n",
      "          [ 1.2796e-02, -1.4672e-03,  4.7631e-03],\n",
      "          [ 1.8446e-02, -2.1272e-02, -1.9396e-02]],\n",
      "\n",
      "         [[ 3.2037e-03,  2.6741e-02,  1.0572e-02],\n",
      "          [ 2.0528e-03,  1.9152e-02, -2.1672e-02],\n",
      "          [-1.7547e-02,  1.1895e-02,  2.4159e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3126e-02, -8.8779e-05, -1.1336e-02],\n",
      "          [-1.8522e-02, -1.5518e-02, -2.4022e-03],\n",
      "          [-2.3697e-03, -1.3215e-02, -2.6945e-02]],\n",
      "\n",
      "         [[ 1.7926e-02,  2.7913e-02,  1.7259e-02],\n",
      "          [-5.4931e-03, -2.0931e-02,  1.5209e-02],\n",
      "          [-1.3267e-02,  2.7174e-02, -8.1499e-03]],\n",
      "\n",
      "         [[ 9.7360e-04,  1.1660e-02, -1.1087e-02],\n",
      "          [-2.6598e-02, -1.9117e-02,  1.5153e-02],\n",
      "          [-9.9648e-03,  2.7165e-02, -1.7708e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0530e-02, -2.5871e-03,  1.0399e-02],\n",
      "          [-1.3144e-02,  8.0028e-03, -1.9138e-02],\n",
      "          [-1.8252e-02, -1.7637e-03, -2.7037e-02]],\n",
      "\n",
      "         [[-7.8566e-03,  4.5231e-04,  1.8529e-02],\n",
      "          [-1.7527e-02, -2.6176e-02, -2.2360e-03],\n",
      "          [ 2.5317e-04,  9.6313e-03,  8.3075e-03]],\n",
      "\n",
      "         [[-2.6056e-02, -2.8696e-02, -1.7246e-02],\n",
      "          [-1.6312e-02, -2.6763e-02, -1.7977e-02],\n",
      "          [-2.2615e-02,  2.2841e-02,  1.1785e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2538e-03, -1.9282e-02, -8.4942e-03],\n",
      "          [ 2.5184e-02,  2.1919e-02,  2.6224e-02],\n",
      "          [ 2.0835e-02, -2.4733e-02,  3.0315e-03]],\n",
      "\n",
      "         [[-9.4474e-03, -1.2614e-02,  2.8463e-02],\n",
      "          [ 1.5445e-02, -1.6506e-02,  5.5567e-03],\n",
      "          [-1.7784e-02, -2.3717e-02,  1.1010e-02]],\n",
      "\n",
      "         [[ 1.2105e-02, -1.0369e-02,  2.7796e-02],\n",
      "          [-3.6628e-03,  2.4749e-02,  1.3795e-02],\n",
      "          [-2.6881e-02,  3.3327e-03,  1.4576e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.1162e-04, -2.2213e-02,  6.6470e-03],\n",
      "          [-7.6842e-03, -1.2214e-02,  2.3933e-02],\n",
      "          [ 2.1643e-02, -1.8445e-03, -1.0946e-03]],\n",
      "\n",
      "         [[ 1.9796e-02, -1.8659e-02, -1.6667e-02],\n",
      "          [-1.7571e-02,  2.8853e-02,  1.3547e-02],\n",
      "          [ 2.2355e-02, -2.7071e-02, -2.4730e-02]],\n",
      "\n",
      "         [[-2.0865e-02, -1.2411e-02, -2.1350e-02],\n",
      "          [-2.2959e-02,  4.6802e-03,  1.1998e-02],\n",
      "          [-2.5742e-02,  2.2052e-02, -2.3151e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.8635e-04,  1.2174e-02,  6.8067e-03],\n",
      "          [-1.3844e-02,  5.3731e-04, -2.2740e-02],\n",
      "          [ 5.5589e-03, -8.0207e-03, -6.9512e-03]],\n",
      "\n",
      "         [[ 9.8815e-03, -7.2399e-03, -2.7986e-02],\n",
      "          [ 2.7120e-02,  2.9408e-02, -2.7354e-02],\n",
      "          [-9.2107e-04,  1.1149e-02,  4.5733e-03]],\n",
      "\n",
      "         [[ 2.9217e-02,  1.8748e-02,  6.4419e-03],\n",
      "          [ 2.8769e-02,  1.6387e-02, -2.5757e-02],\n",
      "          [ 7.0122e-03,  2.4943e-02,  2.2093e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7951e-02,  2.7724e-02,  2.3641e-02],\n",
      "          [ 2.5535e-02,  2.8002e-02,  9.1293e-04],\n",
      "          [ 1.1726e-03, -2.0949e-02, -3.0826e-03]],\n",
      "\n",
      "         [[-2.3031e-02, -1.9907e-02, -1.4334e-03],\n",
      "          [ 4.7443e-03, -9.8311e-05, -4.4937e-03],\n",
      "          [ 8.0692e-03,  3.6730e-03, -2.7121e-02]],\n",
      "\n",
      "         [[-2.4190e-03, -1.9422e-02,  2.5260e-02],\n",
      "          [ 2.3052e-03,  2.6989e-02, -2.5668e-02],\n",
      "          [-1.4494e-02,  6.0867e-03, -1.7946e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2722e-02,  1.7244e-02,  1.5630e-03],\n",
      "          [-1.0458e-02,  1.2290e-02,  2.8388e-02],\n",
      "          [ 2.5871e-02,  2.6386e-02, -9.0946e-03]],\n",
      "\n",
      "         [[ 1.3570e-03, -9.7891e-03, -1.5751e-02],\n",
      "          [ 2.9278e-02, -2.9174e-02, -1.7265e-02],\n",
      "          [ 2.1101e-02, -2.6670e-03,  1.3142e-02]],\n",
      "\n",
      "         [[-1.6462e-02, -2.2888e-02, -2.0526e-02],\n",
      "          [ 2.7050e-02,  2.8361e-02,  5.0910e-03],\n",
      "          [-1.3110e-02,  2.7026e-02,  2.8359e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8320e-03,  3.1060e-03, -8.5030e-03],\n",
      "          [ 1.1641e-02, -1.3162e-02, -1.1112e-02],\n",
      "          [ 1.6548e-02, -1.9520e-02,  1.1260e-02]],\n",
      "\n",
      "         [[-1.3899e-02, -1.0839e-02,  2.8175e-02],\n",
      "          [-8.0173e-03,  1.0189e-03, -4.7195e-03],\n",
      "          [-7.5809e-03, -2.2136e-02,  6.8631e-03]],\n",
      "\n",
      "         [[ 5.8066e-03, -1.2333e-02,  1.2055e-02],\n",
      "          [-2.9889e-03, -7.2394e-03, -1.8212e-02],\n",
      "          [ 2.0297e-02, -2.0214e-02,  1.8573e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6018e-02, -2.0480e-02,  2.2190e-02],\n",
      "          [ 1.2426e-02,  2.2192e-02, -5.2078e-03],\n",
      "          [-9.0371e-03,  2.9224e-04,  1.9001e-02]],\n",
      "\n",
      "         [[ 2.0748e-02,  4.6041e-03,  1.4420e-03],\n",
      "          [ 2.4198e-02,  1.9866e-02,  2.0491e-02],\n",
      "          [ 1.7113e-02, -4.6614e-03, -1.6609e-02]],\n",
      "\n",
      "         [[ 1.4480e-02, -2.6132e-02, -2.8947e-02],\n",
      "          [ 7.1792e-03,  1.9259e-02, -2.5279e-02],\n",
      "          [-2.2613e-02,  6.9628e-03,  1.6291e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4497e-02, -2.1105e-03, -5.4414e-03],\n",
      "          [-1.1882e-02, -7.6717e-03,  1.9015e-02],\n",
      "          [-2.5371e-02, -1.1773e-02,  4.9401e-03]],\n",
      "\n",
      "         [[-9.5693e-03,  5.7185e-04,  1.6391e-02],\n",
      "          [-3.1012e-03, -2.6452e-02, -1.7835e-02],\n",
      "          [-1.0282e-02, -1.3504e-02, -1.7664e-03]],\n",
      "\n",
      "         [[ 1.5474e-02,  2.6823e-02,  7.6922e-03],\n",
      "          [ 7.5207e-03, -9.1352e-03, -1.0608e-02],\n",
      "          [ 2.5509e-02, -9.8798e-03,  5.4286e-03]]]])\n",
      "Layer: layer3.1.conv2.bias, Biases: tensor([ 0.0238,  0.0146,  0.0002, -0.0090,  0.0061, -0.0054,  0.0174, -0.0035,\n",
      "         0.0108,  0.0110,  0.0072, -0.0010,  0.0201, -0.0265,  0.0133,  0.0204,\n",
      "        -0.0131, -0.0249,  0.0011, -0.0085,  0.0278, -0.0267, -0.0277,  0.0019,\n",
      "         0.0275,  0.0057,  0.0161,  0.0080, -0.0051,  0.0153, -0.0232,  0.0023,\n",
      "        -0.0218, -0.0211, -0.0095,  0.0146,  0.0198,  0.0089, -0.0091,  0.0057,\n",
      "        -0.0227,  0.0178, -0.0074, -0.0266, -0.0191, -0.0118,  0.0198,  0.0020,\n",
      "         0.0211,  0.0218, -0.0111, -0.0127, -0.0247,  0.0243,  0.0031, -0.0177,\n",
      "        -0.0038,  0.0222,  0.0030, -0.0179,  0.0208,  0.0196,  0.0249, -0.0136,\n",
      "         0.0103, -0.0224, -0.0075,  0.0111, -0.0063,  0.0284, -0.0158, -0.0132,\n",
      "         0.0066,  0.0276, -0.0214, -0.0062,  0.0133, -0.0120, -0.0191, -0.0284,\n",
      "         0.0045, -0.0037,  0.0271, -0.0234,  0.0105,  0.0154,  0.0130,  0.0097,\n",
      "         0.0043,  0.0100, -0.0185,  0.0005, -0.0212,  0.0033,  0.0171, -0.0125,\n",
      "        -0.0233, -0.0215, -0.0201, -0.0071, -0.0236,  0.0140, -0.0280,  0.0111,\n",
      "        -0.0091,  0.0128, -0.0073,  0.0117, -0.0110, -0.0168,  0.0061,  0.0200,\n",
      "        -0.0224,  0.0228,  0.0107,  0.0045,  0.0148,  0.0193, -0.0041, -0.0223,\n",
      "         0.0259, -0.0219,  0.0103, -0.0028, -0.0249,  0.0059, -0.0153, -0.0035,\n",
      "         0.0189,  0.0005, -0.0134, -0.0246,  0.0137,  0.0174,  0.0001, -0.0278,\n",
      "         0.0285, -0.0170,  0.0008, -0.0017,  0.0119,  0.0284,  0.0129, -0.0141,\n",
      "         0.0079, -0.0061,  0.0290,  0.0099,  0.0054,  0.0109,  0.0274,  0.0208,\n",
      "        -0.0079, -0.0264,  0.0290,  0.0294,  0.0007, -0.0184, -0.0139, -0.0274,\n",
      "        -0.0239, -0.0108,  0.0209, -0.0250, -0.0065, -0.0069,  0.0044, -0.0004,\n",
      "         0.0052, -0.0109,  0.0274,  0.0133, -0.0167, -0.0208,  0.0125, -0.0162,\n",
      "        -0.0292,  0.0271,  0.0253,  0.0180, -0.0263,  0.0157, -0.0022, -0.0001,\n",
      "        -0.0041, -0.0171,  0.0035, -0.0262,  0.0091, -0.0092,  0.0070, -0.0157,\n",
      "        -0.0008, -0.0096, -0.0014, -0.0008,  0.0121, -0.0020, -0.0017,  0.0190,\n",
      "         0.0291, -0.0237, -0.0030, -0.0143,  0.0271,  0.0294,  0.0050,  0.0141,\n",
      "        -0.0042, -0.0212,  0.0021, -0.0120,  0.0126, -0.0163, -0.0264, -0.0172,\n",
      "        -0.0238, -0.0183, -0.0268, -0.0105,  0.0221,  0.0047,  0.0145,  0.0127,\n",
      "         0.0034, -0.0191,  0.0149, -0.0151,  0.0065,  0.0007, -0.0240, -0.0112,\n",
      "         0.0269, -0.0085,  0.0197,  0.0204, -0.0231,  0.0026, -0.0143, -0.0212,\n",
      "        -0.0237,  0.0209, -0.0033, -0.0143, -0.0290, -0.0224, -0.0218,  0.0268,\n",
      "        -0.0080,  0.0286, -0.0007, -0.0054,  0.0057,  0.0051, -0.0171, -0.0040])\n",
      "Layer: layer3.1.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])\n",
      "Layer: layer3.1.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.2.conv1.weight:, Weights: tensor([[[[ 0.0038,  0.0123, -0.0093],\n",
      "          [ 0.0190,  0.0186, -0.0151],\n",
      "          [ 0.0124, -0.0175, -0.0017]],\n",
      "\n",
      "         [[ 0.0091,  0.0070, -0.0086],\n",
      "          [-0.0036,  0.0131,  0.0051],\n",
      "          [-0.0168, -0.0199, -0.0127]],\n",
      "\n",
      "         [[-0.0067,  0.0178, -0.0095],\n",
      "          [-0.0076,  0.0115, -0.0013],\n",
      "          [-0.0020, -0.0025,  0.0207]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0052, -0.0056,  0.0031],\n",
      "          [ 0.0023, -0.0012, -0.0051],\n",
      "          [-0.0167, -0.0140,  0.0156]],\n",
      "\n",
      "         [[ 0.0138,  0.0079, -0.0198],\n",
      "          [-0.0052,  0.0065, -0.0132],\n",
      "          [ 0.0079, -0.0188,  0.0106]],\n",
      "\n",
      "         [[-0.0130,  0.0059,  0.0078],\n",
      "          [ 0.0150,  0.0187,  0.0125],\n",
      "          [-0.0188,  0.0099, -0.0197]]],\n",
      "\n",
      "\n",
      "        [[[-0.0078,  0.0098, -0.0128],\n",
      "          [ 0.0053, -0.0185,  0.0166],\n",
      "          [ 0.0093, -0.0142,  0.0022]],\n",
      "\n",
      "         [[ 0.0187, -0.0083,  0.0081],\n",
      "          [ 0.0089, -0.0158,  0.0086],\n",
      "          [-0.0087, -0.0108, -0.0056]],\n",
      "\n",
      "         [[ 0.0199,  0.0077,  0.0072],\n",
      "          [ 0.0020, -0.0193,  0.0149],\n",
      "          [-0.0207, -0.0174, -0.0034]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0063,  0.0106, -0.0125],\n",
      "          [ 0.0020,  0.0126, -0.0142],\n",
      "          [ 0.0200, -0.0084, -0.0005]],\n",
      "\n",
      "         [[-0.0069,  0.0123, -0.0089],\n",
      "          [ 0.0084, -0.0007, -0.0029],\n",
      "          [ 0.0140, -0.0144,  0.0026]],\n",
      "\n",
      "         [[-0.0064, -0.0088,  0.0187],\n",
      "          [-0.0059,  0.0146,  0.0149],\n",
      "          [-0.0194, -0.0046,  0.0096]]],\n",
      "\n",
      "\n",
      "        [[[-0.0044,  0.0113,  0.0134],\n",
      "          [-0.0173, -0.0008, -0.0196],\n",
      "          [-0.0174, -0.0198,  0.0143]],\n",
      "\n",
      "         [[ 0.0095, -0.0028, -0.0118],\n",
      "          [-0.0140, -0.0003,  0.0194],\n",
      "          [-0.0015, -0.0050, -0.0011]],\n",
      "\n",
      "         [[-0.0090,  0.0076, -0.0057],\n",
      "          [-0.0075,  0.0047, -0.0059],\n",
      "          [-0.0160, -0.0012, -0.0180]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0202,  0.0062,  0.0110],\n",
      "          [-0.0020,  0.0079,  0.0121],\n",
      "          [ 0.0169, -0.0155,  0.0059]],\n",
      "\n",
      "         [[ 0.0011, -0.0201, -0.0130],\n",
      "          [-0.0064, -0.0152, -0.0124],\n",
      "          [ 0.0104, -0.0133, -0.0008]],\n",
      "\n",
      "         [[ 0.0004, -0.0054, -0.0017],\n",
      "          [-0.0064, -0.0031,  0.0035],\n",
      "          [-0.0101,  0.0039,  0.0120]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0033, -0.0121, -0.0003],\n",
      "          [-0.0041,  0.0118, -0.0186],\n",
      "          [ 0.0195,  0.0154, -0.0094]],\n",
      "\n",
      "         [[-0.0116, -0.0127, -0.0095],\n",
      "          [-0.0008,  0.0016,  0.0048],\n",
      "          [-0.0042, -0.0182,  0.0165]],\n",
      "\n",
      "         [[ 0.0115, -0.0019,  0.0115],\n",
      "          [ 0.0032,  0.0106,  0.0114],\n",
      "          [ 0.0121,  0.0144, -0.0064]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0045, -0.0096,  0.0015],\n",
      "          [-0.0125, -0.0033,  0.0168],\n",
      "          [ 0.0061, -0.0059,  0.0123]],\n",
      "\n",
      "         [[-0.0081, -0.0183, -0.0024],\n",
      "          [ 0.0181, -0.0029,  0.0208],\n",
      "          [ 0.0026, -0.0046,  0.0010]],\n",
      "\n",
      "         [[-0.0012, -0.0002,  0.0207],\n",
      "          [ 0.0037, -0.0148,  0.0034],\n",
      "          [ 0.0060, -0.0049, -0.0016]]],\n",
      "\n",
      "\n",
      "        [[[-0.0143,  0.0172,  0.0129],\n",
      "          [-0.0003,  0.0053, -0.0118],\n",
      "          [-0.0154,  0.0129,  0.0104]],\n",
      "\n",
      "         [[-0.0135, -0.0149,  0.0129],\n",
      "          [-0.0180, -0.0046, -0.0024],\n",
      "          [ 0.0002,  0.0042,  0.0075]],\n",
      "\n",
      "         [[ 0.0161,  0.0063, -0.0059],\n",
      "          [ 0.0179,  0.0088, -0.0019],\n",
      "          [-0.0102, -0.0037, -0.0026]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0008,  0.0024, -0.0039],\n",
      "          [-0.0196, -0.0092, -0.0200],\n",
      "          [-0.0138,  0.0122, -0.0191]],\n",
      "\n",
      "         [[ 0.0207, -0.0198,  0.0109],\n",
      "          [-0.0097,  0.0018, -0.0138],\n",
      "          [ 0.0184, -0.0018, -0.0170]],\n",
      "\n",
      "         [[-0.0052,  0.0109, -0.0155],\n",
      "          [ 0.0141,  0.0135,  0.0150],\n",
      "          [ 0.0186,  0.0074, -0.0016]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0189,  0.0071,  0.0087],\n",
      "          [-0.0139, -0.0103,  0.0077],\n",
      "          [ 0.0003, -0.0039, -0.0129]],\n",
      "\n",
      "         [[-0.0165, -0.0179, -0.0049],\n",
      "          [-0.0103, -0.0033,  0.0023],\n",
      "          [ 0.0140,  0.0009, -0.0176]],\n",
      "\n",
      "         [[ 0.0159, -0.0144, -0.0027],\n",
      "          [-0.0183, -0.0048, -0.0068],\n",
      "          [ 0.0088, -0.0178,  0.0039]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0205,  0.0164,  0.0158],\n",
      "          [-0.0061, -0.0081, -0.0195],\n",
      "          [-0.0158,  0.0163,  0.0142]],\n",
      "\n",
      "         [[-0.0119, -0.0194,  0.0110],\n",
      "          [-0.0082, -0.0172,  0.0132],\n",
      "          [-0.0044,  0.0205, -0.0069]],\n",
      "\n",
      "         [[ 0.0127,  0.0066, -0.0086],\n",
      "          [-0.0131,  0.0074, -0.0100],\n",
      "          [-0.0019, -0.0152,  0.0169]]]])\n",
      "Layer: layer3.2.conv1.bias, Biases: tensor([ 0.0187,  0.0131, -0.0126, -0.0026,  0.0039, -0.0198, -0.0125,  0.0188,\n",
      "        -0.0073,  0.0208, -0.0099,  0.0187,  0.0080, -0.0058,  0.0053, -0.0206,\n",
      "        -0.0199, -0.0195, -0.0003, -0.0095,  0.0166,  0.0157, -0.0161,  0.0198,\n",
      "        -0.0165, -0.0159,  0.0020, -0.0149, -0.0078,  0.0025,  0.0011,  0.0101,\n",
      "        -0.0077,  0.0199, -0.0106, -0.0153,  0.0085, -0.0171, -0.0077, -0.0178,\n",
      "        -0.0149,  0.0165, -0.0039, -0.0115, -0.0038, -0.0041, -0.0147,  0.0173,\n",
      "         0.0062,  0.0050, -0.0171,  0.0157,  0.0152, -0.0148,  0.0048, -0.0055,\n",
      "         0.0037, -0.0084,  0.0044, -0.0026,  0.0203,  0.0151,  0.0200,  0.0202,\n",
      "         0.0154, -0.0059, -0.0008,  0.0182,  0.0085,  0.0038, -0.0125,  0.0050,\n",
      "        -0.0199, -0.0172, -0.0163,  0.0203, -0.0096, -0.0116,  0.0195, -0.0183,\n",
      "         0.0065, -0.0080, -0.0164,  0.0161, -0.0201, -0.0043,  0.0010, -0.0194,\n",
      "        -0.0155, -0.0050, -0.0036, -0.0062, -0.0139, -0.0075,  0.0109, -0.0205,\n",
      "         0.0014,  0.0152, -0.0139, -0.0190,  0.0032,  0.0103,  0.0134, -0.0016,\n",
      "         0.0063,  0.0011, -0.0032,  0.0103,  0.0195,  0.0134, -0.0162, -0.0090,\n",
      "        -0.0038, -0.0111,  0.0026, -0.0180, -0.0121, -0.0036,  0.0142, -0.0004,\n",
      "         0.0002,  0.0165, -0.0200, -0.0043, -0.0038,  0.0042, -0.0152,  0.0062])\n",
      "Layer: layer3.2.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Layer: layer3.2.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.2.conv2.weight:, Weights: tensor([[[[-3.5465e-03,  6.9953e-03, -1.1819e-02],\n",
      "          [-1.5331e-02,  1.0855e-02,  2.7728e-02],\n",
      "          [ 4.8147e-03, -2.6773e-02, -2.0326e-02]],\n",
      "\n",
      "         [[ 2.4394e-02,  1.9595e-02,  2.8761e-02],\n",
      "          [-5.2083e-03,  9.5208e-03,  2.5907e-02],\n",
      "          [ 7.6906e-03, -6.2117e-03, -1.5103e-02]],\n",
      "\n",
      "         [[-2.5854e-02,  1.6211e-02,  8.9672e-03],\n",
      "          [-3.7668e-03,  2.2218e-02,  4.2490e-03],\n",
      "          [-1.6550e-02,  1.1956e-02, -1.0347e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5255e-03,  2.2875e-02,  1.8012e-02],\n",
      "          [ 1.8076e-02,  1.9675e-04,  6.1986e-03],\n",
      "          [ 2.4107e-02,  2.9041e-02,  1.7800e-02]],\n",
      "\n",
      "         [[-9.7007e-03,  2.3139e-02,  2.2048e-02],\n",
      "          [-1.4534e-02,  4.0498e-04, -1.6678e-02],\n",
      "          [ 8.1250e-03,  1.8566e-03, -1.8326e-02]],\n",
      "\n",
      "         [[ 1.2601e-02,  2.6704e-02, -7.8531e-03],\n",
      "          [ 2.6681e-02, -1.9484e-02,  2.3750e-02],\n",
      "          [ 8.0241e-03,  2.4505e-02, -1.1621e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2918e-02,  1.0139e-02, -2.2666e-02],\n",
      "          [ 1.7835e-02, -1.1942e-03,  2.7525e-02],\n",
      "          [ 1.9602e-02, -1.0447e-02,  6.8456e-03]],\n",
      "\n",
      "         [[ 1.6316e-02,  8.1281e-03,  1.5051e-02],\n",
      "          [-5.8299e-03, -2.7561e-02, -1.1171e-02],\n",
      "          [ 2.3849e-02,  1.9731e-02, -2.5734e-02]],\n",
      "\n",
      "         [[-2.0426e-03,  2.3330e-02,  1.6737e-03],\n",
      "          [ 4.5638e-03, -2.7087e-02, -1.9945e-02],\n",
      "          [-8.2870e-03,  1.4229e-02,  2.7819e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4179e-02,  1.6982e-02, -5.4610e-03],\n",
      "          [-1.0822e-02, -2.1819e-03,  2.3364e-02],\n",
      "          [ 4.4436e-03, -2.3567e-02, -9.4146e-05]],\n",
      "\n",
      "         [[-1.4522e-02, -5.4710e-03, -1.2785e-02],\n",
      "          [-9.9140e-03, -1.5014e-02, -9.6402e-03],\n",
      "          [-6.3221e-03, -2.0707e-02,  1.6009e-02]],\n",
      "\n",
      "         [[-2.1156e-02, -1.5273e-02,  1.4428e-02],\n",
      "          [-1.7591e-02,  1.5282e-02, -1.9898e-02],\n",
      "          [-2.6350e-02,  9.6282e-03, -6.1804e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.7391e-02, -1.3180e-02, -1.1117e-02],\n",
      "          [ 5.6975e-03, -2.7981e-02, -1.4921e-02],\n",
      "          [ 1.7534e-02,  2.0973e-02, -1.4260e-02]],\n",
      "\n",
      "         [[ 2.3990e-03, -7.7395e-03,  7.4708e-04],\n",
      "          [-8.6709e-03,  2.6823e-04,  9.1698e-03],\n",
      "          [ 1.6186e-02,  6.6354e-03, -1.4153e-02]],\n",
      "\n",
      "         [[-4.6803e-03,  1.7201e-02, -1.7921e-02],\n",
      "          [-2.0696e-02,  6.6363e-03, -1.3779e-02],\n",
      "          [ 8.7408e-03, -6.3709e-03,  1.2361e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3220e-02, -1.8275e-02,  1.6231e-02],\n",
      "          [-5.7991e-03, -2.5162e-02,  2.6762e-02],\n",
      "          [ 2.9387e-02,  4.1249e-03, -2.1826e-02]],\n",
      "\n",
      "         [[-2.8573e-02,  1.0874e-03, -1.3026e-03],\n",
      "          [-1.7049e-02, -2.1551e-02, -8.0147e-03],\n",
      "          [-1.5187e-02, -2.7498e-02, -2.8537e-02]],\n",
      "\n",
      "         [[ 2.5228e-02,  2.7727e-02, -2.9997e-03],\n",
      "          [-1.8067e-02, -1.1256e-02,  2.4681e-02],\n",
      "          [-2.8500e-03, -2.0825e-02,  3.0862e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 8.4092e-03, -7.0775e-03,  1.9442e-02],\n",
      "          [-1.9872e-02,  2.0489e-02, -5.5843e-03],\n",
      "          [-1.7831e-02, -2.0651e-02,  2.5792e-02]],\n",
      "\n",
      "         [[ 2.2404e-02,  1.2804e-02, -2.9041e-02],\n",
      "          [ 1.0533e-02, -2.5202e-02,  2.8230e-02],\n",
      "          [-2.0508e-02, -1.7951e-02,  1.6821e-02]],\n",
      "\n",
      "         [[-2.6764e-02,  2.8351e-02,  1.6320e-02],\n",
      "          [-4.9324e-03,  2.1998e-02, -6.9577e-06],\n",
      "          [ 2.4102e-02, -2.4035e-02,  2.3683e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3934e-02,  2.7748e-02, -2.9290e-02],\n",
      "          [-1.5031e-02, -5.2119e-03, -2.0874e-02],\n",
      "          [-2.5142e-02, -8.1712e-03, -3.7003e-03]],\n",
      "\n",
      "         [[-1.7509e-03,  4.2337e-03, -1.2683e-02],\n",
      "          [-1.9338e-02, -1.3101e-02,  1.5623e-02],\n",
      "          [ 6.3121e-04,  5.2196e-03,  1.3637e-02]],\n",
      "\n",
      "         [[-2.4432e-03, -1.8444e-02, -1.2656e-02],\n",
      "          [-3.2171e-04,  1.9559e-02, -1.6477e-02],\n",
      "          [ 1.0773e-02,  1.2103e-02, -2.8763e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.4309e-03,  1.0648e-02,  1.3342e-02],\n",
      "          [ 3.8826e-03,  1.5434e-02, -1.7999e-02],\n",
      "          [ 2.7690e-02,  2.7695e-03, -2.1952e-02]],\n",
      "\n",
      "         [[-1.0216e-02, -2.0739e-02,  1.7854e-02],\n",
      "          [-2.4538e-02, -1.1732e-02,  2.2730e-02],\n",
      "          [-2.3762e-02, -3.0963e-03, -1.9963e-02]],\n",
      "\n",
      "         [[-1.1375e-03, -9.3513e-03, -3.0208e-03],\n",
      "          [-2.5233e-02,  9.2688e-03,  1.2307e-02],\n",
      "          [ 2.8240e-02, -6.2729e-03,  2.7382e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0142e-02,  2.1858e-02, -2.4468e-02],\n",
      "          [-1.6766e-02,  1.2464e-02,  1.9659e-02],\n",
      "          [ 1.8459e-02,  6.8109e-03,  2.6395e-02]],\n",
      "\n",
      "         [[-2.8658e-02,  1.7053e-02, -1.6591e-03],\n",
      "          [ 2.5088e-03, -2.7322e-02, -2.3769e-02],\n",
      "          [-1.4474e-02,  2.0928e-03, -7.6272e-03]],\n",
      "\n",
      "         [[-2.8545e-02, -2.1944e-02,  1.6879e-02],\n",
      "          [ 2.7407e-02, -2.3398e-02, -2.1079e-02],\n",
      "          [-9.8266e-03, -2.0579e-02, -3.5144e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.5378e-03, -3.8235e-03, -8.1236e-03],\n",
      "          [-1.6498e-02, -2.2595e-02,  2.3067e-02],\n",
      "          [-8.7779e-04,  9.9376e-03, -5.4614e-03]],\n",
      "\n",
      "         [[ 6.4630e-03,  1.3971e-02, -8.9942e-04],\n",
      "          [ 1.1041e-02,  1.2956e-03,  5.5743e-03],\n",
      "          [ 6.7528e-03, -3.0095e-03, -2.7655e-02]],\n",
      "\n",
      "         [[ 2.1708e-03,  1.4891e-02,  1.2357e-02],\n",
      "          [-1.9533e-02,  1.5167e-02,  1.1125e-02],\n",
      "          [ 1.8151e-02,  2.7119e-02,  2.0931e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.5090e-03,  2.7178e-02, -2.7044e-02],\n",
      "          [ 1.3613e-03, -1.1909e-02, -2.6523e-02],\n",
      "          [-7.6731e-03,  1.2680e-03,  3.2108e-03]],\n",
      "\n",
      "         [[-3.2294e-03,  1.6718e-02,  2.0825e-02],\n",
      "          [-3.7213e-03,  7.7876e-03,  1.6385e-02],\n",
      "          [-1.7285e-02, -7.7190e-03,  9.4692e-04]],\n",
      "\n",
      "         [[-8.7748e-03, -2.8478e-02,  2.4853e-02],\n",
      "          [ 9.8367e-03,  3.1126e-03,  1.5469e-02],\n",
      "          [ 2.2413e-02,  2.2166e-02,  8.6203e-03]]]])\n",
      "Layer: layer3.2.conv2.bias, Biases: tensor([ 0.0163,  0.0037, -0.0135, -0.0200, -0.0201, -0.0056,  0.0270, -0.0067,\n",
      "        -0.0015, -0.0090, -0.0222, -0.0113, -0.0010,  0.0276, -0.0129, -0.0148,\n",
      "        -0.0076, -0.0196,  0.0167, -0.0217, -0.0231, -0.0002,  0.0204, -0.0089,\n",
      "         0.0228,  0.0022,  0.0030,  0.0026,  0.0129,  0.0266, -0.0249, -0.0072,\n",
      "         0.0186,  0.0200,  0.0110,  0.0131, -0.0150,  0.0093,  0.0150, -0.0293,\n",
      "        -0.0242,  0.0194, -0.0264,  0.0178, -0.0278, -0.0009,  0.0052,  0.0243,\n",
      "        -0.0256,  0.0027,  0.0214,  0.0213,  0.0275,  0.0065,  0.0094,  0.0259,\n",
      "        -0.0229, -0.0082,  0.0093, -0.0154,  0.0259,  0.0004,  0.0051, -0.0042,\n",
      "         0.0257, -0.0040,  0.0091,  0.0127,  0.0008, -0.0277, -0.0095,  0.0290,\n",
      "         0.0031,  0.0143,  0.0041, -0.0065,  0.0272,  0.0012,  0.0284, -0.0290,\n",
      "         0.0182, -0.0060, -0.0243,  0.0094,  0.0184, -0.0124, -0.0231,  0.0277,\n",
      "        -0.0095,  0.0170, -0.0005, -0.0195, -0.0165,  0.0134, -0.0044, -0.0025,\n",
      "        -0.0231,  0.0270,  0.0002,  0.0212, -0.0188, -0.0050, -0.0116, -0.0040,\n",
      "        -0.0019,  0.0259, -0.0192, -0.0294,  0.0198, -0.0294, -0.0166,  0.0267,\n",
      "         0.0121,  0.0148, -0.0258,  0.0106,  0.0008, -0.0030,  0.0139,  0.0043,\n",
      "        -0.0037,  0.0261, -0.0234,  0.0171,  0.0133,  0.0143, -0.0059, -0.0111,\n",
      "         0.0168,  0.0246,  0.0021, -0.0015, -0.0170, -0.0213, -0.0084,  0.0175,\n",
      "        -0.0277, -0.0196,  0.0015,  0.0085,  0.0192, -0.0282,  0.0005, -0.0196,\n",
      "         0.0023, -0.0128, -0.0019, -0.0141, -0.0060,  0.0033, -0.0266,  0.0239,\n",
      "         0.0025, -0.0227, -0.0218,  0.0286, -0.0247, -0.0186, -0.0100,  0.0129,\n",
      "        -0.0220,  0.0252, -0.0050,  0.0246,  0.0230,  0.0079, -0.0174,  0.0093,\n",
      "        -0.0118, -0.0102,  0.0239,  0.0244,  0.0116,  0.0112, -0.0003, -0.0213,\n",
      "         0.0213,  0.0265,  0.0160, -0.0114,  0.0044,  0.0124, -0.0184, -0.0117,\n",
      "        -0.0290, -0.0031, -0.0241,  0.0099, -0.0025,  0.0238,  0.0102,  0.0096,\n",
      "         0.0025, -0.0006,  0.0024, -0.0119,  0.0229, -0.0039,  0.0086, -0.0201,\n",
      "         0.0144, -0.0166, -0.0173,  0.0270, -0.0161, -0.0187, -0.0132, -0.0256,\n",
      "         0.0247, -0.0226, -0.0265,  0.0071,  0.0086, -0.0091,  0.0201,  0.0122,\n",
      "         0.0018, -0.0141, -0.0137,  0.0109, -0.0169,  0.0207, -0.0277, -0.0082,\n",
      "         0.0149,  0.0266,  0.0209, -0.0199, -0.0252,  0.0184,  0.0157, -0.0009,\n",
      "         0.0242,  0.0152,  0.0003, -0.0146, -0.0031,  0.0243,  0.0172, -0.0061,\n",
      "         0.0219, -0.0107, -0.0169, -0.0116,  0.0142,  0.0294, -0.0097,  0.0213,\n",
      "        -0.0115,  0.0203, -0.0057,  0.0220, -0.0084,  0.0279,  0.0115, -0.0190])\n",
      "Layer: layer3.2.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])\n",
      "Layer: layer3.2.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.3.conv1.weight:, Weights: tensor([[[[ 1.6395e-02,  1.8169e-03, -7.0441e-03],\n",
      "          [ 1.8708e-02, -8.5816e-03, -1.8530e-02],\n",
      "          [-1.2411e-02,  1.4973e-02, -1.2854e-03]],\n",
      "\n",
      "         [[ 1.7791e-02,  6.6286e-03, -8.3754e-03],\n",
      "          [ 8.8552e-03,  5.2154e-03, -5.2971e-03],\n",
      "          [ 8.2102e-03, -6.1488e-03,  2.0015e-02]],\n",
      "\n",
      "         [[ 1.7605e-02,  1.3159e-02,  3.8818e-03],\n",
      "          [-1.8852e-02, -4.1097e-04, -3.3466e-03],\n",
      "          [ 5.7131e-03, -1.0960e-02, -8.1879e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.0092e-03,  6.5105e-03,  1.8040e-02],\n",
      "          [-9.7662e-03,  3.4967e-03, -6.5160e-03],\n",
      "          [-1.3868e-03,  1.2349e-02,  1.0414e-03]],\n",
      "\n",
      "         [[ 9.5384e-03,  1.4256e-02, -1.5904e-02],\n",
      "          [-7.3420e-03,  1.3864e-02, -6.9770e-03],\n",
      "          [ 7.6599e-03, -1.7267e-02,  7.0964e-03]],\n",
      "\n",
      "         [[-9.2242e-03, -2.7939e-03,  1.1669e-03],\n",
      "          [ 1.0438e-02, -1.8196e-02, -1.9428e-02],\n",
      "          [-1.5708e-02,  9.8207e-03,  1.8530e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7184e-02,  6.0068e-03,  1.0536e-02],\n",
      "          [ 1.2053e-02, -2.0584e-02, -1.6573e-02],\n",
      "          [ 8.2453e-03, -1.3395e-02, -3.6294e-03]],\n",
      "\n",
      "         [[-5.2253e-03,  1.9586e-02,  1.1351e-02],\n",
      "          [-1.3482e-02, -2.1506e-03, -1.5011e-02],\n",
      "          [-5.4739e-03,  8.0123e-03, -1.9206e-03]],\n",
      "\n",
      "         [[ 1.9654e-02,  8.8963e-03, -1.0669e-02],\n",
      "          [-6.7408e-04, -1.5851e-02,  2.7778e-03],\n",
      "          [ 5.7563e-03,  2.0069e-02, -5.5444e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.1955e-03, -9.7461e-03, -6.6202e-03],\n",
      "          [ 9.5872e-03,  7.3389e-03, -1.0921e-02],\n",
      "          [ 1.5027e-02, -1.1524e-02,  9.3961e-03]],\n",
      "\n",
      "         [[ 1.2586e-02,  1.1900e-02,  2.0124e-02],\n",
      "          [-5.9430e-03, -1.0077e-02,  7.6296e-03],\n",
      "          [-1.5975e-02,  7.4327e-03, -2.3745e-03]],\n",
      "\n",
      "         [[-5.9070e-03, -1.8910e-02,  7.5587e-03],\n",
      "          [-1.5275e-02, -2.7301e-03, -1.0181e-02],\n",
      "          [-1.2324e-02, -6.9237e-04, -2.0689e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.8572e-03, -2.0344e-02, -6.7194e-03],\n",
      "          [-1.0604e-02, -1.0730e-02, -3.4869e-03],\n",
      "          [ 9.0321e-03,  1.7767e-02, -2.2638e-04]],\n",
      "\n",
      "         [[ 7.6123e-03,  5.8800e-04, -2.0233e-02],\n",
      "          [-5.5238e-03,  1.9027e-02,  1.1384e-02],\n",
      "          [-2.0725e-02,  4.3615e-04,  6.2656e-03]],\n",
      "\n",
      "         [[ 1.9161e-03, -6.8378e-03,  5.7250e-03],\n",
      "          [-4.3912e-03,  2.0688e-02,  1.6548e-02],\n",
      "          [-1.3866e-02, -1.9775e-02, -5.6437e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.6892e-03, -1.0423e-02, -1.1733e-02],\n",
      "          [-1.0960e-02,  3.7596e-04,  1.6155e-02],\n",
      "          [ 9.7350e-03,  1.3617e-02,  1.6895e-02]],\n",
      "\n",
      "         [[ 8.7450e-03,  9.9422e-03, -1.6585e-02],\n",
      "          [ 8.2657e-03, -7.7104e-03,  1.1895e-02],\n",
      "          [ 1.6655e-02,  1.5482e-03, -3.2833e-03]],\n",
      "\n",
      "         [[-1.1424e-03,  1.0655e-02, -8.7559e-03],\n",
      "          [-1.9906e-02,  1.6569e-02, -2.0221e-02],\n",
      "          [ 9.2574e-03, -1.5284e-03,  1.1445e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.7628e-02, -1.1097e-02, -7.6894e-03],\n",
      "          [ 4.1931e-03, -6.3759e-03, -5.7860e-03],\n",
      "          [-1.7092e-02, -1.4130e-02,  1.7235e-02]],\n",
      "\n",
      "         [[-1.1636e-03,  1.6000e-02,  1.3697e-02],\n",
      "          [-1.8395e-02,  1.3430e-02, -1.7879e-02],\n",
      "          [-1.8805e-02,  1.2063e-02,  1.0964e-02]],\n",
      "\n",
      "         [[ 8.0059e-03,  6.9229e-03,  8.8457e-03],\n",
      "          [ 1.2104e-02, -9.3788e-03, -4.1547e-03],\n",
      "          [ 1.8592e-02,  4.0259e-03,  1.1474e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.3833e-03, -1.2828e-02,  3.9647e-03],\n",
      "          [-1.6828e-02, -1.8241e-03, -9.5397e-03],\n",
      "          [-1.1769e-02,  9.0758e-03, -1.0172e-02]],\n",
      "\n",
      "         [[-1.9781e-02, -6.9316e-03,  7.5576e-03],\n",
      "          [-2.4835e-03, -1.2848e-02, -9.6280e-03],\n",
      "          [-1.5845e-02, -1.5833e-03,  7.9473e-03]],\n",
      "\n",
      "         [[ 2.1305e-03, -1.2341e-04, -1.1598e-02],\n",
      "          [ 3.6680e-03, -7.1101e-03, -4.7988e-04],\n",
      "          [-2.0200e-02, -1.6249e-02,  1.9987e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1183e-03, -1.2048e-02, -1.1464e-02],\n",
      "          [-1.1495e-02,  1.2260e-02, -3.2927e-04],\n",
      "          [-4.4655e-03, -1.0978e-02, -9.4439e-03]],\n",
      "\n",
      "         [[ 4.6342e-03, -1.4019e-02, -1.6133e-02],\n",
      "          [ 5.1438e-03,  1.4442e-02, -1.1032e-02],\n",
      "          [-1.4399e-02,  1.2988e-02,  6.8528e-03]],\n",
      "\n",
      "         [[-2.7934e-03,  2.5505e-03,  1.4511e-02],\n",
      "          [-2.5926e-04,  1.6234e-02, -1.6226e-02],\n",
      "          [-6.2547e-04, -1.8634e-02,  1.2465e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9669e-03, -1.9293e-02, -1.6271e-02],\n",
      "          [ 2.0512e-03, -1.2725e-02,  4.2338e-03],\n",
      "          [ 6.9829e-03, -1.3397e-02,  7.6695e-03]],\n",
      "\n",
      "         [[ 1.8093e-02, -9.0499e-03, -2.3246e-05],\n",
      "          [-1.1550e-02,  1.5001e-02, -1.4209e-02],\n",
      "          [-1.4291e-02, -1.2116e-02,  1.5845e-02]],\n",
      "\n",
      "         [[ 5.0204e-03, -1.8387e-02,  6.4400e-03],\n",
      "          [-4.8472e-03, -3.5470e-03, -3.0373e-03],\n",
      "          [ 8.4596e-03,  8.5526e-03,  8.5633e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5596e-03, -3.2302e-03, -8.5670e-03],\n",
      "          [-1.3106e-02,  1.8685e-03,  3.9155e-03],\n",
      "          [-6.3710e-03, -1.0925e-02,  1.1970e-02]],\n",
      "\n",
      "         [[-1.7597e-02,  6.9859e-03, -6.2084e-03],\n",
      "          [ 7.7363e-03,  8.0269e-03, -2.0128e-03],\n",
      "          [-1.8673e-02, -1.9376e-02,  7.1776e-03]],\n",
      "\n",
      "         [[ 9.9597e-03, -1.7021e-02,  1.5731e-02],\n",
      "          [-1.1033e-02,  6.2811e-03,  1.8636e-02],\n",
      "          [-1.8311e-02,  5.5413e-03,  9.6530e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4071e-03, -1.1116e-02, -7.2148e-03],\n",
      "          [ 1.5417e-02,  1.6986e-02,  2.0419e-02],\n",
      "          [ 1.9529e-02, -1.2591e-02,  1.6514e-02]],\n",
      "\n",
      "         [[ 7.4399e-03, -2.8359e-03, -1.1924e-02],\n",
      "          [-1.8645e-02,  1.1104e-02,  1.2303e-02],\n",
      "          [ 5.7859e-03, -1.9358e-02,  1.9239e-03]],\n",
      "\n",
      "         [[ 2.0657e-02,  5.6195e-03,  2.2059e-03],\n",
      "          [ 1.2730e-02,  1.8317e-02, -1.2816e-02],\n",
      "          [-9.9180e-03, -1.9034e-02,  8.0936e-03]]]])\n",
      "Layer: layer3.3.conv1.bias, Biases: tensor([ 0.0102, -0.0151,  0.0092,  0.0122,  0.0036, -0.0083, -0.0116,  0.0006,\n",
      "        -0.0034,  0.0077,  0.0098,  0.0208, -0.0073, -0.0143, -0.0032, -0.0108,\n",
      "         0.0192, -0.0039, -0.0041, -0.0162, -0.0034,  0.0032,  0.0099, -0.0105,\n",
      "        -0.0138,  0.0072,  0.0172, -0.0097,  0.0071, -0.0196, -0.0174,  0.0093,\n",
      "        -0.0130, -0.0207,  0.0197,  0.0109, -0.0022,  0.0002, -0.0201,  0.0012,\n",
      "        -0.0124,  0.0189,  0.0012,  0.0090,  0.0090,  0.0125,  0.0068,  0.0194,\n",
      "        -0.0073, -0.0029, -0.0154, -0.0188, -0.0069, -0.0205, -0.0041,  0.0172,\n",
      "        -0.0133, -0.0202, -0.0185,  0.0165,  0.0045, -0.0040,  0.0116, -0.0127,\n",
      "        -0.0004, -0.0186,  0.0070,  0.0053, -0.0166,  0.0025,  0.0009,  0.0044,\n",
      "         0.0126, -0.0036,  0.0033, -0.0023, -0.0117,  0.0182, -0.0173,  0.0054,\n",
      "         0.0035, -0.0187, -0.0187, -0.0155,  0.0052, -0.0026, -0.0070, -0.0008,\n",
      "        -0.0207, -0.0188,  0.0182,  0.0170, -0.0084,  0.0092, -0.0170,  0.0162,\n",
      "        -0.0103, -0.0030,  0.0168, -0.0135,  0.0181, -0.0050, -0.0040,  0.0196,\n",
      "        -0.0067, -0.0167,  0.0029, -0.0037, -0.0037,  0.0096,  0.0147,  0.0025,\n",
      "         0.0003,  0.0028, -0.0201,  0.0053,  0.0074,  0.0023, -0.0175,  0.0151,\n",
      "        -0.0158,  0.0099, -0.0050, -0.0012,  0.0187,  0.0176, -0.0073,  0.0110])\n",
      "Layer: layer3.3.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Layer: layer3.3.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.3.conv2.weight:, Weights: tensor([[[[ 0.0218, -0.0277,  0.0223],\n",
      "          [ 0.0107, -0.0240,  0.0070],\n",
      "          [-0.0103,  0.0096,  0.0052]],\n",
      "\n",
      "         [[-0.0223,  0.0080,  0.0027],\n",
      "          [ 0.0244,  0.0011, -0.0203],\n",
      "          [-0.0045,  0.0048, -0.0051]],\n",
      "\n",
      "         [[ 0.0291, -0.0236, -0.0239],\n",
      "          [ 0.0039, -0.0087,  0.0268],\n",
      "          [ 0.0214, -0.0143,  0.0276]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0205, -0.0196, -0.0016],\n",
      "          [ 0.0144,  0.0049,  0.0016],\n",
      "          [ 0.0049, -0.0243, -0.0158]],\n",
      "\n",
      "         [[ 0.0156,  0.0129, -0.0188],\n",
      "          [-0.0242, -0.0094,  0.0059],\n",
      "          [-0.0078,  0.0019, -0.0197]],\n",
      "\n",
      "         [[-0.0271,  0.0258,  0.0205],\n",
      "          [-0.0291,  0.0157, -0.0152],\n",
      "          [-0.0026, -0.0051, -0.0220]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0208, -0.0282, -0.0036],\n",
      "          [ 0.0213, -0.0044, -0.0106],\n",
      "          [-0.0274,  0.0276, -0.0268]],\n",
      "\n",
      "         [[-0.0020,  0.0041, -0.0290],\n",
      "          [ 0.0191, -0.0086, -0.0123],\n",
      "          [ 0.0247,  0.0274,  0.0057]],\n",
      "\n",
      "         [[ 0.0209,  0.0274,  0.0001],\n",
      "          [-0.0280,  0.0227,  0.0199],\n",
      "          [ 0.0181, -0.0214, -0.0012]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0273, -0.0240, -0.0079],\n",
      "          [-0.0012,  0.0183, -0.0072],\n",
      "          [ 0.0118,  0.0036,  0.0060]],\n",
      "\n",
      "         [[ 0.0056, -0.0126, -0.0136],\n",
      "          [-0.0076,  0.0104, -0.0139],\n",
      "          [-0.0254, -0.0103, -0.0270]],\n",
      "\n",
      "         [[ 0.0281, -0.0148, -0.0002],\n",
      "          [-0.0219,  0.0077,  0.0116],\n",
      "          [-0.0294, -0.0101,  0.0118]]],\n",
      "\n",
      "\n",
      "        [[[-0.0263, -0.0008, -0.0200],\n",
      "          [ 0.0079,  0.0055,  0.0135],\n",
      "          [-0.0077, -0.0237,  0.0006]],\n",
      "\n",
      "         [[-0.0042, -0.0036, -0.0041],\n",
      "          [-0.0079, -0.0135,  0.0247],\n",
      "          [-0.0212,  0.0008, -0.0161]],\n",
      "\n",
      "         [[-0.0185,  0.0272,  0.0267],\n",
      "          [ 0.0093, -0.0152,  0.0105],\n",
      "          [-0.0264, -0.0032, -0.0025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0155, -0.0015,  0.0287],\n",
      "          [-0.0057,  0.0157, -0.0015],\n",
      "          [-0.0247,  0.0211, -0.0071]],\n",
      "\n",
      "         [[-0.0165, -0.0258,  0.0175],\n",
      "          [ 0.0264,  0.0208,  0.0212],\n",
      "          [-0.0100, -0.0150, -0.0293]],\n",
      "\n",
      "         [[-0.0183,  0.0073, -0.0113],\n",
      "          [-0.0080,  0.0230,  0.0237],\n",
      "          [ 0.0290,  0.0218, -0.0240]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0246,  0.0259,  0.0290],\n",
      "          [-0.0125, -0.0082,  0.0184],\n",
      "          [-0.0028, -0.0063, -0.0002]],\n",
      "\n",
      "         [[-0.0032, -0.0168, -0.0144],\n",
      "          [ 0.0089, -0.0088,  0.0132],\n",
      "          [ 0.0170, -0.0234,  0.0089]],\n",
      "\n",
      "         [[-0.0107, -0.0181, -0.0163],\n",
      "          [-0.0075,  0.0284, -0.0094],\n",
      "          [-0.0255,  0.0259,  0.0106]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0056,  0.0146,  0.0285],\n",
      "          [ 0.0197, -0.0025,  0.0271],\n",
      "          [ 0.0065, -0.0035, -0.0064]],\n",
      "\n",
      "         [[ 0.0089, -0.0147,  0.0246],\n",
      "          [-0.0073, -0.0069, -0.0203],\n",
      "          [-0.0157,  0.0118, -0.0029]],\n",
      "\n",
      "         [[-0.0130, -0.0042,  0.0217],\n",
      "          [ 0.0197,  0.0068, -0.0061],\n",
      "          [-0.0161,  0.0217,  0.0034]]],\n",
      "\n",
      "\n",
      "        [[[-0.0006, -0.0282,  0.0079],\n",
      "          [-0.0125, -0.0051,  0.0285],\n",
      "          [-0.0188, -0.0136, -0.0090]],\n",
      "\n",
      "         [[-0.0209,  0.0281,  0.0278],\n",
      "          [-0.0085, -0.0058,  0.0097],\n",
      "          [ 0.0182, -0.0143, -0.0198]],\n",
      "\n",
      "         [[-0.0264,  0.0266,  0.0034],\n",
      "          [-0.0100, -0.0152,  0.0075],\n",
      "          [-0.0263,  0.0224, -0.0111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0248,  0.0269,  0.0128],\n",
      "          [-0.0281,  0.0291,  0.0268],\n",
      "          [ 0.0223, -0.0248, -0.0203]],\n",
      "\n",
      "         [[ 0.0100,  0.0090,  0.0172],\n",
      "          [-0.0026, -0.0258, -0.0146],\n",
      "          [-0.0173, -0.0060,  0.0186]],\n",
      "\n",
      "         [[ 0.0041,  0.0216, -0.0286],\n",
      "          [-0.0088, -0.0063,  0.0145],\n",
      "          [ 0.0004, -0.0027,  0.0085]]],\n",
      "\n",
      "\n",
      "        [[[-0.0247, -0.0102, -0.0091],\n",
      "          [-0.0198,  0.0047,  0.0093],\n",
      "          [-0.0283, -0.0122,  0.0235]],\n",
      "\n",
      "         [[ 0.0058,  0.0210,  0.0291],\n",
      "          [-0.0256,  0.0081,  0.0232],\n",
      "          [ 0.0072, -0.0096,  0.0115]],\n",
      "\n",
      "         [[-0.0012,  0.0141,  0.0163],\n",
      "          [-0.0094,  0.0017,  0.0156],\n",
      "          [-0.0166,  0.0012, -0.0252]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0052, -0.0173,  0.0175],\n",
      "          [-0.0147,  0.0266,  0.0002],\n",
      "          [ 0.0126, -0.0036,  0.0121]],\n",
      "\n",
      "         [[ 0.0187, -0.0293,  0.0110],\n",
      "          [-0.0131, -0.0105,  0.0179],\n",
      "          [ 0.0008, -0.0150, -0.0228]],\n",
      "\n",
      "         [[ 0.0267, -0.0014,  0.0215],\n",
      "          [ 0.0070,  0.0212, -0.0180],\n",
      "          [-0.0153,  0.0196, -0.0048]]]])\n",
      "Layer: layer3.3.conv2.bias, Biases: tensor([ 1.7563e-02,  1.6052e-02, -6.8950e-03, -2.0705e-02, -1.0721e-02,\n",
      "         2.2195e-02, -1.2074e-02, -2.6619e-02,  2.7541e-02,  1.1499e-02,\n",
      "        -1.7597e-02,  2.3102e-02, -6.6334e-03, -2.2801e-02,  5.3063e-03,\n",
      "         2.3187e-02, -2.7642e-02, -4.0514e-03,  2.5894e-02, -1.8284e-02,\n",
      "         2.9350e-02, -4.4372e-03, -2.7246e-02, -7.9231e-03, -2.4290e-02,\n",
      "         9.9462e-03, -2.1496e-02, -2.9347e-02, -8.7611e-04, -1.1656e-03,\n",
      "        -6.3483e-03, -2.6039e-02, -1.3890e-02,  8.3228e-03, -3.6239e-03,\n",
      "        -2.9217e-02, -2.4635e-02,  8.5670e-03, -1.1586e-02, -1.4669e-02,\n",
      "         2.3173e-02,  1.3050e-02,  3.6566e-03,  1.4457e-02, -2.4020e-02,\n",
      "         1.8911e-02,  2.6278e-02,  1.2608e-02,  2.0588e-02, -2.6673e-02,\n",
      "        -3.7142e-03, -1.7092e-02, -2.7800e-02, -1.7678e-03, -2.8194e-02,\n",
      "        -8.2091e-04, -2.6842e-02,  1.3010e-02,  2.5378e-02,  5.6988e-03,\n",
      "        -2.4832e-02, -6.3811e-03,  2.0836e-02,  6.5707e-03, -6.5911e-05,\n",
      "         1.2471e-02,  2.3491e-03, -1.0389e-02, -1.8898e-02, -1.3207e-02,\n",
      "        -1.4961e-02, -1.2361e-02,  2.0046e-02,  2.1749e-02, -3.5626e-03,\n",
      "        -6.8395e-04,  1.2080e-02,  6.5228e-03, -5.4146e-03,  1.5466e-02,\n",
      "         2.6212e-02, -1.0333e-02, -1.6745e-02,  1.0362e-02,  5.6465e-03,\n",
      "        -8.9875e-03, -1.2835e-02,  1.8534e-02, -2.5066e-02,  5.9136e-03,\n",
      "        -2.8318e-02, -2.6110e-02,  5.6872e-04, -3.7009e-03, -1.0291e-02,\n",
      "         1.9034e-02, -3.3541e-03,  1.7321e-02, -2.7456e-03, -2.4831e-02,\n",
      "         1.0078e-02,  8.9367e-03,  2.3173e-02,  2.2204e-03, -2.6010e-02,\n",
      "        -1.6093e-02, -3.6812e-03, -1.1550e-02, -2.0151e-02,  2.2976e-03,\n",
      "        -1.2645e-02,  1.6243e-02,  2.1734e-02, -4.2055e-04,  2.4233e-02,\n",
      "         1.8145e-02,  2.2334e-02, -1.2094e-02,  2.7145e-02, -2.6970e-02,\n",
      "        -1.8367e-02, -7.2052e-03,  8.9493e-03,  1.8525e-02,  1.8809e-02,\n",
      "         5.6426e-03, -1.9716e-02, -1.8573e-02, -2.1616e-02,  5.6557e-03,\n",
      "        -2.8913e-02, -6.6935e-03, -1.4631e-03,  2.1371e-02, -2.1710e-03,\n",
      "        -1.8977e-02, -2.6416e-02,  3.9152e-03, -2.0485e-02, -1.7757e-02,\n",
      "         9.7091e-03,  2.2729e-02, -2.4448e-02,  2.1933e-02,  1.5567e-02,\n",
      "         2.5265e-02, -1.8498e-02,  1.8255e-02, -8.6976e-03,  2.4377e-02,\n",
      "         3.7396e-03, -9.6022e-03,  5.4688e-03,  1.3965e-02,  8.1028e-03,\n",
      "         2.7868e-02,  9.1096e-03, -1.4770e-02,  9.4237e-04, -6.9246e-03,\n",
      "         1.3931e-02, -2.8231e-02,  1.5894e-02, -1.5154e-02,  9.7458e-05,\n",
      "         2.4384e-02, -4.5397e-03, -1.0456e-02,  2.3952e-03,  2.4009e-02,\n",
      "         1.5387e-02, -2.5138e-02, -2.0496e-02,  1.5070e-02, -1.7190e-02,\n",
      "         2.4433e-02,  7.6203e-03, -1.3615e-03, -3.6719e-03, -2.2844e-02,\n",
      "        -1.6314e-02,  2.3486e-03,  1.7920e-02, -2.1677e-02, -2.7524e-02,\n",
      "        -1.0579e-02, -9.5368e-03, -2.0225e-02,  1.6710e-02,  2.1117e-02,\n",
      "        -1.7015e-02,  1.9539e-02, -2.6069e-02,  2.4583e-03,  1.6926e-03,\n",
      "         2.1019e-02,  1.4890e-02,  1.3942e-02,  2.4875e-02,  4.7501e-03,\n",
      "        -2.2479e-02,  1.3746e-03, -1.4614e-02,  2.1791e-02, -2.6649e-04,\n",
      "         1.1511e-02,  2.3043e-02,  9.8654e-03, -2.3553e-02,  5.5107e-03,\n",
      "         2.2353e-02, -2.1580e-02, -2.9028e-02, -1.1042e-02, -1.1204e-02,\n",
      "        -2.3469e-02,  1.7282e-02, -1.7272e-02, -6.8717e-03,  1.8155e-02,\n",
      "         1.2534e-02, -2.0013e-02,  2.3506e-04, -1.4648e-02, -1.1553e-02,\n",
      "         2.9307e-02, -1.5715e-02,  2.1582e-02, -5.3790e-05, -5.5729e-03,\n",
      "         1.7637e-02, -2.7773e-02,  1.4722e-02, -6.1489e-03,  2.0491e-02,\n",
      "         2.0009e-02, -9.6902e-03, -3.7193e-03,  2.5767e-02,  1.7168e-02,\n",
      "        -6.2503e-03, -2.7882e-02,  1.3542e-02, -1.1997e-02, -1.1625e-02,\n",
      "         9.9522e-03,  1.5666e-02, -1.7082e-02,  2.8804e-02, -3.4034e-03,\n",
      "         1.8514e-02,  1.8851e-02,  1.4937e-02, -2.3697e-02,  1.7843e-03,\n",
      "        -2.0339e-02])\n",
      "Layer: layer3.3.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])\n",
      "Layer: layer3.3.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.4.conv1.weight:, Weights: tensor([[[[ 1.7717e-02,  1.8377e-02,  1.2903e-02],\n",
      "          [ 1.4227e-02, -6.2482e-04,  1.1759e-02],\n",
      "          [-7.6831e-03, -2.9231e-03, -1.3416e-02]],\n",
      "\n",
      "         [[ 4.5384e-04,  1.4559e-02,  1.4375e-02],\n",
      "          [ 1.5460e-02, -8.2677e-05,  1.9830e-02],\n",
      "          [-6.6449e-04, -5.2229e-04,  1.0961e-02]],\n",
      "\n",
      "         [[-4.2464e-03,  1.0209e-02, -1.9131e-03],\n",
      "          [-1.4168e-02,  1.7869e-02,  1.3417e-02],\n",
      "          [-1.4690e-02,  7.2394e-03,  1.1000e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1592e-03, -4.1915e-03,  1.7594e-02],\n",
      "          [-9.5022e-03,  1.5988e-02, -1.9831e-02],\n",
      "          [ 1.1843e-02,  1.2227e-02, -9.4321e-03]],\n",
      "\n",
      "         [[ 1.7871e-03,  2.3399e-03, -4.6776e-03],\n",
      "          [-2.0100e-02, -8.3461e-03,  2.0414e-02],\n",
      "          [ 2.7899e-03, -5.6313e-03,  1.1053e-02]],\n",
      "\n",
      "         [[ 4.4861e-03, -1.4902e-02, -7.3818e-03],\n",
      "          [-1.0257e-02, -1.2117e-03,  1.5830e-02],\n",
      "          [ 1.3309e-02, -6.4525e-03,  1.2333e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3178e-02, -1.5394e-02,  1.6092e-02],\n",
      "          [ 9.4009e-03, -6.3906e-03, -7.9832e-03],\n",
      "          [ 1.2203e-02,  1.8624e-02, -1.0061e-02]],\n",
      "\n",
      "         [[-1.3584e-02, -2.0243e-02,  1.3556e-02],\n",
      "          [-2.0354e-02,  4.6022e-03,  3.4784e-03],\n",
      "          [-1.7436e-02,  7.5467e-03,  1.8790e-02]],\n",
      "\n",
      "         [[ 1.4358e-02, -1.2314e-02, -7.6378e-04],\n",
      "          [ 1.6318e-02,  1.1932e-02, -1.8953e-02],\n",
      "          [ 8.4929e-03,  1.8494e-02, -4.4149e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8989e-04, -8.9954e-03,  5.8124e-03],\n",
      "          [-1.8881e-02, -1.1004e-02,  1.4892e-02],\n",
      "          [-1.3205e-03,  7.4062e-03,  2.8575e-03]],\n",
      "\n",
      "         [[-5.6250e-03, -5.5524e-03, -9.4609e-03],\n",
      "          [ 9.5708e-03, -1.3496e-02, -1.5183e-02],\n",
      "          [-1.5074e-02, -9.5894e-04,  2.5195e-03]],\n",
      "\n",
      "         [[ 9.8850e-03,  7.8248e-03,  7.0096e-03],\n",
      "          [ 1.4590e-02,  1.8343e-02, -2.0234e-02],\n",
      "          [-1.6065e-02, -1.3212e-02, -1.3017e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5368e-02,  6.8442e-03, -4.1749e-03],\n",
      "          [ 3.7602e-03, -1.4357e-02, -3.4335e-03],\n",
      "          [ 4.6953e-03, -2.9264e-03,  2.3799e-03]],\n",
      "\n",
      "         [[-5.5680e-03,  7.5541e-03, -1.5519e-02],\n",
      "          [ 1.0741e-05, -1.7086e-02, -1.1462e-02],\n",
      "          [-2.0537e-02, -9.7711e-03,  1.5148e-02]],\n",
      "\n",
      "         [[ 1.6748e-02, -4.5254e-03,  6.7678e-04],\n",
      "          [ 2.7519e-03,  1.0698e-02,  8.2335e-03],\n",
      "          [ 1.3227e-02,  5.5870e-03,  7.1199e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8154e-02, -1.9680e-02,  6.7421e-03],\n",
      "          [ 1.7996e-02, -1.7282e-02,  6.2323e-03],\n",
      "          [ 1.8722e-02, -1.6084e-02,  1.4484e-02]],\n",
      "\n",
      "         [[-1.0651e-02, -1.7020e-02,  6.4093e-03],\n",
      "          [-1.2446e-02,  1.5970e-02, -3.1605e-04],\n",
      "          [ 1.6553e-03, -1.7332e-02,  9.5521e-03]],\n",
      "\n",
      "         [[ 1.1501e-02, -1.7543e-02, -2.8070e-03],\n",
      "          [ 4.3319e-03,  1.7019e-02,  3.3925e-03],\n",
      "          [-5.5735e-03, -1.9469e-02, -6.4529e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.6448e-02, -1.2454e-02, -1.2612e-02],\n",
      "          [ 1.0922e-02,  6.5391e-03, -2.0093e-02],\n",
      "          [ 4.9090e-03,  1.9262e-02, -1.2310e-03]],\n",
      "\n",
      "         [[-5.3921e-03,  1.8425e-02, -2.0289e-02],\n",
      "          [ 1.9832e-02,  1.5860e-02, -9.8644e-03],\n",
      "          [-2.0339e-02, -1.6596e-04, -7.4996e-03]],\n",
      "\n",
      "         [[ 1.6544e-02,  1.6453e-02, -1.0865e-03],\n",
      "          [ 8.1289e-03, -1.3505e-02, -8.8980e-03],\n",
      "          [-1.3286e-03, -1.6660e-03, -2.7742e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.6335e-03,  1.3788e-03, -6.7441e-03],\n",
      "          [-1.8212e-02, -1.2971e-03, -7.5415e-03],\n",
      "          [ 1.1519e-02, -8.3227e-03,  1.4424e-03]],\n",
      "\n",
      "         [[ 1.2934e-02,  7.6782e-03,  6.9856e-03],\n",
      "          [-1.9681e-02,  2.6851e-03, -1.3953e-02],\n",
      "          [ 7.7341e-03, -1.2149e-02, -3.4052e-03]],\n",
      "\n",
      "         [[-1.8611e-02,  6.8619e-03, -1.2210e-02],\n",
      "          [-1.3806e-02,  1.0731e-02, -1.9626e-02],\n",
      "          [-1.9257e-02, -1.5102e-02,  1.1210e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0962e-02,  1.4495e-02, -2.1990e-03],\n",
      "          [ 1.5690e-02,  1.7145e-02,  1.8714e-02],\n",
      "          [-8.2111e-03,  4.1015e-03,  1.2539e-02]],\n",
      "\n",
      "         [[-1.9570e-02, -5.5742e-03,  1.2889e-03],\n",
      "          [ 3.3389e-04,  2.3100e-03,  5.1847e-03],\n",
      "          [-1.5531e-02,  3.9673e-03, -1.3640e-02]],\n",
      "\n",
      "         [[-1.4459e-02,  2.0693e-02,  1.2118e-02],\n",
      "          [ 1.9665e-03,  1.7497e-02, -1.0534e-02],\n",
      "          [-2.0665e-03, -1.8626e-02,  1.1208e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8963e-02, -4.4551e-03,  5.3607e-03],\n",
      "          [-1.9522e-02, -7.6145e-03, -7.7861e-03],\n",
      "          [ 1.6131e-02,  2.0594e-03, -1.9926e-02]],\n",
      "\n",
      "         [[ 1.4339e-02, -1.5936e-02,  5.7985e-03],\n",
      "          [ 9.6623e-03,  8.2588e-03,  9.3317e-03],\n",
      "          [-1.0022e-02, -1.8005e-02,  1.0220e-02]],\n",
      "\n",
      "         [[-1.8191e-02,  9.1783e-03, -1.3820e-02],\n",
      "          [-3.4311e-03,  1.5292e-02, -3.8755e-03],\n",
      "          [-1.8864e-02, -1.7149e-02, -1.4877e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.0167e-03,  3.8396e-04, -4.8052e-03],\n",
      "          [ 1.7306e-03,  7.2370e-03, -3.4931e-03],\n",
      "          [ 9.0188e-03,  1.5107e-02, -1.4088e-02]],\n",
      "\n",
      "         [[ 1.4557e-02,  1.7153e-03, -1.5338e-02],\n",
      "          [ 1.4916e-02,  1.4468e-02, -1.2031e-02],\n",
      "          [ 2.9786e-03,  1.2585e-02,  9.9771e-03]],\n",
      "\n",
      "         [[-1.4256e-02,  1.4539e-02,  1.1693e-02],\n",
      "          [ 1.1587e-02, -1.7129e-02, -5.9739e-03],\n",
      "          [-1.7399e-03, -1.6177e-02, -1.6202e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7581e-02,  1.1620e-02, -2.0736e-02],\n",
      "          [ 1.4535e-02, -1.3370e-03,  7.4277e-03],\n",
      "          [-6.6658e-03, -1.6821e-02,  4.3832e-03]],\n",
      "\n",
      "         [[-1.7484e-02,  4.2807e-04,  1.1033e-02],\n",
      "          [-2.0426e-02, -4.2890e-03, -9.0694e-03],\n",
      "          [ 1.5522e-02, -7.8329e-03,  1.2789e-02]],\n",
      "\n",
      "         [[-1.8450e-02, -4.0668e-03,  8.3246e-03],\n",
      "          [-6.9835e-03,  2.1873e-04,  6.0030e-03],\n",
      "          [-1.7795e-02,  1.1587e-02, -4.4738e-03]]]])\n",
      "Layer: layer3.4.conv1.bias, Biases: tensor([-1.9552e-02,  1.1601e-02, -1.4863e-02,  4.9287e-04,  1.6110e-02,\n",
      "        -1.8303e-02,  8.1166e-03,  2.4999e-03, -1.8352e-02, -2.2005e-03,\n",
      "         1.9183e-02, -1.3167e-02, -1.6111e-03, -7.6473e-03, -1.9141e-02,\n",
      "        -1.6467e-02, -1.5412e-02,  1.8147e-02, -8.1699e-03, -1.8649e-02,\n",
      "        -1.5542e-02, -3.5432e-03,  1.2628e-02, -4.6160e-03,  7.9253e-03,\n",
      "        -5.4980e-03,  1.8880e-02,  1.1627e-03,  1.5271e-02, -8.3330e-03,\n",
      "         5.8191e-03, -9.4633e-03,  7.3622e-04, -1.7591e-02,  1.3863e-02,\n",
      "         1.8693e-02,  1.8134e-02, -1.2288e-02,  9.1464e-03, -1.2187e-02,\n",
      "         1.4885e-02, -2.0244e-02, -3.9188e-03,  1.8675e-02,  7.0228e-03,\n",
      "        -9.9333e-03, -2.0137e-02,  5.6621e-03, -1.9264e-02,  1.5727e-02,\n",
      "         5.4244e-03,  1.3055e-03, -2.0730e-02, -7.8158e-03,  4.3893e-03,\n",
      "         1.1554e-02, -5.5127e-03, -1.9544e-02,  1.4660e-02, -1.7486e-02,\n",
      "         2.2023e-03, -3.5072e-03, -6.6263e-03,  2.0581e-02,  1.1847e-02,\n",
      "         2.0721e-02,  1.4346e-02, -3.7834e-03, -1.0937e-02,  8.1568e-03,\n",
      "        -4.0343e-03, -1.8034e-02,  1.1673e-02, -1.9214e-03,  3.5569e-03,\n",
      "        -1.1654e-02,  9.2772e-03,  1.5089e-02, -1.3751e-02, -1.8758e-02,\n",
      "         1.6037e-02,  4.7618e-03, -1.2033e-02,  1.6091e-02, -5.6663e-03,\n",
      "         1.7085e-02, -3.8473e-03, -1.6463e-02,  7.3139e-03, -1.8445e-02,\n",
      "        -1.5525e-02, -1.9985e-02,  7.6621e-03,  1.3016e-03, -1.6896e-02,\n",
      "        -9.0638e-03,  6.4486e-04,  1.2868e-02,  6.9577e-03, -6.6303e-05,\n",
      "         1.0868e-02,  1.2106e-02, -1.4599e-02, -1.8920e-02, -8.4143e-03,\n",
      "        -1.6284e-02, -1.6990e-03,  1.7310e-02, -1.6221e-02, -9.3830e-03,\n",
      "         7.5949e-03,  1.2527e-02, -1.4244e-02,  1.8417e-02,  3.5580e-03,\n",
      "        -1.1185e-02,  1.3274e-02,  6.9962e-03,  1.6647e-02,  4.8160e-03,\n",
      "        -1.6811e-02,  1.7860e-02,  5.5111e-03,  3.5028e-03, -1.6742e-02,\n",
      "        -9.3451e-03,  8.5412e-03, -1.1643e-02])\n",
      "Layer: layer3.4.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Layer: layer3.4.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.4.conv2.weight:, Weights: tensor([[[[-1.2675e-02,  1.4682e-02,  3.9216e-03],\n",
      "          [ 3.1781e-03,  5.6845e-03,  2.2956e-02],\n",
      "          [-9.0164e-03, -7.1006e-03, -2.8482e-02]],\n",
      "\n",
      "         [[ 2.3481e-02, -1.4315e-02, -2.6477e-04],\n",
      "          [ 2.4666e-02, -1.9368e-02,  2.7251e-02],\n",
      "          [-2.8383e-02,  1.1683e-03,  2.2322e-02]],\n",
      "\n",
      "         [[-5.1654e-03,  6.8924e-03,  1.7422e-02],\n",
      "          [ 2.6694e-02, -3.8916e-03, -3.5816e-03],\n",
      "          [-1.0669e-02,  1.5692e-02,  1.3204e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1508e-02,  1.9764e-02,  5.8240e-03],\n",
      "          [ 2.1295e-02, -1.2134e-02, -2.5165e-02],\n",
      "          [ 1.4874e-02,  2.4076e-02, -9.4630e-03]],\n",
      "\n",
      "         [[ 2.0122e-02, -2.4937e-02, -2.3418e-02],\n",
      "          [-7.9038e-03,  7.6172e-03,  2.5049e-02],\n",
      "          [ 8.2024e-04,  1.7601e-02,  2.7591e-02]],\n",
      "\n",
      "         [[-2.4477e-02, -1.8452e-02,  7.5442e-03],\n",
      "          [-6.1654e-03,  2.8528e-02,  3.0428e-03],\n",
      "          [ 5.5806e-03, -1.0601e-02,  2.5516e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5632e-04, -1.5614e-02,  1.7887e-03],\n",
      "          [-3.2480e-03, -2.2000e-02,  2.1571e-03],\n",
      "          [-1.9650e-02,  2.5100e-02,  2.6681e-02]],\n",
      "\n",
      "         [[-2.1241e-02,  2.3566e-02, -2.5912e-02],\n",
      "          [-1.7290e-02, -1.7789e-02,  2.2987e-02],\n",
      "          [ 2.7013e-02,  2.6046e-02,  1.5306e-02]],\n",
      "\n",
      "         [[-2.1262e-02, -1.7582e-02, -2.4514e-02],\n",
      "          [-9.2801e-03,  1.0182e-02, -8.5126e-03],\n",
      "          [ 1.6339e-02,  1.9756e-02, -5.1928e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5311e-02,  2.8546e-02,  1.6675e-02],\n",
      "          [ 2.2742e-02,  5.1037e-03,  2.3895e-02],\n",
      "          [-2.6632e-02, -2.8093e-02,  1.7560e-02]],\n",
      "\n",
      "         [[ 9.0182e-03, -2.3327e-02,  3.2757e-03],\n",
      "          [-6.4831e-04,  2.6301e-02,  2.0833e-02],\n",
      "          [-2.7711e-02, -7.0851e-03, -2.0510e-02]],\n",
      "\n",
      "         [[ 2.9404e-03, -2.8691e-02,  3.3089e-03],\n",
      "          [-9.7295e-03, -7.6155e-04, -2.0735e-02],\n",
      "          [ 1.9415e-04, -1.3791e-02,  1.5905e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4213e-02,  1.6184e-02,  9.8031e-04],\n",
      "          [-8.4011e-03, -1.1113e-02,  1.5964e-02],\n",
      "          [-2.3425e-02, -5.2163e-03,  2.9520e-03]],\n",
      "\n",
      "         [[-5.4220e-03, -3.6643e-03, -6.7599e-03],\n",
      "          [-2.1210e-02, -1.5467e-02,  2.9327e-02],\n",
      "          [ 2.8498e-02,  1.9723e-02,  1.2326e-02]],\n",
      "\n",
      "         [[ 2.9030e-02, -1.7546e-02,  1.2386e-02],\n",
      "          [-1.9041e-02,  7.0389e-03, -1.7412e-02],\n",
      "          [-2.9364e-02, -1.6101e-02,  1.5048e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1754e-02,  1.1496e-02,  8.5376e-03],\n",
      "          [-1.6780e-02, -1.2788e-03, -1.0547e-02],\n",
      "          [-1.5878e-02,  9.2171e-03, -9.1331e-03]],\n",
      "\n",
      "         [[ 1.5723e-02,  1.3715e-02, -1.8785e-02],\n",
      "          [ 2.9539e-03, -1.9156e-02, -1.0857e-02],\n",
      "          [ 1.1614e-02, -1.9473e-02, -1.2673e-02]],\n",
      "\n",
      "         [[ 6.4880e-03, -1.7726e-02,  1.0066e-03],\n",
      "          [-2.1737e-03, -3.0453e-03, -1.5412e-02],\n",
      "          [ 5.9468e-03, -1.6767e-02,  1.5365e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.7858e-02,  2.8065e-02,  7.2873e-03],\n",
      "          [-1.3213e-02,  2.8997e-03, -2.5841e-02],\n",
      "          [ 2.0436e-02, -3.1086e-04, -1.2100e-02]],\n",
      "\n",
      "         [[ 2.9138e-02,  7.4922e-03,  2.5208e-02],\n",
      "          [ 1.4133e-02,  1.7729e-02,  2.5896e-02],\n",
      "          [ 9.4538e-03, -1.2651e-02,  9.0483e-03]],\n",
      "\n",
      "         [[-2.3392e-02,  1.1040e-03,  3.3304e-03],\n",
      "          [-2.6396e-02, -2.5356e-03, -3.6490e-03],\n",
      "          [-1.3170e-02, -2.3745e-02,  2.0890e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7097e-02,  7.9313e-03, -1.2659e-02],\n",
      "          [ 3.7945e-03, -1.9760e-02,  5.3036e-03],\n",
      "          [-2.2011e-02,  4.4196e-03,  2.7915e-02]],\n",
      "\n",
      "         [[-4.4348e-04, -1.7579e-02, -2.5419e-03],\n",
      "          [ 2.1632e-02, -2.5553e-02, -4.7317e-03],\n",
      "          [ 5.8174e-04,  1.8015e-02, -1.9883e-02]],\n",
      "\n",
      "         [[ 1.9494e-02, -2.8190e-02,  1.9873e-04],\n",
      "          [ 1.3855e-02, -2.9266e-02,  2.6862e-02],\n",
      "          [-1.7597e-03,  1.6317e-02, -9.5169e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6005e-02, -1.5600e-03, -6.1803e-04],\n",
      "          [-2.5273e-02,  8.6617e-03,  1.3461e-03],\n",
      "          [ 1.8217e-02,  2.3079e-02, -2.6628e-02]],\n",
      "\n",
      "         [[-1.9443e-02, -1.1889e-02, -2.4627e-02],\n",
      "          [-7.2264e-03,  1.8311e-02,  3.9499e-03],\n",
      "          [-1.4794e-03,  3.2965e-03, -2.2219e-02]],\n",
      "\n",
      "         [[ 5.4523e-03,  1.4497e-02, -1.5435e-02],\n",
      "          [-3.5336e-03, -9.2945e-03, -2.3903e-02],\n",
      "          [-1.1137e-02,  2.8659e-02,  1.2705e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2347e-03,  2.5823e-04,  1.7898e-02],\n",
      "          [ 8.3937e-03, -3.3594e-03,  3.4599e-04],\n",
      "          [ 1.7143e-02,  6.5127e-05, -2.9861e-03]],\n",
      "\n",
      "         [[-1.6513e-02, -9.3919e-03, -1.8150e-04],\n",
      "          [ 9.3873e-03, -2.4144e-02, -7.4727e-03],\n",
      "          [ 1.0191e-03,  1.4101e-03, -9.5917e-03]],\n",
      "\n",
      "         [[ 1.2844e-02, -6.9488e-03,  2.7296e-02],\n",
      "          [ 1.1260e-02, -2.5573e-02, -1.0275e-02],\n",
      "          [ 2.3337e-02,  1.8923e-02,  1.8968e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0992e-03,  1.9487e-02,  6.7712e-05],\n",
      "          [ 1.1815e-02, -2.3600e-02, -2.4152e-02],\n",
      "          [-2.9236e-02,  1.6207e-02,  2.3504e-02]],\n",
      "\n",
      "         [[ 6.9700e-03, -1.8734e-02, -1.6740e-02],\n",
      "          [ 2.0953e-02,  1.6150e-02, -2.0910e-02],\n",
      "          [-1.3314e-02, -9.6109e-03, -2.2019e-02]],\n",
      "\n",
      "         [[ 1.1454e-04, -1.2891e-02,  1.2624e-02],\n",
      "          [ 2.4415e-02,  2.7938e-02,  6.7416e-03],\n",
      "          [ 1.2504e-02, -2.0480e-02, -2.9141e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7949e-02,  1.1133e-02,  1.5504e-02],\n",
      "          [ 1.7221e-02,  2.8001e-02,  1.2907e-02],\n",
      "          [-7.7067e-03,  2.6836e-02, -2.5350e-02]],\n",
      "\n",
      "         [[ 1.0076e-02,  1.5232e-02,  2.6311e-02],\n",
      "          [-2.3421e-02,  2.0085e-02,  2.2822e-02],\n",
      "          [-1.9201e-02, -1.7298e-02,  4.1557e-03]],\n",
      "\n",
      "         [[ 9.6104e-03, -1.7478e-02, -2.2677e-02],\n",
      "          [ 2.1896e-02,  1.0649e-02, -5.8115e-03],\n",
      "          [-7.5604e-03,  8.8869e-03, -9.1629e-03]]]])\n",
      "Layer: layer3.4.conv2.bias, Biases: tensor([ 0.0283, -0.0139, -0.0019, -0.0084,  0.0251, -0.0119,  0.0124, -0.0046,\n",
      "         0.0140,  0.0011, -0.0284, -0.0233, -0.0082,  0.0234,  0.0221, -0.0265,\n",
      "        -0.0202, -0.0249, -0.0237,  0.0277, -0.0039, -0.0026,  0.0153, -0.0228,\n",
      "         0.0174, -0.0269,  0.0218,  0.0119, -0.0154, -0.0141,  0.0192,  0.0255,\n",
      "         0.0076, -0.0053,  0.0072, -0.0013, -0.0064, -0.0049,  0.0235, -0.0082,\n",
      "        -0.0235,  0.0092,  0.0293,  0.0286, -0.0154, -0.0033, -0.0102,  0.0013,\n",
      "        -0.0189, -0.0011, -0.0171, -0.0133,  0.0123, -0.0138,  0.0037, -0.0278,\n",
      "         0.0223, -0.0002,  0.0199, -0.0115,  0.0092, -0.0252, -0.0271, -0.0037,\n",
      "        -0.0225, -0.0094, -0.0225,  0.0181,  0.0036, -0.0095,  0.0149, -0.0129,\n",
      "         0.0146,  0.0101, -0.0105,  0.0151,  0.0024, -0.0262, -0.0148,  0.0240,\n",
      "         0.0240,  0.0266, -0.0284, -0.0032,  0.0021, -0.0120,  0.0078, -0.0190,\n",
      "        -0.0277, -0.0138, -0.0246, -0.0253,  0.0264, -0.0255,  0.0091, -0.0010,\n",
      "        -0.0030, -0.0060,  0.0080,  0.0088,  0.0090,  0.0277,  0.0042,  0.0036,\n",
      "         0.0077, -0.0264,  0.0121,  0.0027, -0.0057,  0.0002, -0.0278, -0.0094,\n",
      "        -0.0103, -0.0289,  0.0025,  0.0136,  0.0151, -0.0238,  0.0203, -0.0077,\n",
      "        -0.0017,  0.0139,  0.0078, -0.0243,  0.0154, -0.0274, -0.0172, -0.0239,\n",
      "        -0.0137, -0.0191, -0.0199, -0.0205,  0.0242, -0.0230,  0.0123, -0.0139,\n",
      "         0.0239,  0.0223,  0.0005,  0.0101, -0.0016, -0.0124,  0.0006, -0.0107,\n",
      "        -0.0017,  0.0156, -0.0286, -0.0047, -0.0175, -0.0135,  0.0080, -0.0201,\n",
      "        -0.0184,  0.0169,  0.0220, -0.0130, -0.0260, -0.0215, -0.0146,  0.0193,\n",
      "         0.0224,  0.0121, -0.0252,  0.0150, -0.0118,  0.0032,  0.0202,  0.0072,\n",
      "        -0.0237, -0.0227,  0.0245,  0.0121, -0.0054,  0.0136,  0.0092,  0.0009,\n",
      "        -0.0174, -0.0141, -0.0044, -0.0130,  0.0159, -0.0010,  0.0078, -0.0103,\n",
      "         0.0036,  0.0279,  0.0125,  0.0253, -0.0097,  0.0213, -0.0246,  0.0043,\n",
      "         0.0212,  0.0224,  0.0290, -0.0207,  0.0147, -0.0154,  0.0189,  0.0047,\n",
      "         0.0270,  0.0010,  0.0108, -0.0006,  0.0275,  0.0213, -0.0252,  0.0066,\n",
      "         0.0283, -0.0227, -0.0195, -0.0190, -0.0129, -0.0019, -0.0163, -0.0176,\n",
      "        -0.0027,  0.0020,  0.0101,  0.0135, -0.0043,  0.0150,  0.0280, -0.0118,\n",
      "        -0.0129, -0.0245,  0.0270, -0.0204,  0.0156, -0.0044,  0.0201, -0.0033,\n",
      "        -0.0026, -0.0127,  0.0127, -0.0144,  0.0254,  0.0154, -0.0043,  0.0084,\n",
      "         0.0264,  0.0119,  0.0169, -0.0104,  0.0191, -0.0141, -0.0176,  0.0179,\n",
      "         0.0165,  0.0129,  0.0260,  0.0081,  0.0130, -0.0111,  0.0191,  0.0067])\n",
      "Layer: layer3.4.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])\n",
      "Layer: layer3.4.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.5.conv1.weight:, Weights: tensor([[[[ 1.4063e-02, -6.5351e-03,  9.7084e-03],\n",
      "          [ 3.7131e-03,  9.2506e-03,  1.2195e-02],\n",
      "          [ 7.4943e-03, -5.1562e-03,  7.1293e-03]],\n",
      "\n",
      "         [[ 1.6627e-02, -1.2569e-02, -3.1486e-03],\n",
      "          [-3.5025e-03,  1.2093e-02,  1.9550e-02],\n",
      "          [ 1.1253e-02,  1.5260e-03, -1.8989e-02]],\n",
      "\n",
      "         [[-1.7556e-02, -1.7058e-02, -1.7543e-02],\n",
      "          [ 4.1629e-03, -1.9469e-02, -1.7610e-02],\n",
      "          [-1.2252e-02, -1.3087e-02,  3.9446e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6456e-02,  1.1783e-02, -1.0477e-02],\n",
      "          [-1.2805e-03, -1.4603e-02, -1.9794e-02],\n",
      "          [-1.2664e-02, -1.1576e-02,  1.2677e-02]],\n",
      "\n",
      "         [[-4.1328e-04, -1.5110e-02, -9.8101e-03],\n",
      "          [ 5.9594e-03,  1.6429e-02, -9.5605e-04],\n",
      "          [ 1.5621e-02, -8.5781e-03, -1.2618e-02]],\n",
      "\n",
      "         [[-7.2458e-03, -1.4695e-02, -1.9524e-02],\n",
      "          [-1.3890e-02, -1.2344e-02,  1.5153e-02],\n",
      "          [-2.6343e-03, -9.7764e-03,  1.5389e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7839e-02,  1.9235e-02, -5.8504e-03],\n",
      "          [ 1.5444e-02,  3.3959e-03,  8.9111e-03],\n",
      "          [ 1.9953e-02,  7.4457e-03, -4.5562e-03]],\n",
      "\n",
      "         [[ 1.5839e-02,  4.2155e-03,  7.7387e-03],\n",
      "          [-4.9083e-03, -1.4999e-02,  2.0823e-03],\n",
      "          [-8.9792e-03,  1.3187e-02, -7.4909e-03]],\n",
      "\n",
      "         [[-2.0660e-02, -5.9483e-03, -3.8287e-03],\n",
      "          [ 1.1203e-02, -5.6842e-04,  3.9543e-03],\n",
      "          [ 1.7459e-02, -1.1948e-02,  2.0122e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.1887e-03, -1.1874e-02, -2.2532e-03],\n",
      "          [-1.5443e-02, -1.3573e-02,  2.0406e-02],\n",
      "          [ 1.0617e-02,  1.9908e-02,  3.8492e-03]],\n",
      "\n",
      "         [[ 3.6748e-03, -1.3351e-02,  1.4459e-02],\n",
      "          [-1.7259e-02,  2.3338e-03, -1.4182e-02],\n",
      "          [ 1.5853e-02,  1.4711e-02, -1.0290e-02]],\n",
      "\n",
      "         [[-7.7291e-03, -1.2780e-02, -8.9924e-03],\n",
      "          [ 1.9094e-02, -8.9130e-03, -6.7865e-03],\n",
      "          [-2.1064e-03, -1.1235e-02,  1.1784e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5764e-03, -1.7696e-02,  1.3595e-02],\n",
      "          [-1.1732e-02,  1.8591e-03,  1.7384e-02],\n",
      "          [-1.1827e-02,  8.1780e-03,  1.5334e-02]],\n",
      "\n",
      "         [[-1.9140e-02,  1.2779e-02,  1.8974e-02],\n",
      "          [-1.9730e-02, -1.5743e-03, -1.8729e-02],\n",
      "          [-9.0003e-03, -3.1033e-03,  1.9514e-02]],\n",
      "\n",
      "         [[-1.5070e-02,  8.7183e-03,  1.6571e-02],\n",
      "          [ 8.0109e-03, -4.7224e-03,  1.6462e-02],\n",
      "          [-9.7118e-03,  8.8321e-04,  1.9452e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8633e-02,  1.6691e-03, -1.1905e-02],\n",
      "          [-9.6735e-03, -8.8522e-03,  1.5829e-02],\n",
      "          [-6.1276e-03,  1.1131e-03,  1.0770e-03]],\n",
      "\n",
      "         [[ 1.2038e-02,  5.4318e-03, -8.4230e-03],\n",
      "          [ 1.3016e-02,  1.1738e-02,  6.9896e-03],\n",
      "          [ 4.6895e-03, -1.9696e-02, -1.8905e-02]],\n",
      "\n",
      "         [[-1.7525e-02, -6.0148e-03,  3.2669e-03],\n",
      "          [ 1.8980e-02,  9.1147e-03,  1.1354e-02],\n",
      "          [-3.3099e-03, -1.8429e-02,  7.6238e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.5235e-03,  1.1716e-02,  5.1271e-03],\n",
      "          [-5.1550e-03,  1.5767e-02,  1.2046e-02],\n",
      "          [ 9.8270e-03,  9.5858e-03, -1.6207e-02]],\n",
      "\n",
      "         [[ 1.9402e-02,  1.9082e-02,  1.3427e-03],\n",
      "          [-1.7590e-02,  1.3247e-02,  9.9150e-03],\n",
      "          [ 6.2328e-03, -1.4411e-02, -9.9989e-03]],\n",
      "\n",
      "         [[ 7.4835e-03,  7.9605e-04,  1.1643e-02],\n",
      "          [-1.5763e-02, -1.6960e-02,  3.3483e-03],\n",
      "          [ 5.3535e-03, -1.6746e-02, -1.6471e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0723e-02,  1.6183e-03,  1.3426e-02],\n",
      "          [ 1.0102e-02,  7.5034e-03, -4.4337e-03],\n",
      "          [ 8.2394e-03, -8.7394e-03, -7.8439e-03]],\n",
      "\n",
      "         [[-3.2618e-03,  9.3239e-03, -8.2931e-03],\n",
      "          [ 3.0191e-03, -2.0750e-02, -9.0287e-03],\n",
      "          [-1.8609e-02,  1.4834e-02,  2.0159e-02]],\n",
      "\n",
      "         [[ 7.5700e-03, -1.9035e-02,  8.1365e-04],\n",
      "          [-1.2889e-02,  3.2541e-04, -6.1904e-03],\n",
      "          [ 1.7123e-02,  1.0604e-02, -1.7696e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9701e-03,  2.9280e-03,  1.7142e-02],\n",
      "          [ 5.4511e-03, -1.0412e-02,  1.5622e-02],\n",
      "          [ 9.5877e-03, -8.6693e-03,  3.7467e-03]],\n",
      "\n",
      "         [[ 7.6051e-03,  2.1124e-03, -1.0457e-02],\n",
      "          [-1.6252e-02,  8.4519e-03,  7.0628e-03],\n",
      "          [-3.5658e-03,  1.1039e-02,  1.1366e-02]],\n",
      "\n",
      "         [[-2.7721e-03, -1.4279e-03, -1.5728e-02],\n",
      "          [-4.0806e-03, -5.5320e-03,  1.6689e-02],\n",
      "          [-6.3075e-04, -6.9231e-03,  1.3226e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8893e-02,  1.6970e-04, -1.5352e-02],\n",
      "          [ 5.6581e-03,  1.5036e-02, -1.1856e-02],\n",
      "          [ 1.9989e-02, -5.2847e-03, -7.8578e-03]],\n",
      "\n",
      "         [[-1.1831e-02,  2.0244e-03,  1.3909e-02],\n",
      "          [-4.8217e-03,  5.9204e-03, -1.0540e-02],\n",
      "          [ 2.0950e-04, -1.1602e-02, -1.6087e-02]],\n",
      "\n",
      "         [[-3.6821e-05,  4.8314e-03, -1.8818e-02],\n",
      "          [ 3.5817e-03,  1.9098e-02, -1.1163e-02],\n",
      "          [ 1.4446e-02, -9.4079e-04, -1.1657e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8730e-02,  1.5348e-03, -5.8293e-03],\n",
      "          [-1.3960e-02, -1.2520e-02,  1.0542e-02],\n",
      "          [ 1.4838e-02,  1.5999e-02, -5.9570e-03]],\n",
      "\n",
      "         [[ 5.8263e-03, -3.1399e-03,  1.1179e-02],\n",
      "          [-7.3546e-03,  9.1628e-03,  1.6933e-02],\n",
      "          [-2.1130e-03,  2.9168e-03, -1.9387e-02]],\n",
      "\n",
      "         [[ 2.4207e-03, -6.4035e-04,  5.0658e-03],\n",
      "          [ 1.0441e-02, -1.7408e-02, -1.2243e-02],\n",
      "          [ 1.1704e-02, -1.9520e-02,  6.4316e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0641e-02, -1.4264e-02,  1.1193e-04],\n",
      "          [ 3.6888e-03, -1.9814e-02, -9.2840e-03],\n",
      "          [ 1.7518e-02, -6.9310e-05,  6.1064e-03]],\n",
      "\n",
      "         [[-1.9926e-02,  4.4270e-03, -1.8243e-02],\n",
      "          [ 3.1282e-03,  4.4948e-03, -1.6827e-02],\n",
      "          [-1.2788e-02,  1.0337e-02, -1.6616e-02]],\n",
      "\n",
      "         [[ 2.4548e-03, -3.5058e-03, -1.8489e-02],\n",
      "          [-1.4565e-02, -1.0071e-02,  1.5925e-02],\n",
      "          [-9.2355e-03,  2.0358e-02, -1.6510e-03]]]])\n",
      "Layer: layer3.5.conv1.bias, Biases: tensor([-1.1403e-02,  2.0274e-02, -1.4308e-02, -3.6400e-03,  9.3784e-03,\n",
      "         7.8423e-03,  1.6273e-02,  1.7628e-02, -6.4454e-04,  1.1722e-02,\n",
      "         1.4439e-03,  1.9177e-02,  4.2840e-03,  7.0357e-03, -8.5684e-03,\n",
      "        -4.0871e-03,  1.4427e-02, -1.6029e-02,  2.0593e-02,  1.3351e-02,\n",
      "         1.5411e-02,  8.4747e-04, -9.6069e-03, -1.5587e-02, -8.1341e-03,\n",
      "         9.3520e-03,  1.4566e-02,  9.8182e-03, -7.0589e-03,  1.5753e-02,\n",
      "        -7.2128e-03,  1.0758e-02, -5.8983e-03, -1.3810e-02, -1.3088e-02,\n",
      "         1.2672e-02,  2.0306e-02,  6.0098e-03,  1.0853e-02,  6.1920e-03,\n",
      "         8.4565e-03, -6.8192e-03,  1.0464e-02,  1.9562e-02, -3.4484e-03,\n",
      "        -1.2015e-02, -5.5106e-03, -3.9042e-03,  9.6547e-03,  1.3554e-04,\n",
      "         2.0172e-02, -1.1400e-02, -6.6593e-05, -8.0085e-04,  1.7156e-02,\n",
      "        -1.7736e-02, -1.5347e-02, -8.3464e-03,  1.5593e-02, -2.5990e-04,\n",
      "        -2.9441e-03,  2.5428e-03, -1.0230e-02,  1.0475e-02,  1.4526e-02,\n",
      "        -2.4977e-03, -8.7187e-04, -9.5219e-03, -1.4550e-02,  6.3225e-03,\n",
      "        -1.6511e-02,  6.6769e-03, -1.3499e-02,  9.7497e-03,  1.1144e-03,\n",
      "         1.8586e-02, -1.4458e-02, -1.6470e-02, -1.4901e-02, -1.1602e-02,\n",
      "        -7.8839e-04, -1.1285e-02, -1.9641e-02, -5.8586e-03, -2.0597e-02,\n",
      "        -1.4852e-02, -8.5122e-03, -8.9688e-03, -1.8456e-02,  1.1106e-03,\n",
      "         1.0762e-03, -2.6696e-03, -1.0656e-02, -6.3105e-03, -1.8649e-03,\n",
      "         2.7412e-03,  2.0443e-02,  1.9785e-03, -1.8311e-03,  2.0125e-02,\n",
      "        -1.9896e-02,  1.2872e-03, -1.4042e-02, -1.5062e-02, -8.0123e-03,\n",
      "        -1.4558e-02,  1.2490e-02,  1.0854e-02,  1.6954e-02,  1.5676e-02,\n",
      "         4.7023e-03,  1.7630e-03,  6.6052e-03, -2.0248e-02,  8.8033e-03,\n",
      "        -1.1691e-02,  1.5845e-02, -4.0632e-03,  6.1413e-03,  1.1912e-02,\n",
      "         6.2297e-03, -1.3056e-02, -3.4803e-03, -2.2879e-03,  1.6678e-02,\n",
      "        -6.7358e-03,  1.6663e-02, -6.9580e-03])\n",
      "Layer: layer3.5.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "Layer: layer3.5.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer3.5.conv2.weight:, Weights: tensor([[[[-1.7086e-02, -2.1740e-02,  2.3462e-02],\n",
      "          [ 2.3544e-02, -1.9923e-02, -1.0173e-02],\n",
      "          [ 2.5579e-02,  2.5246e-02, -5.2348e-03]],\n",
      "\n",
      "         [[ 1.5171e-02,  8.1667e-03,  2.0005e-02],\n",
      "          [ 1.1510e-03, -1.6908e-02, -8.5863e-03],\n",
      "          [-1.3682e-02,  1.3438e-02,  2.7647e-02]],\n",
      "\n",
      "         [[ 1.9773e-02,  9.2984e-03, -1.3361e-02],\n",
      "          [ 5.7354e-03, -2.7556e-02, -1.2043e-02],\n",
      "          [-1.4444e-02, -5.4954e-04,  1.8252e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9953e-02,  2.9445e-02, -7.8584e-03],\n",
      "          [ 2.4341e-02,  1.6616e-02, -2.0819e-02],\n",
      "          [-2.5230e-02, -9.6612e-03,  2.9179e-03]],\n",
      "\n",
      "         [[ 1.9594e-02, -1.3015e-02,  7.3520e-03],\n",
      "          [-1.9022e-02, -1.9583e-03,  8.9972e-03],\n",
      "          [-1.9229e-02,  1.3365e-02,  6.6772e-03]],\n",
      "\n",
      "         [[-2.4194e-02, -2.8117e-02, -2.6968e-02],\n",
      "          [ 2.3507e-02, -2.1490e-02,  1.3480e-02],\n",
      "          [ 2.2603e-02,  7.9096e-03, -4.3534e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1671e-02, -2.4964e-02, -2.6516e-02],\n",
      "          [ 2.5392e-02, -2.2086e-02, -1.9620e-02],\n",
      "          [-1.4990e-02, -2.2764e-02, -1.5331e-03]],\n",
      "\n",
      "         [[ 3.7293e-03,  1.2013e-04,  2.0393e-02],\n",
      "          [-1.5786e-02, -1.8848e-02,  1.1228e-02],\n",
      "          [ 2.5823e-02, -6.5443e-03, -2.5178e-02]],\n",
      "\n",
      "         [[-1.8174e-02, -1.7714e-02, -5.5330e-03],\n",
      "          [ 1.5251e-02, -3.0464e-03, -1.2729e-02],\n",
      "          [ 6.4855e-03,  1.9582e-02,  1.2473e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.1147e-03, -2.7255e-02,  1.6592e-02],\n",
      "          [ 1.0495e-02,  2.4346e-02,  2.5940e-02],\n",
      "          [-2.7584e-02,  9.3428e-03, -2.3703e-03]],\n",
      "\n",
      "         [[ 2.9117e-03,  1.4964e-02,  1.4162e-02],\n",
      "          [-1.0765e-02, -2.6973e-02,  1.9105e-02],\n",
      "          [-7.4680e-04,  2.6435e-02,  1.4585e-02]],\n",
      "\n",
      "         [[ 1.1230e-02, -6.7792e-03,  4.9552e-03],\n",
      "          [ 5.4756e-03, -1.1344e-02, -1.7843e-02],\n",
      "          [-2.1317e-02,  1.3734e-02,  1.5954e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0417e-03, -2.6887e-02, -7.4808e-03],\n",
      "          [-3.5321e-03, -1.4229e-02, -2.9036e-02],\n",
      "          [ 1.7356e-02, -8.1717e-03,  1.4468e-02]],\n",
      "\n",
      "         [[ 1.5212e-02, -2.6354e-02,  2.3781e-02],\n",
      "          [-1.9992e-02,  2.4728e-02,  1.2739e-02],\n",
      "          [ 2.6056e-02,  1.2441e-03,  1.7605e-02]],\n",
      "\n",
      "         [[-2.3924e-03,  1.2899e-02, -5.9748e-03],\n",
      "          [ 1.3529e-02,  3.1682e-03,  1.0938e-02],\n",
      "          [-2.2528e-02,  1.8919e-02, -1.3245e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1824e-02,  6.5382e-03,  3.1048e-03],\n",
      "          [ 5.2959e-03,  8.4892e-03, -1.3092e-02],\n",
      "          [ 1.1013e-02,  4.6874e-05, -6.5982e-03]],\n",
      "\n",
      "         [[-4.5286e-03, -1.7357e-02, -2.9085e-02],\n",
      "          [ 7.3800e-03, -3.6156e-03,  2.7255e-02],\n",
      "          [ 1.9293e-02,  2.0413e-02, -6.9807e-03]],\n",
      "\n",
      "         [[-8.1098e-03, -7.6262e-03, -2.8236e-02],\n",
      "          [ 1.4946e-02, -1.9086e-02,  1.9768e-02],\n",
      "          [-1.1294e-02, -2.2685e-02,  1.9724e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.5461e-03, -1.7557e-04, -2.6551e-02],\n",
      "          [-2.6264e-02,  1.6171e-03,  6.4158e-03],\n",
      "          [-8.7231e-03,  1.8397e-02, -2.7664e-02]],\n",
      "\n",
      "         [[-2.4794e-02, -9.3670e-03,  2.3118e-02],\n",
      "          [ 1.3547e-02, -8.5255e-04, -1.5167e-03],\n",
      "          [-2.4570e-03, -2.8320e-02,  3.0375e-03]],\n",
      "\n",
      "         [[-2.3656e-02, -2.8270e-02,  3.1007e-03],\n",
      "          [ 2.7336e-02, -1.9305e-02, -2.4807e-02],\n",
      "          [-2.3588e-02, -3.4826e-03,  2.8488e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1684e-02, -5.2288e-03,  2.9072e-02],\n",
      "          [-1.7428e-03, -9.3927e-04,  1.3542e-02],\n",
      "          [ 1.9051e-02, -1.0159e-02,  1.1656e-04]],\n",
      "\n",
      "         [[-2.0286e-02, -2.5255e-02,  1.9178e-02],\n",
      "          [ 1.8827e-02, -1.1311e-02, -1.1111e-02],\n",
      "          [-2.2793e-02, -2.3557e-02, -1.4361e-02]],\n",
      "\n",
      "         [[-9.4093e-03,  2.7815e-02, -2.8957e-02],\n",
      "          [ 2.7867e-02,  1.4229e-02,  1.5192e-02],\n",
      "          [ 8.6121e-03,  2.5807e-02, -2.5076e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8086e-02, -9.7974e-03,  1.3777e-02],\n",
      "          [-2.8672e-02,  7.5224e-03,  3.1372e-03],\n",
      "          [ 6.5458e-03,  2.6223e-02, -2.7255e-02]],\n",
      "\n",
      "         [[-2.6026e-02,  1.8870e-02, -6.4615e-04],\n",
      "          [ 2.1052e-02,  6.1192e-03, -5.2904e-03],\n",
      "          [-1.1020e-03,  1.6941e-02,  1.7182e-02]],\n",
      "\n",
      "         [[-1.0511e-02,  2.5293e-02,  1.6327e-02],\n",
      "          [-6.2949e-03,  2.7515e-02,  2.2955e-03],\n",
      "          [ 1.7602e-03, -4.0852e-03, -1.5455e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4849e-02,  2.7925e-02,  1.9314e-02],\n",
      "          [ 1.5913e-02, -7.8434e-03, -1.5395e-02],\n",
      "          [-2.2784e-02, -1.9599e-03,  8.1852e-03]],\n",
      "\n",
      "         [[-2.2229e-03,  8.2026e-03,  1.7231e-02],\n",
      "          [ 1.2005e-02,  6.3547e-03, -2.6741e-02],\n",
      "          [ 2.9395e-02,  1.5546e-02, -2.4681e-02]],\n",
      "\n",
      "         [[ 1.2655e-02,  2.3675e-02,  1.7865e-02],\n",
      "          [-1.9760e-02,  5.8188e-03,  5.5112e-03],\n",
      "          [ 1.5236e-02,  1.1841e-02,  9.9404e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1151e-02, -2.6133e-02,  3.9821e-03],\n",
      "          [ 1.3448e-02, -2.5008e-02, -1.0286e-02],\n",
      "          [ 2.5442e-02,  2.8689e-02, -1.4010e-02]],\n",
      "\n",
      "         [[ 1.6106e-02,  2.0090e-02, -2.3848e-02],\n",
      "          [-7.1392e-03, -3.7134e-03,  6.9891e-03],\n",
      "          [ 6.4927e-03, -1.0840e-03,  1.9143e-02]],\n",
      "\n",
      "         [[-1.7940e-02,  1.5705e-02, -2.9350e-02],\n",
      "          [-7.9361e-03, -1.4258e-02,  2.6707e-02],\n",
      "          [ 2.1082e-02, -2.1460e-03, -2.2827e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2494e-02, -1.0091e-03,  2.5705e-02],\n",
      "          [-1.6500e-02, -2.9835e-03,  4.3912e-03],\n",
      "          [ 1.1154e-02,  2.8547e-02, -1.0757e-02]],\n",
      "\n",
      "         [[-1.6010e-02,  1.0093e-02,  6.2696e-03],\n",
      "          [ 1.8062e-02, -1.2216e-02,  7.3732e-03],\n",
      "          [ 2.5313e-02,  1.4613e-02,  1.9470e-02]],\n",
      "\n",
      "         [[-2.6307e-02,  1.0728e-02, -2.2121e-02],\n",
      "          [-6.7487e-03, -1.3290e-02,  1.8116e-02],\n",
      "          [ 4.9398e-03,  2.8031e-02, -4.0504e-03]]]])\n",
      "Layer: layer3.5.conv2.bias, Biases: tensor([ 0.0215, -0.0128,  0.0027, -0.0237, -0.0098, -0.0083,  0.0273, -0.0183,\n",
      "        -0.0138, -0.0100, -0.0102, -0.0231,  0.0113,  0.0002,  0.0160, -0.0295,\n",
      "        -0.0052,  0.0136, -0.0271,  0.0279, -0.0147,  0.0164,  0.0110, -0.0023,\n",
      "        -0.0210,  0.0169, -0.0030,  0.0113,  0.0028,  0.0053,  0.0096,  0.0011,\n",
      "         0.0134,  0.0166,  0.0063, -0.0086, -0.0206, -0.0037,  0.0200,  0.0278,\n",
      "         0.0274, -0.0269,  0.0225,  0.0093,  0.0083,  0.0084,  0.0160,  0.0089,\n",
      "        -0.0189,  0.0161,  0.0257,  0.0204,  0.0162,  0.0124,  0.0041,  0.0111,\n",
      "        -0.0060, -0.0097,  0.0022,  0.0002, -0.0249,  0.0192,  0.0088,  0.0099,\n",
      "        -0.0265,  0.0212,  0.0128,  0.0108, -0.0078, -0.0046, -0.0101,  0.0203,\n",
      "        -0.0108,  0.0269,  0.0279, -0.0061,  0.0111, -0.0150,  0.0241, -0.0254,\n",
      "        -0.0090,  0.0183,  0.0131,  0.0281, -0.0226,  0.0275,  0.0194,  0.0260,\n",
      "         0.0086, -0.0004,  0.0173,  0.0041, -0.0095, -0.0087,  0.0150, -0.0089,\n",
      "         0.0248,  0.0103, -0.0138,  0.0105, -0.0123, -0.0168,  0.0286, -0.0041,\n",
      "         0.0058, -0.0016,  0.0111,  0.0087,  0.0115,  0.0075, -0.0106,  0.0267,\n",
      "         0.0079, -0.0243,  0.0138, -0.0138,  0.0288, -0.0166, -0.0257, -0.0220,\n",
      "        -0.0223, -0.0254, -0.0068, -0.0189, -0.0226,  0.0286, -0.0058,  0.0094,\n",
      "        -0.0222, -0.0224,  0.0071, -0.0117,  0.0202,  0.0207,  0.0076,  0.0063,\n",
      "        -0.0258, -0.0179,  0.0037,  0.0036,  0.0233, -0.0160,  0.0226,  0.0269,\n",
      "        -0.0071, -0.0224, -0.0109,  0.0002, -0.0097, -0.0133, -0.0201, -0.0008,\n",
      "        -0.0132,  0.0291, -0.0110, -0.0220,  0.0192, -0.0030, -0.0249,  0.0016,\n",
      "         0.0054, -0.0206, -0.0180, -0.0038,  0.0223,  0.0069, -0.0199, -0.0252,\n",
      "        -0.0103, -0.0037,  0.0258, -0.0031, -0.0131,  0.0219,  0.0106, -0.0250,\n",
      "        -0.0145,  0.0108,  0.0159, -0.0161, -0.0238,  0.0188, -0.0181,  0.0202,\n",
      "        -0.0195,  0.0210,  0.0070, -0.0221,  0.0277,  0.0020,  0.0245, -0.0252,\n",
      "         0.0102, -0.0211, -0.0210, -0.0160,  0.0291,  0.0221,  0.0259, -0.0168,\n",
      "        -0.0186,  0.0203,  0.0237, -0.0246,  0.0078, -0.0279,  0.0255, -0.0160,\n",
      "        -0.0159,  0.0237,  0.0151,  0.0138, -0.0035, -0.0284,  0.0064,  0.0225,\n",
      "         0.0072, -0.0080, -0.0268,  0.0106, -0.0139,  0.0069, -0.0170, -0.0171,\n",
      "         0.0063,  0.0011,  0.0008,  0.0072, -0.0278,  0.0238,  0.0143, -0.0008,\n",
      "        -0.0084, -0.0196,  0.0107,  0.0107,  0.0227,  0.0135, -0.0272,  0.0250,\n",
      "         0.0087,  0.0245, -0.0048, -0.0231, -0.0064, -0.0101, -0.0187, -0.0189,\n",
      "        -0.0245,  0.0146,  0.0069, -0.0078,  0.0129, -0.0226,  0.0200,  0.0115])\n",
      "Layer: layer3.5.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])\n",
      "Layer: layer3.5.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer4.0.conv1.weight:, Weights: tensor([[[[ 7.7937e-03,  1.7812e-02,  1.9990e-02],\n",
      "          [-1.2696e-02, -6.3358e-03, -1.6919e-02],\n",
      "          [-4.2968e-03, -1.6635e-02, -1.5872e-02]],\n",
      "\n",
      "         [[-3.2177e-03,  1.3733e-02, -1.3854e-02],\n",
      "          [ 9.4776e-04,  1.2904e-02, -1.6534e-02],\n",
      "          [-1.7015e-02,  5.2757e-03,  1.8916e-02]],\n",
      "\n",
      "         [[-7.6561e-03, -8.5029e-03,  1.9207e-02],\n",
      "          [ 3.6392e-03,  4.1858e-03,  1.1702e-02],\n",
      "          [ 1.4876e-02,  2.1944e-03, -1.3936e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0539e-02,  1.6815e-02,  1.3276e-02],\n",
      "          [-1.2186e-02,  1.2356e-02,  1.0490e-02],\n",
      "          [-1.2127e-02,  2.9817e-03,  1.3889e-02]],\n",
      "\n",
      "         [[ 1.0989e-02, -1.2273e-02, -1.6357e-02],\n",
      "          [ 1.2818e-02,  8.3168e-03,  1.1951e-02],\n",
      "          [-3.1181e-03,  2.8195e-03, -2.7594e-03]],\n",
      "\n",
      "         [[-2.6014e-03, -1.7644e-02,  1.3119e-02],\n",
      "          [ 7.0192e-04, -1.0287e-02,  1.1842e-02],\n",
      "          [-4.6554e-03,  1.4200e-02,  8.7272e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.1057e-03, -1.0597e-02, -1.2882e-02],\n",
      "          [-1.9878e-02, -1.0196e-03, -1.9427e-02],\n",
      "          [-6.0727e-03,  8.6667e-03, -1.2800e-02]],\n",
      "\n",
      "         [[ 8.2985e-03, -1.2745e-02,  1.9247e-02],\n",
      "          [-9.8376e-03, -6.7932e-03,  1.6039e-02],\n",
      "          [ 9.8697e-03, -1.4076e-02, -1.7010e-03]],\n",
      "\n",
      "         [[ 1.2273e-02, -1.1388e-02, -1.0625e-02],\n",
      "          [ 1.9979e-02, -1.8514e-02, -2.0597e-02],\n",
      "          [-1.8571e-02,  2.0175e-03,  6.5587e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5665e-04, -5.7941e-03,  5.4647e-03],\n",
      "          [-1.2155e-02,  1.5455e-02,  4.6434e-04],\n",
      "          [ 7.2016e-03, -5.2065e-03, -1.3342e-02]],\n",
      "\n",
      "         [[-1.5172e-02, -1.7154e-02, -4.6846e-03],\n",
      "          [-3.3802e-03, -6.3579e-03, -1.5908e-02],\n",
      "          [-1.0349e-02, -1.4800e-02,  2.1825e-03]],\n",
      "\n",
      "         [[ 1.2762e-02, -6.4953e-03, -1.3468e-02],\n",
      "          [-7.4469e-03,  1.1775e-02, -1.5042e-03],\n",
      "          [-1.6509e-02,  1.0830e-02,  8.7013e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6380e-03,  1.4335e-02,  1.2738e-03],\n",
      "          [-1.5078e-02, -2.0597e-02, -4.3055e-03],\n",
      "          [-1.7461e-02, -9.6591e-03,  1.5535e-02]],\n",
      "\n",
      "         [[ 4.0034e-03,  2.0551e-02,  1.2359e-02],\n",
      "          [-1.6861e-02, -8.5024e-03, -1.3944e-02],\n",
      "          [-1.9382e-02,  9.3863e-03,  7.0540e-04]],\n",
      "\n",
      "         [[-1.4580e-02,  1.1428e-02,  2.6067e-03],\n",
      "          [ 2.0061e-02,  1.0667e-02, -3.1257e-03],\n",
      "          [ 3.9472e-03,  1.1503e-02,  1.6634e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.3274e-03,  1.1988e-02,  1.6506e-02],\n",
      "          [-1.7836e-02, -1.6469e-02,  1.6481e-02],\n",
      "          [ 2.0497e-02,  1.0653e-02,  1.4654e-02]],\n",
      "\n",
      "         [[ 1.0312e-02,  1.8352e-02,  1.6613e-03],\n",
      "          [-2.0260e-02, -1.2724e-02,  1.4594e-02],\n",
      "          [ 6.9706e-03,  1.9385e-02,  8.4110e-03]],\n",
      "\n",
      "         [[ 1.2790e-02, -5.6625e-04,  1.5019e-03],\n",
      "          [ 8.4027e-03,  4.5421e-03,  6.4166e-04],\n",
      "          [ 1.2145e-02,  2.0537e-02, -1.0268e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.9835e-02, -7.5860e-03, -1.4124e-02],\n",
      "          [-1.4638e-02, -1.7009e-02,  1.4205e-02],\n",
      "          [ 7.1121e-03,  1.2729e-02, -7.9277e-03]],\n",
      "\n",
      "         [[ 1.6195e-02, -1.4849e-03, -1.4760e-02],\n",
      "          [-1.9153e-03, -4.5334e-03,  5.2514e-03],\n",
      "          [-6.7428e-03,  8.2628e-03,  3.3665e-03]],\n",
      "\n",
      "         [[-3.0847e-03,  7.8160e-03,  3.0928e-03],\n",
      "          [-1.3426e-02,  8.2821e-03,  5.3282e-03],\n",
      "          [-1.7139e-02, -4.6486e-04,  2.0329e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3432e-02,  3.7125e-03,  4.2754e-03],\n",
      "          [-5.7756e-03, -1.6005e-02, -1.1565e-02],\n",
      "          [-1.9737e-03, -8.7233e-03, -1.4648e-02]],\n",
      "\n",
      "         [[-1.5833e-02, -1.3535e-02,  2.0344e-02],\n",
      "          [-1.1269e-02, -2.0551e-02,  1.9407e-02],\n",
      "          [ 1.0553e-02, -3.2318e-03, -3.4873e-03]],\n",
      "\n",
      "         [[ 1.0072e-02, -1.0812e-02,  1.1637e-02],\n",
      "          [-1.5967e-02, -1.7858e-02,  4.1217e-03],\n",
      "          [ 1.0777e-02,  6.1421e-04,  2.1674e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0246e-02,  5.1125e-04, -1.7639e-02],\n",
      "          [ 3.6429e-04,  1.6292e-02,  1.1640e-05],\n",
      "          [ 6.9198e-03,  5.6951e-03, -1.5819e-02]],\n",
      "\n",
      "         [[ 8.5920e-03,  1.3466e-03, -7.3655e-03],\n",
      "          [-1.5654e-02,  1.6340e-02,  1.4650e-02],\n",
      "          [-1.3641e-02,  1.0243e-02, -6.2879e-03]],\n",
      "\n",
      "         [[ 1.4033e-02,  1.5415e-02, -3.7527e-03],\n",
      "          [-1.2925e-02,  1.8385e-02, -1.7432e-02],\n",
      "          [ 1.9038e-02, -1.2172e-02, -8.0152e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.7149e-03, -1.7363e-02, -1.0611e-02],\n",
      "          [ 1.7058e-02, -1.1908e-02, -4.9495e-03],\n",
      "          [ 1.0931e-02,  8.6683e-04, -3.5626e-03]],\n",
      "\n",
      "         [[-1.1666e-02,  5.8550e-04, -5.7811e-03],\n",
      "          [ 9.0430e-03, -9.7203e-05, -1.1237e-02],\n",
      "          [ 7.5048e-03,  7.5428e-03, -9.3112e-03]],\n",
      "\n",
      "         [[ 1.8582e-02,  5.8815e-03, -6.8852e-03],\n",
      "          [ 8.8416e-03,  4.6280e-03, -1.8204e-02],\n",
      "          [-8.7539e-03, -1.4730e-02, -7.9480e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4170e-02, -1.7831e-02,  1.8115e-02],\n",
      "          [ 2.0082e-02,  1.9052e-02, -1.9476e-02],\n",
      "          [-7.2147e-03, -1.0400e-03,  4.5951e-03]],\n",
      "\n",
      "         [[-3.7376e-03,  1.0553e-02,  4.6852e-03],\n",
      "          [-4.2597e-03, -1.6665e-03, -2.0155e-02],\n",
      "          [-4.2315e-03,  4.4902e-03, -9.2281e-03]],\n",
      "\n",
      "         [[-1.8690e-02,  5.5746e-03,  1.5003e-02],\n",
      "          [ 7.2350e-03,  1.2360e-02,  1.3277e-02],\n",
      "          [-9.7958e-03, -4.0638e-03, -1.9201e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0995e-02,  1.5403e-02,  3.7262e-03],\n",
      "          [-1.6024e-02, -1.3632e-04,  1.7254e-04],\n",
      "          [ 1.9854e-02,  2.3464e-03, -1.2245e-02]],\n",
      "\n",
      "         [[ 6.9213e-03,  5.0907e-03, -9.4825e-03],\n",
      "          [ 1.1205e-02,  3.4871e-03, -1.2016e-02],\n",
      "          [ 5.9924e-03,  1.9403e-02,  1.7763e-02]],\n",
      "\n",
      "         [[ 1.5009e-02, -1.8901e-03, -1.6815e-02],\n",
      "          [ 1.0107e-02, -1.7910e-02, -3.2225e-03],\n",
      "          [-1.0375e-02,  1.5156e-02,  5.0047e-03]]]])\n",
      "Layer: layer4.0.conv1.bias, Biases: tensor([ 2.0704e-02,  7.2959e-03, -1.7644e-02,  1.6730e-02, -1.5271e-03,\n",
      "         1.6280e-02, -1.0697e-02,  4.0745e-04,  2.0151e-02, -6.3529e-03,\n",
      "        -2.0121e-02, -1.1209e-02,  1.6409e-02,  3.7158e-03, -1.3446e-03,\n",
      "        -3.6464e-03, -4.9187e-03,  4.3859e-03,  5.1671e-03,  8.0008e-03,\n",
      "         1.9355e-02, -1.9166e-02,  2.0190e-02,  5.1684e-04, -7.5938e-03,\n",
      "        -9.4820e-03, -1.0803e-02, -9.9827e-03, -6.0517e-03, -1.1716e-02,\n",
      "        -2.0191e-02, -1.8864e-02, -1.5771e-02, -1.4146e-02, -1.7109e-02,\n",
      "        -9.4665e-03,  9.3943e-03,  1.7237e-02,  9.8405e-05, -1.5486e-02,\n",
      "         1.8790e-02,  2.2031e-03, -1.0600e-02,  1.7723e-02,  1.8190e-02,\n",
      "        -9.2081e-03,  1.5161e-02,  1.0554e-02, -1.7723e-02, -7.4134e-03,\n",
      "         7.6429e-03, -1.1435e-03, -4.4703e-03,  4.7848e-03,  1.8885e-02,\n",
      "        -1.6595e-02, -1.8325e-02, -3.0712e-03,  1.2601e-02, -3.9330e-04,\n",
      "         1.5717e-02, -2.0553e-02,  5.8482e-03,  1.8153e-02,  3.5750e-03,\n",
      "        -1.2983e-02, -2.5695e-03,  2.6829e-03,  1.9035e-03,  9.8838e-03,\n",
      "        -8.0516e-03,  1.2398e-02,  2.2708e-03, -1.0460e-02, -4.6788e-03,\n",
      "        -1.9988e-02,  3.7211e-03, -9.7425e-03,  1.0918e-02,  1.7109e-02,\n",
      "         2.7003e-03, -1.2090e-02, -1.4614e-02, -7.3356e-04,  1.2809e-02,\n",
      "         6.4669e-03, -1.8960e-02, -2.0703e-02, -4.0450e-03,  6.7687e-03,\n",
      "         9.7604e-03, -9.9619e-03, -1.3753e-02, -1.6257e-04,  1.9875e-02,\n",
      "         4.7994e-03, -1.4276e-02,  1.7938e-02,  1.9032e-02,  1.2306e-02,\n",
      "         1.2084e-02, -7.2751e-03,  3.5492e-03, -4.8634e-03, -1.3408e-02,\n",
      "         9.7503e-03, -1.8051e-03, -1.3014e-02,  1.2332e-02, -2.5954e-03,\n",
      "         1.6459e-02,  8.4315e-03,  1.5366e-02,  1.0071e-02,  1.0913e-02,\n",
      "         1.8148e-02,  1.3106e-02, -1.7217e-02, -1.6714e-02,  1.7407e-02,\n",
      "        -3.9910e-03,  1.4345e-02, -2.0584e-04,  3.5980e-04,  1.3758e-02,\n",
      "        -7.7551e-03, -1.8472e-02,  1.0671e-02, -1.4453e-02, -6.1350e-03,\n",
      "        -1.3412e-02,  1.2659e-02,  1.4542e-02,  1.0280e-02,  2.0086e-02,\n",
      "         1.3014e-02, -5.4496e-03,  3.6996e-03,  1.3657e-02,  1.8021e-03,\n",
      "        -1.3165e-02,  3.5373e-03,  1.1328e-03, -6.3536e-03, -5.5248e-04,\n",
      "         8.0777e-03,  1.0788e-02, -1.5177e-02,  1.9578e-02,  5.4882e-03,\n",
      "        -1.6044e-02, -2.0514e-02, -3.8026e-03, -1.7857e-02,  2.0600e-02,\n",
      "        -6.3312e-03, -1.4313e-02,  1.2870e-02,  6.0782e-03, -1.1074e-02,\n",
      "        -1.7733e-04,  1.6273e-02, -1.0545e-02,  2.3510e-03, -1.6429e-02,\n",
      "         1.2114e-03, -1.4874e-02, -2.1430e-03,  1.9616e-02,  1.6612e-04,\n",
      "        -9.2030e-03, -1.6293e-02,  2.9226e-03,  1.4711e-02, -2.1412e-03,\n",
      "         4.2342e-03,  1.1087e-02, -2.9140e-04,  1.5871e-02,  5.4427e-03,\n",
      "         7.6700e-03, -4.9978e-03, -2.0473e-04, -4.9466e-03,  1.9696e-02,\n",
      "        -4.1867e-03,  6.3793e-03,  1.9361e-02, -1.4397e-02, -1.4025e-02,\n",
      "        -1.2271e-03, -3.4505e-03, -4.6986e-03,  2.0804e-02, -3.8286e-05,\n",
      "        -2.7643e-03, -1.5951e-02,  1.3231e-02,  1.7940e-02, -1.2698e-02,\n",
      "        -1.5631e-02,  1.4767e-02,  1.4355e-02, -3.2892e-03, -1.6952e-02,\n",
      "        -1.2502e-02, -6.9176e-03,  2.0779e-02,  1.3700e-02, -1.8594e-02,\n",
      "         7.7057e-04,  1.6515e-02, -2.2799e-03,  1.2894e-02, -9.6081e-03,\n",
      "        -1.3498e-02,  8.5086e-03,  1.8247e-03,  1.8382e-02,  3.3936e-03,\n",
      "         1.3791e-03,  1.9108e-02,  1.5691e-02, -7.4188e-03, -2.3354e-03,\n",
      "         2.8018e-03, -9.1513e-03,  4.2780e-03, -7.7332e-03,  6.5263e-03,\n",
      "         8.0960e-03,  1.2519e-02, -9.6733e-03,  1.6474e-03, -2.0069e-02,\n",
      "         5.2670e-03, -1.8605e-02, -1.1287e-02,  8.7855e-03,  2.4863e-03,\n",
      "         3.7873e-03, -1.1264e-02, -3.0424e-03, -9.5446e-03, -1.9666e-02,\n",
      "        -6.2143e-03, -1.0548e-02, -1.0882e-02, -2.6282e-03,  5.2857e-03,\n",
      "        -5.2339e-03,  1.1158e-02, -6.0043e-03, -5.3220e-03,  9.0741e-03,\n",
      "        -3.3334e-03])\n",
      "Layer: layer4.0.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])\n",
      "Layer: layer4.0.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer4.0.conv2.weight:, Weights: tensor([[[[ 8.2397e-04, -6.9342e-03,  1.1621e-02],\n",
      "          [-1.6860e-02,  1.2871e-02, -1.9707e-02],\n",
      "          [-1.8473e-02, -4.9232e-03,  1.3904e-02]],\n",
      "\n",
      "         [[ 1.7798e-02, -1.4104e-02,  1.1338e-03],\n",
      "          [ 1.3646e-03,  1.1251e-02, -1.9727e-02],\n",
      "          [-1.9111e-02,  1.5536e-02,  1.6690e-02]],\n",
      "\n",
      "         [[ 4.7452e-04,  7.4529e-03, -1.8974e-02],\n",
      "          [ 5.4106e-03, -2.4276e-03, -6.5519e-03],\n",
      "          [ 1.9179e-02, -4.5844e-04,  6.3896e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9299e-02,  1.6520e-02,  6.5178e-03],\n",
      "          [-3.6272e-03,  2.2314e-03, -9.8985e-03],\n",
      "          [-8.1799e-03,  9.7854e-03,  3.6975e-03]],\n",
      "\n",
      "         [[ 1.2542e-02, -5.7449e-03, -1.8906e-02],\n",
      "          [ 2.0219e-02,  6.1410e-03,  2.0178e-02],\n",
      "          [ 6.0404e-03, -2.6607e-03, -1.4871e-02]],\n",
      "\n",
      "         [[-1.5395e-02, -1.1554e-02, -1.3430e-02],\n",
      "          [-1.5238e-02,  1.9009e-02,  2.2231e-04],\n",
      "          [ 2.0772e-02, -1.2513e-02,  1.4961e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0026e-03,  1.3205e-02, -3.4777e-03],\n",
      "          [-1.9553e-02,  3.4106e-03,  1.7317e-02],\n",
      "          [-6.5061e-03,  1.1108e-02,  9.1888e-03]],\n",
      "\n",
      "         [[-1.5810e-02, -1.6974e-02, -1.0531e-02],\n",
      "          [ 1.5725e-02,  7.0079e-03, -7.0349e-03],\n",
      "          [ 4.0169e-03, -1.3252e-02,  1.6812e-02]],\n",
      "\n",
      "         [[ 5.5239e-03,  9.8095e-03,  6.0213e-03],\n",
      "          [ 2.2114e-03,  1.4692e-02,  8.5194e-03],\n",
      "          [ 1.7275e-02,  7.5787e-03, -1.0933e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.2033e-03, -1.4472e-02,  9.5585e-03],\n",
      "          [-1.7445e-02,  5.1106e-03, -2.8467e-03],\n",
      "          [-7.3490e-03, -1.4784e-02,  1.9952e-02]],\n",
      "\n",
      "         [[-1.1299e-02, -7.5811e-04, -1.1371e-02],\n",
      "          [ 1.1303e-02, -2.0532e-02, -1.1948e-02],\n",
      "          [-1.2262e-02,  1.7827e-02, -1.7700e-02]],\n",
      "\n",
      "         [[-1.8863e-02,  1.9022e-02, -1.8343e-02],\n",
      "          [-1.8937e-02,  1.8056e-02, -1.0903e-02],\n",
      "          [ 8.8920e-03, -8.6195e-03,  8.6450e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6846e-02, -2.0706e-02,  1.6202e-02],\n",
      "          [-1.3218e-02, -1.2005e-02, -8.1746e-03],\n",
      "          [ 1.0247e-02, -2.0962e-03, -8.5847e-03]],\n",
      "\n",
      "         [[ 3.7763e-03,  6.0844e-03,  1.9551e-02],\n",
      "          [ 1.1458e-02,  8.4287e-03,  1.2381e-02],\n",
      "          [-1.4325e-02, -1.2430e-02, -1.4987e-02]],\n",
      "\n",
      "         [[-1.9010e-02,  1.1191e-02,  1.7816e-02],\n",
      "          [ 1.9503e-02, -2.8564e-03, -1.1300e-03],\n",
      "          [ 1.8915e-02, -6.3595e-03, -1.8658e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9507e-03, -1.1056e-02, -3.9861e-03],\n",
      "          [-1.8639e-02, -1.2597e-02,  1.2886e-02],\n",
      "          [ 1.9818e-02,  1.5744e-02, -1.1325e-02]],\n",
      "\n",
      "         [[-1.8888e-03,  1.8529e-02, -1.4821e-02],\n",
      "          [ 1.3979e-02, -7.1459e-03, -9.8891e-03],\n",
      "          [-1.1696e-02,  1.4384e-02, -6.8195e-03]],\n",
      "\n",
      "         [[-8.3333e-03, -1.2680e-02, -5.0183e-03],\n",
      "          [-1.2099e-02,  6.0649e-03,  1.8860e-02],\n",
      "          [-7.4167e-03, -5.7090e-04, -7.7341e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 9.8210e-03,  7.0363e-03, -4.0536e-03],\n",
      "          [ 1.1238e-02, -1.4195e-02, -1.9692e-02],\n",
      "          [ 1.9409e-03,  4.8549e-03,  1.7273e-02]],\n",
      "\n",
      "         [[ 1.0636e-02,  2.3833e-03, -1.9508e-03],\n",
      "          [-1.0265e-02,  1.7961e-02,  9.9773e-03],\n",
      "          [-5.5256e-03,  4.3228e-03,  1.1269e-02]],\n",
      "\n",
      "         [[ 8.5671e-03, -7.7677e-03, -1.2264e-02],\n",
      "          [-1.0802e-02,  1.5558e-02,  3.5425e-03],\n",
      "          [ 1.9256e-02, -1.4913e-03,  1.0968e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.8498e-03,  5.0211e-03, -2.0229e-03],\n",
      "          [-1.1622e-03,  1.0936e-02,  1.2227e-02],\n",
      "          [ 1.8206e-02, -1.6829e-02, -4.0342e-04]],\n",
      "\n",
      "         [[-3.4481e-03, -8.3962e-03, -4.6133e-03],\n",
      "          [ 1.0826e-02,  1.2944e-02,  3.4893e-03],\n",
      "          [-1.1910e-02, -1.2177e-03, -1.9307e-02]],\n",
      "\n",
      "         [[-1.9066e-02, -1.1171e-02, -1.8358e-02],\n",
      "          [ 4.3089e-03,  1.2788e-02, -1.9498e-02],\n",
      "          [-1.4417e-02, -1.0532e-02, -1.2054e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.6081e-03,  1.1793e-02, -1.5702e-03],\n",
      "          [-8.3006e-03,  9.1432e-03, -1.9466e-02],\n",
      "          [-1.6960e-02, -5.7128e-03, -6.8310e-03]],\n",
      "\n",
      "         [[ 1.3911e-03,  1.7270e-02,  1.7575e-02],\n",
      "          [ 2.8595e-04, -1.0145e-02,  1.8616e-02],\n",
      "          [-2.3961e-03,  2.0419e-02, -1.8265e-03]],\n",
      "\n",
      "         [[-1.9359e-02,  8.0417e-03, -1.7144e-02],\n",
      "          [ 4.8936e-03,  1.2083e-02,  7.9021e-05],\n",
      "          [-1.6087e-03,  1.8829e-02,  1.4707e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8732e-02,  8.2336e-03, -1.6686e-02],\n",
      "          [ 8.8833e-03, -5.2229e-03, -2.5120e-03],\n",
      "          [ 1.9397e-02,  4.0316e-03, -2.3195e-03]],\n",
      "\n",
      "         [[-7.4453e-03, -1.9320e-02, -2.0522e-02],\n",
      "          [-9.5292e-03, -1.3319e-03,  1.0987e-02],\n",
      "          [ 7.4482e-03, -1.7740e-02, -1.4148e-03]],\n",
      "\n",
      "         [[ 9.0860e-03, -1.5515e-02, -8.8106e-04],\n",
      "          [-1.7892e-02, -1.1455e-02,  1.5265e-02],\n",
      "          [-1.6335e-02, -1.5556e-02,  1.8563e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5676e-02,  1.8554e-02,  5.0994e-03],\n",
      "          [-3.0627e-03,  6.6704e-03, -1.5774e-02],\n",
      "          [-1.8097e-02,  1.2291e-02, -2.0812e-02]],\n",
      "\n",
      "         [[ 1.5481e-02,  2.0575e-02, -6.5394e-03],\n",
      "          [ 1.5277e-02, -1.8411e-02, -7.5386e-03],\n",
      "          [-2.3975e-03,  1.1743e-02, -1.0994e-02]],\n",
      "\n",
      "         [[ 1.4432e-02, -2.9974e-03, -7.3307e-03],\n",
      "          [ 1.6201e-03, -1.8860e-03,  2.5127e-03],\n",
      "          [ 1.6525e-03,  1.5741e-02, -2.0020e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5848e-02, -1.7805e-02, -1.7754e-02],\n",
      "          [-9.8817e-03, -5.3617e-03, -1.0355e-02],\n",
      "          [-3.5670e-03,  1.8321e-02, -1.2068e-02]],\n",
      "\n",
      "         [[ 8.2410e-03,  2.0419e-02, -1.1609e-02],\n",
      "          [ 2.5589e-03,  1.1392e-02,  4.3340e-03],\n",
      "          [-1.0673e-02,  1.9245e-02, -1.5464e-02]],\n",
      "\n",
      "         [[-5.6974e-03, -5.8397e-03,  1.2965e-02],\n",
      "          [-4.7882e-03,  1.4576e-02, -1.2152e-02],\n",
      "          [ 1.2462e-02, -2.0520e-02,  1.6656e-02]]]])\n",
      "Layer: layer4.0.conv2.bias, Biases: tensor([-1.6680e-02, -1.3452e-02, -1.3104e-02, -1.9421e-02,  1.9437e-02,\n",
      "         3.9456e-03,  1.0477e-02, -2.0169e-02, -9.9710e-03, -8.0333e-03,\n",
      "        -1.6667e-02, -3.5693e-03, -1.2822e-02, -7.5635e-03,  9.1548e-03,\n",
      "        -4.8256e-03,  1.3860e-02, -1.1212e-02, -1.1671e-02, -2.7335e-03,\n",
      "        -7.5719e-03, -1.5634e-02,  1.8457e-02,  3.9399e-03, -1.2717e-02,\n",
      "        -1.7806e-02, -2.0052e-04,  4.6700e-04,  1.0923e-03, -1.7277e-02,\n",
      "         1.8125e-03, -8.8541e-03, -1.2692e-02,  8.7916e-03,  1.5464e-02,\n",
      "         8.1738e-03, -4.7260e-03, -9.8405e-03, -2.5709e-03, -1.3715e-02,\n",
      "        -1.1487e-03,  1.4386e-02, -3.3169e-03, -1.8191e-02, -1.7703e-03,\n",
      "        -1.9979e-02, -1.2446e-02, -5.4165e-03,  1.7205e-02,  1.9470e-02,\n",
      "         2.8422e-03, -9.6139e-03, -1.1054e-02,  5.1148e-03, -2.5671e-03,\n",
      "         1.9298e-02,  2.9868e-03,  4.7803e-03, -1.6489e-02, -1.9178e-02,\n",
      "        -4.0725e-03,  1.2254e-02,  7.0751e-03,  1.4272e-02, -1.3658e-02,\n",
      "        -1.1801e-02, -1.9435e-02, -1.6764e-02,  8.5988e-03,  1.3741e-02,\n",
      "        -1.2201e-02,  1.1362e-02,  1.2665e-02, -3.3679e-03, -1.3649e-02,\n",
      "         2.7046e-03, -5.8966e-03,  7.1585e-03,  7.5227e-03,  1.8666e-02,\n",
      "         5.1401e-03, -8.2143e-03,  6.8550e-03,  1.1130e-02, -1.0206e-02,\n",
      "        -1.4480e-02,  5.1654e-03, -1.1098e-02, -1.6203e-02,  1.5902e-02,\n",
      "        -1.5014e-03, -8.6397e-03,  1.4589e-02,  1.6777e-02,  6.9502e-03,\n",
      "         3.0849e-03, -9.0299e-03, -1.7990e-02,  2.0726e-02, -1.7953e-02,\n",
      "        -1.0816e-02, -1.9253e-02,  7.1652e-03,  7.7357e-03, -1.5656e-02,\n",
      "        -1.5266e-02, -7.2366e-03, -8.0519e-03,  5.4930e-03, -1.8304e-02,\n",
      "        -1.7415e-02,  1.9159e-02, -1.6392e-02,  2.0592e-02, -1.0191e-02,\n",
      "        -5.6826e-03,  5.3278e-03, -1.4756e-02, -1.3821e-02,  8.1460e-03,\n",
      "         4.3518e-03, -1.9225e-02,  3.0046e-03,  1.1091e-02, -1.5753e-02,\n",
      "         1.2770e-02,  5.7159e-03, -1.6259e-02,  6.3605e-03,  1.4086e-02,\n",
      "        -2.0330e-02, -2.0218e-02, -6.7444e-03, -1.4219e-02, -7.8154e-03,\n",
      "         1.7505e-03, -4.5495e-03, -5.2090e-03,  1.6338e-02,  1.3084e-02,\n",
      "        -1.8629e-02, -6.6683e-03, -1.3373e-02, -1.8539e-02,  1.9071e-02,\n",
      "        -1.6513e-03,  7.2218e-05,  1.5998e-02, -1.6955e-02,  1.1814e-02,\n",
      "        -1.9766e-03,  1.3557e-02,  1.0910e-02, -9.8878e-03,  6.4712e-03,\n",
      "        -2.8436e-05, -1.3741e-02, -1.3133e-02, -1.4197e-02,  1.5363e-02,\n",
      "         1.3709e-02,  2.0307e-02,  4.0349e-03, -5.8874e-03,  1.6521e-02,\n",
      "         1.5041e-02,  1.1244e-02,  1.3984e-02,  1.8162e-02,  1.4161e-03,\n",
      "        -1.7928e-02, -5.3993e-03,  1.2792e-03,  4.6622e-03, -1.9809e-03,\n",
      "        -1.9433e-02, -1.1107e-02, -1.7724e-02, -1.4095e-02, -5.0551e-04,\n",
      "         1.1392e-02, -1.1460e-02,  1.3913e-02,  7.0527e-03,  1.7812e-02,\n",
      "        -1.3853e-02, -2.0453e-02,  1.6979e-02,  5.0747e-04, -1.1225e-02,\n",
      "         1.2174e-02, -3.9091e-05,  1.7682e-02, -9.3918e-04, -3.1628e-03,\n",
      "         1.9270e-02,  7.4509e-03, -1.4635e-02, -2.1317e-03,  9.9488e-03,\n",
      "         1.5982e-02, -1.7132e-04,  1.6311e-02, -1.1934e-02,  1.2470e-02,\n",
      "         1.3779e-02,  2.1156e-03, -4.8006e-03, -5.1512e-03, -6.7615e-04,\n",
      "        -1.7185e-02, -1.3427e-02,  1.6673e-02,  1.2012e-02,  1.7593e-02,\n",
      "        -6.6574e-03, -1.5939e-02,  2.8296e-03,  1.4681e-03, -1.3721e-03,\n",
      "         1.5129e-02,  8.6143e-03, -6.0069e-03, -9.3136e-03,  4.0678e-04,\n",
      "         1.4870e-02, -3.4780e-03,  4.5038e-03, -1.5349e-02, -1.7553e-02,\n",
      "         7.4458e-03,  1.1986e-02,  1.3705e-02, -7.8604e-03,  3.9537e-04,\n",
      "         1.4824e-02, -1.0892e-02, -5.2122e-03,  2.0770e-02, -1.1696e-02,\n",
      "        -3.9527e-03,  8.2396e-03,  2.2861e-03,  1.2320e-02,  1.7178e-02,\n",
      "        -4.0858e-03,  1.6147e-02,  4.7370e-03, -1.0180e-03,  8.2094e-04,\n",
      "         1.3919e-02, -1.4607e-02, -8.9141e-03, -1.1547e-02, -2.6558e-03,\n",
      "         1.1528e-02,  5.6735e-03, -1.9334e-02, -1.9785e-02,  2.4390e-03,\n",
      "         1.3463e-02, -1.1753e-02, -9.9552e-03,  7.4922e-03,  1.3643e-02,\n",
      "         1.2435e-02,  1.5854e-02,  1.3998e-02,  1.9001e-02, -4.9438e-03,\n",
      "         1.6836e-02,  1.9627e-02, -7.3653e-03,  1.6445e-02,  2.1726e-03,\n",
      "        -4.1193e-03,  6.8339e-03,  5.6685e-04,  1.8944e-02,  1.5321e-02,\n",
      "        -1.9103e-02, -1.5094e-02, -3.3766e-03,  2.8643e-03, -1.0975e-02,\n",
      "         5.9894e-03,  2.8961e-03, -4.0833e-03,  1.3860e-02, -1.9895e-02,\n",
      "         1.2273e-02, -1.5119e-02, -1.2821e-02,  8.8838e-03, -1.9912e-02,\n",
      "         1.2604e-02, -1.3008e-02, -1.3217e-02,  5.3160e-04,  1.9687e-02,\n",
      "         1.8977e-02, -6.5427e-04,  1.9299e-02,  1.4634e-02,  1.9992e-02,\n",
      "         1.5629e-02, -1.7191e-02,  9.8615e-03,  1.1512e-03, -5.6029e-04,\n",
      "         1.4442e-02, -1.4356e-03,  2.7272e-03, -7.5123e-03, -2.5691e-03,\n",
      "         7.9023e-03,  1.1932e-03,  1.6885e-02,  6.6697e-03, -3.4343e-03,\n",
      "         1.1166e-02, -8.2487e-03,  1.3920e-02, -1.8365e-02,  1.9953e-02,\n",
      "         9.2089e-04,  7.8545e-03,  7.9862e-03,  1.5670e-02,  5.6182e-03,\n",
      "         1.5748e-02, -2.8169e-03, -1.3573e-02,  1.5243e-04, -1.3557e-02,\n",
      "        -3.4287e-03, -4.7441e-03,  2.9694e-03,  2.3082e-03, -6.8801e-03,\n",
      "         1.5692e-02,  8.8453e-03, -8.6759e-03,  3.5688e-03, -1.3942e-02,\n",
      "        -1.3825e-02,  9.0761e-03, -1.5813e-02, -1.5157e-02, -1.8931e-02,\n",
      "        -1.5627e-02,  8.6750e-03, -4.3596e-03, -1.0704e-03, -1.5013e-02,\n",
      "         6.9747e-03,  1.1677e-02,  5.9899e-03, -1.2194e-02, -1.1299e-02,\n",
      "        -1.8057e-02,  7.7519e-03, -8.8111e-04, -1.3440e-02, -6.3847e-03,\n",
      "         4.6224e-03, -2.2638e-03,  7.0441e-03,  1.7046e-02, -2.6177e-03,\n",
      "         1.8550e-03,  1.2812e-02, -9.9853e-03,  8.7143e-03,  1.0676e-02,\n",
      "        -4.3599e-03,  3.1092e-03, -4.0984e-03,  4.2502e-03, -5.0044e-03,\n",
      "         1.1048e-02, -1.9336e-02,  1.0232e-02, -2.0044e-02, -1.0031e-02,\n",
      "        -6.4116e-03,  5.9452e-03, -1.2281e-02, -1.1764e-02,  3.3430e-04,\n",
      "        -1.5165e-02, -1.8236e-02, -4.4998e-03,  1.1763e-03, -1.0316e-02,\n",
      "        -1.1822e-02, -1.9999e-02, -9.1436e-03,  4.4553e-03,  1.1883e-02,\n",
      "         6.9579e-03, -9.2560e-03,  9.2092e-04,  1.9584e-02,  1.0150e-02,\n",
      "        -9.1195e-03, -1.4906e-02, -2.7845e-03, -6.1099e-03,  1.9921e-02,\n",
      "         1.4688e-02,  1.8991e-02,  1.7214e-02, -1.7850e-02,  3.5617e-03,\n",
      "        -1.7631e-02, -1.7629e-02,  1.6741e-02,  1.7147e-02, -2.6367e-03,\n",
      "        -2.0448e-02,  1.8362e-02, -1.0060e-02, -9.0271e-03, -1.8940e-02,\n",
      "        -3.1805e-03,  7.8977e-03,  7.4787e-03, -1.3880e-02,  1.6759e-03,\n",
      "         9.0143e-03, -9.0919e-03, -1.1483e-02,  1.6790e-02, -1.6672e-02,\n",
      "         1.9813e-02,  1.5454e-02,  1.3978e-02, -5.4874e-03, -4.4084e-03,\n",
      "         4.1258e-03, -8.3087e-03,  1.7081e-02, -4.6103e-03,  1.4098e-02,\n",
      "        -1.9479e-03, -5.0982e-03, -1.1361e-02, -6.9077e-03, -1.5658e-02,\n",
      "         3.9941e-03, -1.0222e-02,  1.5798e-02, -1.4413e-02,  1.4161e-02,\n",
      "        -7.2852e-03,  3.9441e-03,  4.4663e-03, -6.1422e-03,  1.8286e-02,\n",
      "         1.0072e-04,  1.3215e-02, -6.8683e-03, -2.0290e-02, -1.1680e-02,\n",
      "        -1.9443e-02,  1.3993e-02,  3.2086e-03,  8.4586e-03, -4.0419e-03,\n",
      "         7.5744e-03,  1.9276e-02, -1.5437e-02,  8.6678e-03,  9.1256e-03,\n",
      "        -5.2348e-05,  1.1642e-02, -5.7837e-03, -8.0110e-03,  1.4543e-02,\n",
      "         5.3155e-03,  4.1578e-03, -1.4121e-02,  1.1131e-02, -4.3284e-03,\n",
      "         2.0101e-02,  4.4948e-03,  1.2934e-02, -1.5971e-02, -4.2966e-03,\n",
      "         7.1748e-03, -2.0049e-02, -1.6380e-02,  6.7996e-03,  1.5522e-04,\n",
      "        -5.0176e-04, -4.7549e-03, -4.4758e-03,  6.3317e-03,  2.0284e-02,\n",
      "        -5.3799e-03, -1.5289e-02,  3.1367e-03, -9.2799e-03, -1.7279e-02,\n",
      "         6.1919e-03, -1.5275e-02, -1.9295e-03,  1.0863e-02, -1.9406e-02,\n",
      "        -1.2364e-02, -7.9093e-03])\n",
      "Layer: layer4.0.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer4.0.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer4.0.identity_downsample.0.weight:, Weights: tensor([[[[ 0.0450]],\n",
      "\n",
      "         [[-0.0044]],\n",
      "\n",
      "         [[-0.0409]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0010]],\n",
      "\n",
      "         [[ 0.0092]],\n",
      "\n",
      "         [[ 0.0318]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0452]],\n",
      "\n",
      "         [[-0.0590]],\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0604]],\n",
      "\n",
      "         [[ 0.0513]],\n",
      "\n",
      "         [[ 0.0160]]],\n",
      "\n",
      "\n",
      "        [[[-0.0528]],\n",
      "\n",
      "         [[ 0.0555]],\n",
      "\n",
      "         [[-0.0459]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0084]],\n",
      "\n",
      "         [[-0.0537]],\n",
      "\n",
      "         [[-0.0283]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0599]],\n",
      "\n",
      "         [[ 0.0274]],\n",
      "\n",
      "         [[ 0.0048]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0609]],\n",
      "\n",
      "         [[-0.0476]],\n",
      "\n",
      "         [[ 0.0257]]],\n",
      "\n",
      "\n",
      "        [[[-0.0080]],\n",
      "\n",
      "         [[ 0.0455]],\n",
      "\n",
      "         [[-0.0397]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0355]],\n",
      "\n",
      "         [[ 0.0309]],\n",
      "\n",
      "         [[-0.0247]]],\n",
      "\n",
      "\n",
      "        [[[-0.0582]],\n",
      "\n",
      "         [[ 0.0546]],\n",
      "\n",
      "         [[-0.0446]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0248]],\n",
      "\n",
      "         [[ 0.0529]],\n",
      "\n",
      "         [[-0.0622]]]])\n",
      "Layer: layer4.0.identity_downsample.0.bias, Biases: tensor([ 0.0371, -0.0276, -0.0612,  0.0009,  0.0353, -0.0408, -0.0236, -0.0147,\n",
      "         0.0321,  0.0423, -0.0561,  0.0612,  0.0405,  0.0616, -0.0616,  0.0572,\n",
      "         0.0486,  0.0293,  0.0016,  0.0488,  0.0256, -0.0359, -0.0580,  0.0306,\n",
      "        -0.0250,  0.0592,  0.0039,  0.0267,  0.0207, -0.0163, -0.0479, -0.0277,\n",
      "        -0.0432, -0.0014, -0.0075,  0.0265, -0.0385, -0.0586,  0.0398, -0.0221,\n",
      "         0.0286,  0.0089, -0.0018, -0.0596, -0.0425,  0.0609,  0.0366, -0.0569,\n",
      "         0.0369, -0.0421, -0.0274,  0.0227,  0.0544, -0.0260,  0.0333, -0.0214,\n",
      "        -0.0145,  0.0480, -0.0338, -0.0372,  0.0066,  0.0139,  0.0146,  0.0611,\n",
      "        -0.0162, -0.0205, -0.0493,  0.0020, -0.0454, -0.0613,  0.0163,  0.0098,\n",
      "        -0.0574, -0.0382, -0.0573, -0.0171, -0.0109, -0.0547,  0.0557,  0.0150,\n",
      "         0.0050, -0.0141, -0.0615,  0.0465, -0.0602,  0.0183, -0.0265,  0.0390,\n",
      "        -0.0339,  0.0607, -0.0460, -0.0240, -0.0449, -0.0564,  0.0530,  0.0618,\n",
      "        -0.0324,  0.0028, -0.0574, -0.0368, -0.0164,  0.0269,  0.0440,  0.0468,\n",
      "         0.0542,  0.0568,  0.0224, -0.0078, -0.0451,  0.0371, -0.0020, -0.0437,\n",
      "         0.0091,  0.0106, -0.0490,  0.0323, -0.0321, -0.0065,  0.0075,  0.0226,\n",
      "         0.0605, -0.0546, -0.0053, -0.0092, -0.0089, -0.0295, -0.0072, -0.0280,\n",
      "         0.0135, -0.0161, -0.0356, -0.0084,  0.0618, -0.0488, -0.0375, -0.0239,\n",
      "         0.0194,  0.0139,  0.0053,  0.0117, -0.0223,  0.0453, -0.0372, -0.0334,\n",
      "         0.0597, -0.0137,  0.0540, -0.0326,  0.0331, -0.0284,  0.0596,  0.0495,\n",
      "        -0.0355,  0.0609,  0.0038,  0.0389, -0.0363, -0.0455,  0.0038,  0.0042,\n",
      "        -0.0024, -0.0523, -0.0334,  0.0271, -0.0365,  0.0337,  0.0198, -0.0512,\n",
      "        -0.0372, -0.0040,  0.0231, -0.0330,  0.0411,  0.0385,  0.0576,  0.0558,\n",
      "        -0.0229,  0.0286, -0.0186,  0.0103, -0.0079, -0.0091,  0.0068,  0.0187,\n",
      "        -0.0365,  0.0431,  0.0537, -0.0205, -0.0273, -0.0601, -0.0506, -0.0164,\n",
      "        -0.0076, -0.0311,  0.0487,  0.0131, -0.0252,  0.0231, -0.0310, -0.0465,\n",
      "         0.0495, -0.0325, -0.0103, -0.0282,  0.0232,  0.0015,  0.0205,  0.0077,\n",
      "         0.0413, -0.0100,  0.0446,  0.0451,  0.0608, -0.0537, -0.0055,  0.0248,\n",
      "        -0.0527, -0.0149,  0.0496,  0.0536, -0.0243,  0.0565, -0.0596,  0.0502,\n",
      "        -0.0358,  0.0544,  0.0188,  0.0499,  0.0491,  0.0604,  0.0544, -0.0600,\n",
      "        -0.0124, -0.0092,  0.0494, -0.0207,  0.0279, -0.0512, -0.0529, -0.0297,\n",
      "         0.0354,  0.0135, -0.0312, -0.0042,  0.0528, -0.0312,  0.0517, -0.0046,\n",
      "        -0.0038,  0.0588, -0.0039,  0.0206, -0.0619, -0.0548,  0.0204, -0.0312,\n",
      "        -0.0078, -0.0229,  0.0158,  0.0376, -0.0017,  0.0043, -0.0017,  0.0588,\n",
      "         0.0290,  0.0234, -0.0239, -0.0016, -0.0294,  0.0437,  0.0436,  0.0180,\n",
      "         0.0086,  0.0129,  0.0478,  0.0240, -0.0023, -0.0293,  0.0601, -0.0178,\n",
      "         0.0506,  0.0098, -0.0603,  0.0425, -0.0605,  0.0269,  0.0497,  0.0158,\n",
      "        -0.0154,  0.0462, -0.0450, -0.0497, -0.0435, -0.0575,  0.0557,  0.0478,\n",
      "        -0.0585,  0.0192,  0.0560,  0.0194,  0.0278, -0.0377, -0.0313, -0.0003,\n",
      "        -0.0116,  0.0354, -0.0539, -0.0233,  0.0065, -0.0347,  0.0288,  0.0248,\n",
      "         0.0511, -0.0010,  0.0324,  0.0173, -0.0278,  0.0196,  0.0349, -0.0060,\n",
      "         0.0067,  0.0140,  0.0179,  0.0337,  0.0396,  0.0504,  0.0411, -0.0099,\n",
      "        -0.0089, -0.0344, -0.0133,  0.0059, -0.0132, -0.0562, -0.0522,  0.0598,\n",
      "        -0.0280,  0.0624,  0.0047, -0.0303, -0.0433, -0.0141,  0.0469, -0.0230,\n",
      "        -0.0140,  0.0393,  0.0076, -0.0438, -0.0570,  0.0618,  0.0480, -0.0010,\n",
      "         0.0169,  0.0269, -0.0194, -0.0256, -0.0181,  0.0602, -0.0566,  0.0251,\n",
      "        -0.0438,  0.0468, -0.0189, -0.0382, -0.0099, -0.0066, -0.0608, -0.0477,\n",
      "        -0.0589, -0.0495,  0.0501,  0.0159,  0.0401,  0.0272,  0.0590, -0.0306,\n",
      "         0.0547, -0.0501,  0.0020, -0.0588, -0.0379, -0.0275, -0.0123,  0.0134,\n",
      "         0.0593, -0.0410, -0.0228, -0.0380, -0.0285, -0.0573, -0.0350, -0.0365,\n",
      "        -0.0499, -0.0169, -0.0258, -0.0068,  0.0214,  0.0296, -0.0181, -0.0411,\n",
      "        -0.0188, -0.0143, -0.0396, -0.0470, -0.0035, -0.0187,  0.0042,  0.0151,\n",
      "         0.0168, -0.0126, -0.0234, -0.0388,  0.0259, -0.0111,  0.0296, -0.0528,\n",
      "        -0.0589, -0.0283, -0.0316, -0.0118,  0.0358,  0.0507,  0.0193, -0.0247,\n",
      "         0.0327, -0.0209,  0.0498,  0.0605, -0.0528, -0.0135, -0.0325,  0.0305,\n",
      "         0.0094,  0.0417,  0.0391,  0.0477,  0.0161,  0.0426,  0.0584, -0.0543,\n",
      "        -0.0185, -0.0140, -0.0021,  0.0547,  0.0228, -0.0238, -0.0449, -0.0068,\n",
      "         0.0415,  0.0143,  0.0152,  0.0231,  0.0324,  0.0381,  0.0259,  0.0050,\n",
      "         0.0607,  0.0485,  0.0249,  0.0220, -0.0597,  0.0291,  0.0546,  0.0490,\n",
      "        -0.0514,  0.0043,  0.0112, -0.0076,  0.0392,  0.0330,  0.0601, -0.0147,\n",
      "        -0.0465,  0.0421,  0.0266,  0.0120,  0.0421, -0.0442, -0.0069,  0.0170,\n",
      "        -0.0441, -0.0063, -0.0503, -0.0418, -0.0113,  0.0058,  0.0121, -0.0470,\n",
      "        -0.0104, -0.0506, -0.0074, -0.0306, -0.0086, -0.0314,  0.0500,  0.0345,\n",
      "        -0.0313,  0.0035, -0.0100,  0.0146, -0.0394,  0.0201, -0.0373,  0.0509,\n",
      "         0.0218, -0.0286,  0.0170,  0.0330, -0.0012, -0.0042,  0.0421,  0.0574])\n",
      "Layer: layer4.0.identity_downsample.1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer4.0.identity_downsample.1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer4.1.conv1.weight:, Weights: tensor([[[[-1.0149e-02,  5.1812e-04, -5.5316e-05],\n",
      "          [ 5.4294e-03,  1.2923e-02,  2.0491e-03],\n",
      "          [ 3.0229e-03, -1.3072e-02,  6.9313e-03]],\n",
      "\n",
      "         [[ 1.2952e-02,  6.6240e-03, -1.0988e-02],\n",
      "          [-7.6688e-03,  5.6863e-03, -1.4255e-02],\n",
      "          [-5.9596e-03, -8.2698e-04,  2.9644e-03]],\n",
      "\n",
      "         [[-1.2859e-02,  2.8015e-03, -2.2504e-03],\n",
      "          [ 1.2213e-02,  8.3024e-03, -1.3785e-02],\n",
      "          [-1.2611e-02,  1.2001e-03, -1.3519e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0291e-03, -1.3719e-02,  1.1064e-02],\n",
      "          [ 4.6355e-03, -1.2040e-02, -1.4320e-02],\n",
      "          [-8.1420e-03,  1.1221e-03, -3.5590e-03]],\n",
      "\n",
      "         [[ 1.2327e-02, -9.8991e-03,  3.5978e-03],\n",
      "          [ 5.1499e-04, -1.4409e-02, -2.5814e-03],\n",
      "          [ 2.6451e-03, -1.3200e-03, -1.0883e-02]],\n",
      "\n",
      "         [[-8.0494e-03, -1.3722e-02,  2.0713e-03],\n",
      "          [-9.3520e-03, -1.3595e-02, -1.0622e-02],\n",
      "          [ 3.5183e-03,  7.7747e-03, -6.5806e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9114e-03, -3.5014e-03, -1.1221e-02],\n",
      "          [ 1.1104e-02, -9.9602e-03,  6.5200e-03],\n",
      "          [ 5.3958e-03, -4.2069e-03,  1.3376e-02]],\n",
      "\n",
      "         [[-1.0796e-02, -4.2570e-03,  7.8343e-03],\n",
      "          [-4.6021e-03, -1.3484e-02,  1.4268e-02],\n",
      "          [-7.8657e-03, -6.8721e-03, -6.4897e-03]],\n",
      "\n",
      "         [[ 6.3468e-03,  1.0986e-02,  8.6436e-03],\n",
      "          [-1.7737e-03, -3.8107e-03, -5.5682e-03],\n",
      "          [-1.1680e-02,  2.9087e-03,  1.2494e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0780e-03, -5.7179e-03, -4.3558e-03],\n",
      "          [ 2.4122e-03,  7.5477e-03, -1.4483e-02],\n",
      "          [ 3.1884e-03, -3.2411e-03,  2.8002e-03]],\n",
      "\n",
      "         [[-2.7457e-03,  1.1421e-02,  1.3025e-02],\n",
      "          [-3.4476e-03, -7.0481e-03, -1.2884e-03],\n",
      "          [ 4.3095e-03,  7.2359e-05, -3.0301e-03]],\n",
      "\n",
      "         [[ 7.2751e-04, -1.0587e-02, -7.6566e-03],\n",
      "          [ 8.9222e-03,  3.2792e-03, -3.5607e-03],\n",
      "          [ 4.1786e-03, -6.4510e-03, -7.1773e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.2325e-02,  1.2064e-02, -1.2261e-03],\n",
      "          [-7.8648e-03,  6.5166e-03, -1.3710e-02],\n",
      "          [-1.1514e-02,  6.7906e-03,  4.4581e-03]],\n",
      "\n",
      "         [[ 1.3189e-02,  1.1986e-02,  9.8602e-03],\n",
      "          [ 1.4480e-02,  1.3350e-02, -3.3328e-03],\n",
      "          [-9.5929e-03, -1.4262e-02,  2.7124e-03]],\n",
      "\n",
      "         [[-3.8709e-03,  1.1878e-02,  2.5822e-03],\n",
      "          [ 5.4452e-03, -5.2783e-03, -1.1902e-02],\n",
      "          [ 6.4347e-04, -1.0619e-02,  8.6972e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1600e-03, -3.0125e-03,  6.2397e-03],\n",
      "          [-1.0879e-03,  5.6399e-03, -1.2664e-02],\n",
      "          [ 1.2824e-03, -1.1614e-02,  1.0062e-02]],\n",
      "\n",
      "         [[-9.7294e-03,  1.1170e-02,  9.0306e-03],\n",
      "          [ 3.5155e-03,  6.0550e-03,  7.0212e-03],\n",
      "          [-4.9555e-03,  1.0693e-02, -5.5876e-03]],\n",
      "\n",
      "         [[-6.5627e-03,  1.1501e-02, -1.0345e-02],\n",
      "          [ 7.5054e-03, -6.4533e-03,  1.8330e-03],\n",
      "          [ 1.3217e-02,  8.3093e-04, -1.1551e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.8403e-03, -2.4731e-03, -6.7939e-03],\n",
      "          [ 1.2737e-02, -6.2271e-03, -9.9415e-03],\n",
      "          [-3.9207e-03, -3.2161e-03,  5.0320e-03]],\n",
      "\n",
      "         [[ 9.9699e-03, -1.4271e-02, -2.3123e-03],\n",
      "          [-1.0430e-02, -4.9016e-03,  9.5038e-03],\n",
      "          [-7.2220e-03, -1.4054e-02, -5.5426e-04]],\n",
      "\n",
      "         [[ 1.3699e-02,  1.1819e-02, -4.8205e-03],\n",
      "          [-1.0078e-02,  3.2277e-03, -1.0519e-02],\n",
      "          [-1.2124e-02, -4.1561e-04, -9.3120e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2244e-04,  1.2640e-02,  5.0658e-03],\n",
      "          [-1.4054e-02, -3.5300e-03,  9.9716e-03],\n",
      "          [-3.1103e-03,  1.3341e-02, -9.9734e-03]],\n",
      "\n",
      "         [[-1.2708e-02, -1.9407e-03, -7.0961e-03],\n",
      "          [ 1.3527e-02, -3.9361e-03, -3.3317e-03],\n",
      "          [ 2.1788e-03,  1.1912e-02, -1.2772e-02]],\n",
      "\n",
      "         [[-1.2306e-02, -1.2333e-03, -7.9465e-03],\n",
      "          [-1.0057e-02,  3.3050e-04,  7.1343e-04],\n",
      "          [ 1.1938e-02,  1.3925e-02, -4.7782e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1602e-03,  1.0871e-02, -1.8961e-03],\n",
      "          [ 3.0616e-03,  9.7787e-03,  6.0961e-03],\n",
      "          [ 1.2616e-02,  7.4561e-03,  3.1067e-03]],\n",
      "\n",
      "         [[-4.9227e-03, -1.2059e-02, -1.0895e-02],\n",
      "          [ 9.4106e-03, -6.4945e-03, -7.1178e-03],\n",
      "          [-1.5641e-04,  1.0701e-02,  7.8508e-03]],\n",
      "\n",
      "         [[-9.8712e-03,  7.7400e-03,  1.1463e-02],\n",
      "          [ 5.4382e-03,  1.3554e-02, -4.9126e-03],\n",
      "          [ 9.8904e-03, -1.1364e-02,  2.6368e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9957e-03,  7.1266e-03,  7.1995e-03],\n",
      "          [ 6.1710e-03, -1.0269e-02,  9.1663e-03],\n",
      "          [-1.3010e-02,  3.3777e-03, -6.0969e-03]],\n",
      "\n",
      "         [[ 1.3103e-02, -7.8655e-03,  1.3430e-02],\n",
      "          [ 1.1837e-02, -1.3938e-02, -1.2671e-02],\n",
      "          [ 9.2025e-03,  6.5112e-03, -4.0595e-03]],\n",
      "\n",
      "         [[-9.7957e-03,  9.0578e-03, -2.9231e-03],\n",
      "          [ 6.5094e-03,  3.1887e-03,  2.7539e-03],\n",
      "          [ 9.1960e-03,  5.5220e-03,  5.7707e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3758e-02, -3.8908e-03,  8.5965e-04],\n",
      "          [ 9.8215e-03, -6.6766e-03, -7.3815e-03],\n",
      "          [-1.0365e-02, -4.8683e-03,  3.7040e-03]],\n",
      "\n",
      "         [[-2.8473e-03, -1.2855e-03,  7.7616e-04],\n",
      "          [-3.6299e-03, -7.4531e-03,  1.3200e-02],\n",
      "          [-6.8792e-03,  1.0508e-02,  1.9635e-03]],\n",
      "\n",
      "         [[-1.3121e-02,  2.7391e-03,  8.0691e-03],\n",
      "          [ 8.2420e-03, -1.4329e-02,  6.8488e-04],\n",
      "          [-1.3653e-02,  8.5455e-03,  4.7096e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.6180e-03,  5.7681e-03, -1.3804e-02],\n",
      "          [ 5.1182e-04, -6.2746e-03, -2.0779e-03],\n",
      "          [ 1.3574e-02,  9.5849e-03,  5.9094e-03]],\n",
      "\n",
      "         [[-1.1531e-02,  1.2752e-02, -1.2457e-03],\n",
      "          [-5.0255e-03, -7.0310e-03,  6.6175e-03],\n",
      "          [ 1.2713e-02, -1.5379e-04, -7.2249e-03]],\n",
      "\n",
      "         [[ 5.3714e-03,  1.3098e-02,  6.3757e-03],\n",
      "          [-5.4217e-03,  1.3100e-02,  2.5658e-03],\n",
      "          [-1.2293e-02,  7.3017e-03, -1.4342e-02]]]])\n",
      "Layer: layer4.1.conv1.bias, Biases: tensor([ 3.6407e-03, -1.9033e-03, -2.6524e-03,  9.6782e-03,  1.2972e-02,\n",
      "        -6.0481e-03,  1.4427e-02,  1.2286e-02,  3.4745e-03,  1.6646e-03,\n",
      "        -1.0148e-02,  1.2279e-02, -9.4378e-03, -5.4203e-03, -5.6929e-03,\n",
      "         9.0365e-03,  2.5360e-03, -1.7460e-03, -7.5582e-05,  9.6042e-03,\n",
      "         1.2663e-02, -7.0382e-03,  8.8360e-03, -9.3961e-03, -2.6219e-06,\n",
      "        -7.9513e-03,  1.4067e-03, -4.2505e-03,  1.0317e-02,  8.3815e-03,\n",
      "         1.1062e-02, -6.7596e-03, -2.6411e-03, -3.3209e-03,  6.0192e-04,\n",
      "        -8.5532e-03,  4.7071e-03, -6.9577e-03,  1.0983e-02,  3.2201e-03,\n",
      "         2.0867e-03,  1.3547e-02, -1.4061e-02, -9.6631e-03,  1.3656e-02,\n",
      "         1.0410e-02,  9.0448e-03,  4.0211e-03,  2.8878e-03, -4.0546e-03,\n",
      "        -5.0329e-03, -1.2150e-02,  6.2185e-03,  1.4321e-02, -4.2213e-03,\n",
      "         8.2286e-03, -4.6664e-03,  8.0933e-03, -7.7853e-03, -7.8022e-03,\n",
      "         4.3259e-03,  5.6643e-03,  4.9672e-03,  1.2542e-02,  1.7453e-03,\n",
      "         1.1247e-02,  8.2475e-03, -1.4692e-02,  9.0455e-03,  1.3916e-02,\n",
      "        -8.4443e-04,  8.9573e-03, -6.9135e-03,  1.2908e-02, -7.2363e-03,\n",
      "         9.2690e-03,  1.1568e-02,  7.3024e-03,  7.4585e-03, -6.7285e-03,\n",
      "        -1.4044e-02, -7.7798e-03,  1.0304e-02, -4.0780e-04,  1.4986e-03,\n",
      "        -9.1455e-03, -6.2158e-03,  1.2284e-02, -3.4363e-03,  2.6139e-03,\n",
      "        -3.5703e-03,  1.3826e-02, -1.2249e-02, -4.8241e-03,  3.1520e-03,\n",
      "        -7.1770e-03,  1.0108e-02, -1.3886e-02, -1.0129e-02, -5.3155e-03,\n",
      "         7.5710e-03, -8.5800e-03, -1.2700e-02, -1.1185e-02,  7.5266e-03,\n",
      "        -5.4909e-03, -2.6714e-03, -3.7857e-04, -1.1350e-02, -3.8094e-03,\n",
      "         6.1493e-03,  5.6140e-03, -1.2592e-02,  8.8123e-03,  1.0376e-02,\n",
      "        -1.0302e-02, -6.7640e-03,  1.3729e-02,  9.4213e-03,  6.8931e-05,\n",
      "         5.7666e-03,  2.7998e-04, -1.6671e-03,  1.5595e-03, -1.1553e-02,\n",
      "        -1.0232e-02, -6.8147e-03,  9.1121e-03,  1.2451e-02,  1.1217e-02,\n",
      "        -5.0209e-03, -1.0070e-02, -8.9694e-03, -1.4106e-02,  1.8316e-03,\n",
      "        -1.2374e-02, -4.4151e-03, -9.5890e-03, -7.5672e-03, -8.2989e-04,\n",
      "         1.2430e-02,  7.8579e-04,  1.0381e-02, -9.7888e-03, -1.3481e-02,\n",
      "        -4.2363e-03, -1.0114e-02,  7.4060e-03, -1.6766e-03, -5.5142e-03,\n",
      "         4.3241e-03, -1.3755e-02, -3.9251e-03, -1.3944e-02,  7.4732e-03,\n",
      "         5.8896e-03,  3.1514e-03,  2.5454e-03,  1.3857e-03,  1.2660e-03,\n",
      "         1.1236e-02, -1.2533e-02,  2.8547e-04, -1.0193e-02,  7.5539e-04,\n",
      "        -7.6066e-03,  8.4312e-03, -8.2065e-03, -1.2210e-02, -7.0125e-03,\n",
      "        -1.4364e-02,  7.3915e-03, -8.7734e-03,  1.4667e-02, -8.8343e-04,\n",
      "        -1.2928e-02,  6.1347e-03,  1.3268e-02,  8.5640e-04, -1.2984e-02,\n",
      "        -1.1751e-03, -1.0831e-02, -9.9101e-03, -1.1506e-02, -6.7958e-03,\n",
      "         6.0002e-03,  4.9380e-03, -3.7659e-03, -7.7178e-04,  4.6370e-03,\n",
      "        -3.1464e-03,  1.1531e-03,  1.3131e-04,  7.1824e-03,  7.1410e-03,\n",
      "        -4.5098e-03, -1.1241e-02, -1.3344e-02, -9.2631e-03, -2.7945e-03,\n",
      "        -6.0675e-03, -2.1072e-03, -1.2195e-02,  8.7846e-03, -9.8244e-03,\n",
      "         2.6968e-03,  7.7829e-03, -2.6998e-03, -1.3461e-02,  5.3988e-03,\n",
      "         2.4576e-03, -9.8424e-04,  2.0561e-03,  3.6176e-03,  1.0322e-02,\n",
      "        -1.4381e-02,  4.8120e-03,  7.8908e-03, -6.9802e-03, -1.2887e-02,\n",
      "        -7.6968e-04,  4.0890e-03, -1.8662e-03, -2.2905e-03,  1.6649e-03,\n",
      "        -1.5615e-03,  1.0612e-02,  7.9434e-03, -2.8976e-03, -7.1088e-03,\n",
      "        -1.1008e-02, -7.5081e-03,  9.6433e-03, -2.4099e-03, -2.8601e-03,\n",
      "         1.7015e-03,  2.0141e-03, -3.4556e-03, -1.3446e-03, -8.6645e-03,\n",
      "        -1.3516e-03, -9.0117e-03, -7.2696e-03,  9.4198e-03, -7.9780e-03,\n",
      "        -9.8156e-03,  8.3771e-03,  6.1419e-03, -1.2209e-02, -1.2156e-02,\n",
      "        -9.7312e-04, -1.1226e-02, -8.2415e-03, -1.4415e-02, -4.9768e-03,\n",
      "        -1.3495e-02])\n",
      "Layer: layer4.1.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])\n",
      "Layer: layer4.1.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer4.1.conv2.weight:, Weights: tensor([[[[-1.3481e-02,  1.5648e-02, -8.0855e-03],\n",
      "          [-1.3396e-03, -9.2259e-03,  2.0821e-03],\n",
      "          [-1.8002e-02,  3.1296e-03, -3.7400e-03]],\n",
      "\n",
      "         [[ 1.1269e-02, -2.9922e-03, -1.6564e-02],\n",
      "          [ 1.5346e-02,  1.2641e-02, -6.3875e-03],\n",
      "          [-1.5296e-02, -1.4084e-02, -1.0691e-03]],\n",
      "\n",
      "         [[ 6.7907e-03, -5.0197e-03,  3.1101e-03],\n",
      "          [-1.6720e-02,  1.3561e-03,  1.2771e-02],\n",
      "          [-7.8279e-03, -8.6720e-03, -1.9043e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6098e-02, -9.3318e-03, -1.3172e-02],\n",
      "          [ 1.2747e-02, -1.1006e-02, -1.6051e-02],\n",
      "          [ 1.3541e-02, -1.7533e-02,  5.4038e-03]],\n",
      "\n",
      "         [[ 7.9146e-03, -1.4592e-03,  9.9060e-03],\n",
      "          [-1.1678e-03,  5.9037e-03,  8.9521e-03],\n",
      "          [-1.4581e-02,  1.3569e-02,  8.3919e-03]],\n",
      "\n",
      "         [[-1.2721e-02,  5.9620e-03,  6.9461e-03],\n",
      "          [ 2.3147e-03,  1.0102e-02, -9.9720e-03],\n",
      "          [ 9.9958e-03,  9.4023e-03, -8.2620e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.3581e-03,  2.7815e-03, -9.9820e-03],\n",
      "          [-2.4590e-03,  1.8409e-02, -4.4571e-03],\n",
      "          [-1.1496e-02,  2.9220e-03, -1.7981e-02]],\n",
      "\n",
      "         [[-1.6351e-02, -1.4251e-02,  1.6646e-02],\n",
      "          [-2.0765e-02, -3.2791e-03, -1.4067e-02],\n",
      "          [-1.3407e-02,  1.6162e-02,  2.0167e-02]],\n",
      "\n",
      "         [[-9.4724e-03, -1.0895e-02, -5.5297e-03],\n",
      "          [ 1.3710e-03, -1.7275e-02,  8.8247e-03],\n",
      "          [ 1.4487e-02,  1.8763e-02, -1.5768e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4132e-02,  1.9922e-02,  1.4108e-02],\n",
      "          [ 6.5364e-03, -3.6072e-03,  1.0581e-02],\n",
      "          [-1.9469e-02,  1.6838e-02, -1.8602e-02]],\n",
      "\n",
      "         [[ 5.2057e-03,  6.2470e-03,  1.6960e-02],\n",
      "          [-4.9176e-03,  6.3782e-03,  9.1943e-05],\n",
      "          [ 2.0565e-02,  9.7760e-03,  1.6137e-02]],\n",
      "\n",
      "         [[-1.0603e-02,  7.8683e-03,  8.2410e-03],\n",
      "          [ 1.4676e-02,  6.7075e-03, -1.4363e-02],\n",
      "          [ 1.4584e-02, -1.1581e-02,  1.3269e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7183e-03, -1.8991e-02, -8.5743e-03],\n",
      "          [-1.8095e-02,  1.7234e-02,  1.3305e-02],\n",
      "          [ 1.7267e-02, -9.9851e-03, -1.8362e-03]],\n",
      "\n",
      "         [[ 6.2242e-04, -2.3631e-03, -5.5411e-03],\n",
      "          [-6.2267e-03,  7.4955e-03, -9.8782e-03],\n",
      "          [ 1.2388e-02, -1.4588e-02, -1.6847e-02]],\n",
      "\n",
      "         [[-4.3157e-03, -5.3618e-03,  1.1017e-02],\n",
      "          [-9.7774e-03, -1.9779e-02,  3.8526e-03],\n",
      "          [ 6.1327e-03, -5.2232e-03, -5.5506e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5880e-03,  4.2071e-03,  1.3153e-04],\n",
      "          [ 6.0134e-03, -1.9082e-03, -1.8532e-02],\n",
      "          [ 6.1748e-03, -1.8432e-03, -1.2734e-02]],\n",
      "\n",
      "         [[-4.9816e-03, -1.8735e-02,  1.2810e-02],\n",
      "          [ 1.4602e-02, -1.1671e-02,  2.7362e-03],\n",
      "          [-8.7069e-03,  1.3999e-02,  1.8780e-02]],\n",
      "\n",
      "         [[ 1.0324e-02,  2.8569e-03, -1.8853e-02],\n",
      "          [ 8.4528e-03,  4.8238e-03,  1.1092e-02],\n",
      "          [-7.3392e-03, -1.2001e-02,  3.0494e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.6633e-02, -2.0291e-02, -3.4344e-03],\n",
      "          [ 6.1767e-03, -8.8988e-03,  4.5484e-03],\n",
      "          [ 5.0658e-03, -8.3703e-03, -1.5849e-02]],\n",
      "\n",
      "         [[-8.8655e-03, -4.9903e-03,  1.4437e-02],\n",
      "          [ 7.7916e-03,  7.2209e-03, -9.2554e-03],\n",
      "          [ 1.5335e-02,  4.9001e-04,  9.1656e-03]],\n",
      "\n",
      "         [[ 2.6384e-03,  1.8665e-02,  9.9681e-03],\n",
      "          [-1.6488e-02, -1.7602e-02,  1.5662e-02],\n",
      "          [ 1.6404e-02, -4.0657e-03, -4.7056e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6493e-02,  2.3619e-03,  1.7713e-02],\n",
      "          [ 1.6427e-02,  9.6466e-03,  1.3008e-02],\n",
      "          [ 4.0428e-03,  1.0283e-02,  1.8435e-02]],\n",
      "\n",
      "         [[-6.2130e-04,  5.1196e-03,  1.4609e-02],\n",
      "          [-2.0450e-02,  3.7039e-03, -1.4368e-02],\n",
      "          [-5.0173e-03, -2.6873e-03, -1.8768e-02]],\n",
      "\n",
      "         [[-3.8057e-03, -1.7833e-02, -8.8802e-03],\n",
      "          [ 8.3463e-03,  6.7319e-03,  6.0790e-03],\n",
      "          [-1.4701e-02,  5.4843e-03,  5.7331e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.8831e-03, -7.4479e-03,  9.3622e-03],\n",
      "          [ 6.6064e-03, -8.4675e-03, -1.6319e-02],\n",
      "          [-1.6457e-02, -5.8473e-03, -3.9956e-03]],\n",
      "\n",
      "         [[-7.5023e-03,  4.6170e-03, -7.7174e-03],\n",
      "          [ 7.3669e-03,  1.1633e-02, -1.6352e-02],\n",
      "          [ 3.0106e-04,  1.1605e-02, -1.1053e-02]],\n",
      "\n",
      "         [[-1.8567e-02,  1.9987e-02,  5.5794e-03],\n",
      "          [ 8.1193e-03,  2.8974e-03,  1.5366e-02],\n",
      "          [ 1.7296e-02, -1.4564e-03,  1.7946e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.2598e-03, -4.5995e-03,  5.3755e-04],\n",
      "          [ 1.9245e-02, -1.2809e-02,  1.8304e-02],\n",
      "          [ 1.5979e-02, -1.6590e-03, -1.7153e-03]],\n",
      "\n",
      "         [[ 4.5873e-03,  9.9321e-03, -1.5880e-02],\n",
      "          [ 1.7978e-02, -4.7880e-03,  1.5114e-02],\n",
      "          [ 1.2712e-02,  1.2660e-04,  1.5566e-02]],\n",
      "\n",
      "         [[ 8.1886e-04, -2.6990e-04,  1.4917e-02],\n",
      "          [-4.8665e-03,  1.8261e-03,  5.3856e-03],\n",
      "          [-2.8162e-03, -2.8346e-03,  1.5827e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0737e-02,  1.0822e-03, -8.5839e-03],\n",
      "          [-1.0216e-02,  3.5174e-03, -1.4585e-02],\n",
      "          [ 3.7783e-03,  1.9784e-02,  6.4393e-03]],\n",
      "\n",
      "         [[ 4.0117e-03,  7.4684e-03,  1.6026e-02],\n",
      "          [-1.1971e-02, -1.5657e-02,  1.7295e-02],\n",
      "          [-9.1373e-04, -9.2820e-03, -3.8388e-03]],\n",
      "\n",
      "         [[-1.3204e-02, -1.2792e-02,  1.4394e-02],\n",
      "          [ 1.7421e-02,  9.3683e-03, -1.9325e-02],\n",
      "          [-8.5614e-03, -1.4140e-02, -1.7633e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4591e-02,  6.7456e-03,  1.9271e-02],\n",
      "          [-1.7171e-02,  1.9107e-02,  1.9342e-02],\n",
      "          [-1.7470e-02, -1.4976e-02,  2.0811e-02]],\n",
      "\n",
      "         [[ 4.8115e-03,  5.2717e-03, -8.7715e-03],\n",
      "          [ 8.2617e-03,  4.2856e-03,  3.6032e-03],\n",
      "          [ 2.0485e-02, -5.7534e-03, -1.3073e-02]],\n",
      "\n",
      "         [[-3.2066e-03,  2.5811e-03, -2.0462e-02],\n",
      "          [ 1.4987e-02,  4.3953e-03, -1.8606e-02],\n",
      "          [ 9.3074e-03,  2.8133e-03, -1.8399e-02]]]])\n",
      "Layer: layer4.1.conv2.bias, Biases: tensor([-1.7547e-03,  2.1833e-03, -2.0144e-02, -1.3624e-02,  1.4402e-02,\n",
      "         1.1266e-02,  1.3417e-03,  1.0181e-02,  1.9782e-02,  8.3161e-04,\n",
      "         1.4872e-02,  2.0749e-02, -1.2878e-02, -1.1607e-02,  2.1576e-03,\n",
      "         1.8767e-02,  1.5790e-02,  1.4665e-02, -1.7052e-02, -2.4050e-03,\n",
      "        -1.0711e-02,  1.6286e-02, -2.0697e-02,  1.8767e-02,  3.0798e-03,\n",
      "         1.1279e-02,  1.7251e-02, -2.0027e-02,  1.3392e-02,  1.9961e-02,\n",
      "         9.5934e-03, -2.0081e-02,  2.3883e-03,  2.4975e-03,  9.2038e-03,\n",
      "         8.9268e-03,  3.6437e-03,  1.6008e-02, -1.0447e-02, -3.9767e-03,\n",
      "         5.0062e-04, -1.2408e-02,  1.6535e-02, -1.0467e-02, -2.1705e-03,\n",
      "        -1.5129e-04, -1.8737e-02, -6.3302e-03,  9.3535e-03,  1.7214e-02,\n",
      "         5.7729e-03, -2.0637e-02,  1.3861e-02,  5.8337e-03,  1.9578e-02,\n",
      "         1.6061e-02, -5.0658e-03,  1.6809e-02, -2.3849e-04, -1.6304e-02,\n",
      "         2.0581e-02, -3.9887e-03, -1.2002e-02, -1.8293e-02, -1.2493e-02,\n",
      "         1.0084e-02,  6.5889e-03, -1.2109e-02,  1.0161e-02,  1.2881e-02,\n",
      "        -6.1058e-03,  9.1062e-03,  4.5925e-03,  2.6953e-03,  1.3575e-02,\n",
      "        -1.8151e-02, -4.4981e-03,  1.0484e-02, -1.2129e-02, -1.0486e-02,\n",
      "         1.5746e-03, -1.8435e-02, -1.9762e-02, -8.8394e-03, -5.9729e-03,\n",
      "         1.9378e-02,  1.6116e-02,  1.8500e-02, -8.3831e-03, -7.4202e-03,\n",
      "        -1.5081e-02,  7.8580e-03,  1.6132e-02,  6.3263e-04, -6.7554e-04,\n",
      "        -1.5050e-03, -1.0957e-02, -1.3610e-03,  1.0578e-02, -7.2583e-03,\n",
      "         1.9738e-03,  1.2489e-02, -2.8470e-03, -1.2343e-02,  5.0001e-05,\n",
      "         2.0078e-02,  4.6208e-03, -1.0659e-02,  6.2061e-03, -9.7057e-03,\n",
      "        -1.5557e-02,  2.3343e-03,  3.7257e-03, -1.1346e-02, -3.4029e-03,\n",
      "         1.2338e-03,  6.1316e-03, -9.0922e-03, -5.3661e-03, -1.9624e-02,\n",
      "         1.9391e-02, -1.2060e-02, -6.3926e-04,  8.3363e-03,  1.9995e-03,\n",
      "         2.0107e-02,  6.6182e-03, -1.3448e-02,  8.3732e-03,  1.9225e-02,\n",
      "        -1.9870e-02, -6.1680e-03,  7.3362e-03, -1.5158e-02,  8.4770e-03,\n",
      "        -2.6387e-03,  7.6716e-04,  1.7028e-03, -4.7143e-03, -6.8145e-03,\n",
      "         1.9249e-02, -7.4998e-04, -1.9926e-02, -1.5589e-03,  1.3746e-02,\n",
      "         2.0200e-02, -1.8431e-02,  1.3029e-03, -1.9473e-02, -1.8583e-02,\n",
      "         2.8717e-03,  5.0554e-03,  1.1905e-02,  1.2782e-02, -4.6376e-03,\n",
      "         7.5233e-03,  2.0063e-02,  4.1601e-04,  1.8540e-02, -1.8609e-02,\n",
      "         1.7151e-02,  1.0327e-02,  1.7754e-02,  4.7226e-03,  1.0980e-02,\n",
      "        -6.7619e-03,  8.9823e-03,  1.4050e-02, -1.1978e-02, -1.1878e-02,\n",
      "        -1.4930e-02,  1.2608e-02,  1.8898e-02,  1.4517e-02,  5.2200e-03,\n",
      "         7.2068e-03,  1.3780e-02, -2.0054e-02, -7.2047e-06, -8.7800e-03,\n",
      "         1.0099e-02,  1.2825e-02, -3.7289e-03,  1.2191e-02,  1.1718e-02,\n",
      "        -7.3765e-03, -1.9037e-02,  5.0754e-03, -1.8868e-02, -6.4223e-03,\n",
      "         7.8005e-03,  1.8844e-02,  1.9385e-02,  1.1006e-02, -1.7100e-02,\n",
      "         4.0848e-03,  7.8338e-03,  1.7925e-04,  9.5315e-03,  2.0774e-02,\n",
      "        -1.4897e-02, -1.6351e-02,  1.6412e-02, -6.8942e-03,  9.7602e-03,\n",
      "        -1.6702e-02,  9.5824e-03,  2.0485e-02, -1.5236e-02, -1.2405e-02,\n",
      "        -1.6511e-02, -1.1652e-02, -5.0625e-03, -6.1218e-03, -6.6411e-03,\n",
      "        -1.8307e-02,  1.5703e-02,  1.0639e-02, -9.8149e-03, -7.2958e-04,\n",
      "         5.3646e-03, -5.3611e-03,  5.4749e-03, -1.0167e-02,  1.4333e-02,\n",
      "        -8.9837e-03, -9.5367e-03, -8.3753e-03,  1.4287e-02,  1.9418e-02,\n",
      "         1.1069e-02, -2.0779e-02,  7.3914e-03,  2.4469e-04, -1.5793e-02,\n",
      "        -1.2347e-02,  9.7353e-03,  5.6069e-03, -1.6668e-03,  1.1399e-02,\n",
      "         1.8147e-02,  1.8210e-02,  9.5268e-03,  1.7142e-02, -2.0879e-03,\n",
      "        -2.8171e-03,  1.5178e-02,  1.4522e-02,  7.4286e-03,  1.4867e-02,\n",
      "        -1.8162e-02, -1.8513e-02,  5.1533e-03, -1.6207e-02, -2.0114e-02,\n",
      "        -1.2018e-02, -1.7688e-02,  1.0199e-02, -1.5786e-02,  1.5179e-02,\n",
      "        -1.5854e-02, -1.9154e-02,  1.8012e-02,  1.3899e-02,  7.1569e-03,\n",
      "         2.0209e-02,  1.4287e-02, -1.0664e-02, -1.5023e-02,  6.3088e-03,\n",
      "         8.4249e-03, -2.5347e-03,  7.8470e-03, -1.2103e-02,  1.9679e-02,\n",
      "         1.8145e-02, -1.2271e-02, -1.6753e-02,  1.7599e-02, -6.0994e-03,\n",
      "         3.8490e-03,  1.0373e-02,  7.2651e-03, -1.4678e-02,  4.6371e-03,\n",
      "         1.1312e-02,  2.6310e-03, -2.2487e-03,  6.3845e-03, -7.8028e-03,\n",
      "        -3.3949e-04,  1.5112e-02,  3.9940e-03,  1.4910e-02,  5.8444e-04,\n",
      "        -8.7187e-05, -1.1069e-02, -7.5483e-03, -1.7096e-02,  7.6165e-03,\n",
      "         1.5895e-02,  1.4835e-02, -1.6449e-02, -5.0310e-03, -1.5262e-02,\n",
      "         1.4599e-02, -1.5194e-02, -1.4531e-02,  1.2281e-02,  1.9735e-02,\n",
      "        -5.8209e-03,  7.5104e-03, -3.8417e-03,  6.7747e-03,  6.3957e-03,\n",
      "         5.8310e-03, -5.3877e-03,  1.9412e-02,  1.3160e-02,  6.7653e-03,\n",
      "        -4.3568e-03,  1.5684e-02, -1.5257e-02, -1.8253e-03, -5.4588e-03,\n",
      "         7.5275e-03, -1.4849e-02, -1.0788e-02,  7.9570e-03, -1.0563e-02,\n",
      "        -1.1328e-02,  6.6046e-04, -6.9474e-03, -8.9964e-03, -3.9716e-03,\n",
      "        -1.6407e-02, -1.7533e-02,  6.2674e-03, -2.3253e-03,  7.7611e-03,\n",
      "         9.3529e-03,  1.5758e-02, -8.8546e-03,  1.1717e-02,  8.1969e-04,\n",
      "         9.2908e-03, -1.2212e-02,  1.7236e-02,  1.0332e-02, -1.7692e-03,\n",
      "        -9.7269e-03, -6.6950e-03, -1.8091e-02,  2.0045e-02, -1.2210e-02,\n",
      "        -1.1416e-02,  1.4058e-02, -1.9511e-02, -1.0331e-02, -6.3686e-03,\n",
      "         2.6503e-04,  3.0130e-04,  1.1276e-02, -3.1327e-03,  1.9255e-02,\n",
      "         2.7502e-03, -1.5491e-02,  7.7824e-03, -1.9268e-02, -1.1869e-02,\n",
      "         1.8454e-02, -1.2793e-02,  2.3200e-03, -4.2590e-03, -8.4761e-03,\n",
      "        -1.3894e-02,  4.2459e-03,  1.2949e-02, -7.8496e-03, -1.3660e-03,\n",
      "        -1.4699e-02,  1.3052e-02,  1.8637e-02, -2.0331e-02, -1.9696e-02,\n",
      "         7.4298e-03,  2.0005e-02, -2.2694e-03,  1.2344e-02, -2.3903e-04,\n",
      "         1.5094e-04, -1.5235e-02,  1.2418e-02,  3.1844e-03, -2.0217e-02,\n",
      "        -1.1177e-02,  1.8941e-02, -9.9148e-03,  1.6867e-02,  1.8202e-02,\n",
      "         2.0308e-02,  7.5891e-03, -1.0209e-02, -3.4914e-03,  1.0934e-02,\n",
      "        -9.5318e-03, -9.0225e-03, -1.1576e-02,  1.2610e-02,  1.5939e-02,\n",
      "         6.6867e-03, -1.1506e-02,  4.9507e-03,  4.3152e-03,  4.6454e-03,\n",
      "         2.4254e-03,  1.1844e-02, -3.7382e-04, -9.5714e-03, -1.2493e-02,\n",
      "         1.2484e-02, -1.7018e-02, -8.3474e-03,  1.4759e-02,  2.7176e-03,\n",
      "        -7.4106e-03, -9.1688e-03, -1.5791e-02,  1.0498e-02,  1.5078e-02,\n",
      "        -1.9434e-02, -1.9872e-02, -7.6863e-03,  8.1616e-03,  1.6196e-02,\n",
      "         4.8067e-03,  8.4762e-03, -1.1965e-02,  7.0841e-03, -1.5523e-02,\n",
      "        -1.1479e-02,  9.7820e-03,  1.9647e-02,  1.9586e-02, -1.0105e-02,\n",
      "         2.5721e-03,  1.9070e-02, -9.6159e-03, -1.6205e-02,  5.3250e-03,\n",
      "        -3.1151e-05,  1.7646e-02, -4.3502e-03,  1.7787e-02,  2.9350e-03,\n",
      "        -3.7595e-04, -2.0791e-02,  1.1654e-02,  7.8687e-03,  1.3885e-02,\n",
      "         1.9497e-02, -7.6196e-03,  1.2681e-02, -1.2782e-02,  8.3394e-03,\n",
      "        -5.4916e-03, -1.9523e-02,  3.4792e-04, -1.0446e-02,  7.2187e-03,\n",
      "        -3.6151e-03, -1.4184e-02,  4.9861e-03, -1.3393e-03, -9.9902e-03,\n",
      "         6.9534e-03, -1.2489e-03,  1.1507e-02,  2.0539e-03, -1.1271e-02,\n",
      "        -2.0158e-02, -1.1250e-02, -1.8977e-02, -9.3382e-03, -7.6646e-03,\n",
      "         1.9972e-02, -1.4168e-02, -1.2611e-02, -1.2789e-02, -1.2115e-03,\n",
      "        -1.3862e-02,  1.3455e-02,  1.6774e-02, -6.8587e-03,  1.7124e-03,\n",
      "        -8.3066e-03,  1.7768e-02,  2.0464e-02,  1.6625e-02, -2.2600e-03,\n",
      "        -1.0859e-02,  1.8851e-02, -1.3333e-02, -1.0141e-02, -4.0533e-03,\n",
      "        -5.1173e-04,  8.4564e-03,  4.6342e-03,  1.1113e-02,  2.0004e-02,\n",
      "         1.5619e-02, -8.3277e-03])\n",
      "Layer: layer4.1.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer4.1.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer4.2.conv1.weight:, Weights: tensor([[[[-3.9369e-03, -5.4898e-03, -6.6115e-04],\n",
      "          [-4.5229e-03, -1.1321e-02,  1.2706e-02],\n",
      "          [ 5.4343e-03, -9.4390e-03,  1.4727e-02]],\n",
      "\n",
      "         [[ 4.6258e-03, -2.7240e-03,  3.5002e-03],\n",
      "          [-8.2275e-03, -9.7673e-03,  3.9434e-04],\n",
      "          [-1.3123e-02,  1.3743e-02,  8.4979e-03]],\n",
      "\n",
      "         [[ 2.3951e-04,  1.1276e-02,  8.8053e-03],\n",
      "          [-4.5484e-03, -5.8466e-03,  9.2385e-03],\n",
      "          [ 6.8505e-03,  1.0248e-02, -4.1416e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4186e-04, -1.1414e-03, -1.3676e-02],\n",
      "          [ 4.8434e-03,  6.1396e-03, -1.4376e-02],\n",
      "          [-9.5486e-03, -4.7595e-03, -1.1439e-02]],\n",
      "\n",
      "         [[ 1.4490e-02, -3.9882e-03, -1.1408e-02],\n",
      "          [ 1.3278e-02,  1.0051e-02,  1.3474e-02],\n",
      "          [ 6.2878e-03,  3.7343e-03, -1.0156e-02]],\n",
      "\n",
      "         [[-1.4682e-02, -1.1722e-02, -1.1471e-02],\n",
      "          [-2.9992e-03,  1.0031e-02,  9.4627e-03],\n",
      "          [ 6.4028e-03,  3.7820e-03,  1.1804e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3583e-03, -1.3368e-02,  2.3052e-03],\n",
      "          [ 2.9016e-03, -1.7465e-03, -2.1182e-03],\n",
      "          [-3.5378e-03, -7.1032e-03,  5.2773e-03]],\n",
      "\n",
      "         [[ 4.0195e-04,  1.2596e-02, -1.3977e-02],\n",
      "          [ 6.6278e-03, -1.3049e-02,  4.8090e-03],\n",
      "          [ 8.8744e-03, -1.1380e-02, -2.8964e-03]],\n",
      "\n",
      "         [[-7.1459e-03, -4.6696e-03,  2.3857e-03],\n",
      "          [-1.2894e-02, -1.3426e-02,  5.9994e-03],\n",
      "          [-1.4499e-03,  1.4014e-02,  1.1510e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.7405e-03, -4.3509e-03,  1.3216e-03],\n",
      "          [ 2.2411e-04, -2.5086e-03,  1.5237e-04],\n",
      "          [ 9.1572e-03, -1.4750e-03,  1.1717e-03]],\n",
      "\n",
      "         [[ 7.3795e-03,  2.1107e-03,  6.6048e-03],\n",
      "          [-7.4478e-03, -1.7196e-03, -1.1271e-03],\n",
      "          [-1.3444e-02, -1.4461e-03,  1.6224e-03]],\n",
      "\n",
      "         [[ 3.5642e-05,  1.7152e-04,  4.0601e-03],\n",
      "          [ 1.4083e-02,  7.3870e-03, -2.5925e-04],\n",
      "          [ 1.0709e-02,  1.3124e-02,  1.1211e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.8526e-03, -4.7681e-03, -5.7238e-03],\n",
      "          [ 1.0650e-02, -8.1554e-03,  9.7617e-03],\n",
      "          [ 8.8746e-03,  5.7860e-03,  1.0346e-02]],\n",
      "\n",
      "         [[-9.7541e-03,  1.0178e-02, -6.7437e-03],\n",
      "          [-1.1186e-02, -5.3279e-03,  4.3555e-03],\n",
      "          [-1.4446e-02, -1.3214e-03, -4.0857e-03]],\n",
      "\n",
      "         [[ 7.1446e-03,  8.5695e-03, -1.4612e-02],\n",
      "          [ 5.7718e-03, -3.3105e-04, -5.7069e-03],\n",
      "          [ 5.7486e-03, -1.4417e-02,  8.2927e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5088e-03,  5.3693e-03,  9.4782e-03],\n",
      "          [-1.0447e-02, -1.3879e-02, -8.6384e-03],\n",
      "          [ 2.8250e-03, -6.1357e-04, -6.1043e-03]],\n",
      "\n",
      "         [[ 2.6958e-03, -1.0972e-02,  1.0361e-02],\n",
      "          [-1.3195e-02,  1.5255e-03,  1.2464e-03],\n",
      "          [-3.6085e-03, -4.4147e-03,  9.8827e-03]],\n",
      "\n",
      "         [[ 2.8871e-03, -1.4607e-02, -1.0535e-03],\n",
      "          [-1.2025e-02, -9.5082e-03, -1.6852e-03],\n",
      "          [ 1.9810e-03, -1.3554e-02,  8.7380e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0532e-02,  1.1899e-02,  8.7972e-03],\n",
      "          [ 3.6950e-03, -1.4659e-02,  5.2322e-03],\n",
      "          [ 4.9321e-03, -1.3490e-02,  2.7551e-03]],\n",
      "\n",
      "         [[-8.2507e-03, -4.2900e-03,  3.1349e-03],\n",
      "          [ 7.8349e-03,  3.1743e-03,  2.8623e-03],\n",
      "          [-4.3669e-03, -2.1508e-03, -1.3116e-02]],\n",
      "\n",
      "         [[-7.3433e-03,  1.1464e-02,  9.1490e-03],\n",
      "          [-5.2518e-03, -1.0053e-02, -5.3565e-03],\n",
      "          [ 1.0681e-03, -7.9759e-04, -3.0123e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.4169e-03, -1.6405e-03, -1.2011e-02],\n",
      "          [ 3.3210e-04, -4.6168e-03,  2.6140e-03],\n",
      "          [-1.2921e-04,  6.9529e-03, -5.3451e-03]],\n",
      "\n",
      "         [[-5.1612e-03, -9.0512e-03,  1.4306e-03],\n",
      "          [ 8.5155e-04, -5.8379e-03, -1.2192e-02],\n",
      "          [-9.8373e-03,  1.0685e-02,  1.1534e-02]],\n",
      "\n",
      "         [[-1.3681e-02, -3.2910e-04,  1.3908e-03],\n",
      "          [-1.5495e-03, -9.4975e-04, -6.2612e-03],\n",
      "          [ 2.4152e-03, -1.2255e-02, -5.3417e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5842e-03, -4.9289e-03, -9.0101e-03],\n",
      "          [-2.6050e-03, -1.2191e-02,  2.6333e-03],\n",
      "          [-1.3409e-02,  2.1061e-03,  6.4624e-03]],\n",
      "\n",
      "         [[-6.4934e-03, -1.6149e-03, -5.8153e-03],\n",
      "          [-9.2011e-03,  2.0403e-03, -4.7577e-03],\n",
      "          [ 1.1403e-02, -2.0322e-03, -3.9281e-04]],\n",
      "\n",
      "         [[ 1.2855e-02,  4.3747e-03, -7.5873e-03],\n",
      "          [ 8.4087e-03, -5.1379e-03, -1.0441e-02],\n",
      "          [ 1.2730e-04, -3.0034e-03,  4.7238e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2958e-03, -1.0891e-02, -1.2683e-02],\n",
      "          [ 1.2796e-02,  6.2935e-03, -1.0279e-02],\n",
      "          [-1.3539e-04, -5.1289e-03, -1.4437e-02]],\n",
      "\n",
      "         [[ 1.1001e-03,  5.4670e-03,  1.0758e-02],\n",
      "          [-7.7279e-03, -3.3145e-03,  1.7909e-03],\n",
      "          [ 6.2958e-03,  1.2746e-02, -1.3962e-02]],\n",
      "\n",
      "         [[-1.4082e-02, -3.1314e-03, -1.7555e-03],\n",
      "          [ 2.1689e-03, -1.9051e-03, -7.3209e-03],\n",
      "          [-1.0793e-02,  1.2462e-02,  5.7350e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5763e-03,  4.0353e-04, -7.3991e-03],\n",
      "          [ 3.6810e-03,  1.0545e-02,  1.1257e-02],\n",
      "          [-2.8891e-03, -9.5036e-03,  1.3656e-02]],\n",
      "\n",
      "         [[-5.6177e-03, -1.5778e-03,  5.7058e-03],\n",
      "          [-3.1263e-04, -5.8573e-03, -4.1478e-03],\n",
      "          [ 6.3286e-03,  2.8983e-03,  3.2482e-03]],\n",
      "\n",
      "         [[-2.9523e-03,  5.2487e-03,  1.1063e-02],\n",
      "          [ 1.6861e-03,  4.3402e-03,  2.2875e-03],\n",
      "          [ 1.2781e-02,  1.4075e-02,  1.9784e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2747e-03,  1.3456e-02,  4.9472e-03],\n",
      "          [ 6.6042e-03, -1.1889e-02, -6.3807e-03],\n",
      "          [-9.8295e-03,  6.6531e-03, -1.0348e-02]],\n",
      "\n",
      "         [[ 1.4488e-03,  9.0780e-03, -1.1360e-02],\n",
      "          [-8.8125e-03,  5.0922e-03,  7.5442e-03],\n",
      "          [-1.3625e-03, -1.0128e-02,  4.8326e-03]],\n",
      "\n",
      "         [[ 9.8089e-03,  8.2318e-03,  1.0626e-02],\n",
      "          [ 7.2333e-03, -1.2472e-02,  6.8727e-03],\n",
      "          [ 6.0170e-03, -1.4675e-02,  4.3822e-03]]]])\n",
      "Layer: layer4.2.conv1.bias, Biases: tensor([-8.6414e-03,  9.0247e-03, -3.4226e-04,  5.6517e-03,  1.1316e-02,\n",
      "         2.1224e-04, -1.0254e-02,  2.6149e-03, -9.0666e-03, -4.1427e-03,\n",
      "         8.9739e-03,  1.6243e-03, -1.2716e-02,  8.6736e-03,  1.3188e-02,\n",
      "         4.3859e-03,  9.1941e-04, -9.1718e-03, -8.8482e-03, -1.3564e-02,\n",
      "         2.2741e-03, -1.4356e-02,  1.3232e-02, -1.0855e-03, -1.4203e-02,\n",
      "         9.8080e-03, -1.3556e-02,  7.2734e-03,  1.4455e-02, -2.7563e-03,\n",
      "        -4.3320e-03, -1.2242e-02,  1.1783e-02,  5.9968e-03,  9.5893e-03,\n",
      "         1.4624e-02,  4.0106e-03, -6.5970e-03, -1.9286e-03, -1.2489e-02,\n",
      "        -4.9937e-03, -1.5433e-03, -1.2462e-02, -1.0738e-02, -2.4648e-03,\n",
      "         1.3703e-02,  7.0625e-03, -1.0951e-02,  9.5506e-04,  9.0225e-03,\n",
      "        -1.1520e-02,  1.4065e-02, -7.5180e-03, -1.4686e-02,  3.0247e-03,\n",
      "        -9.3899e-03,  1.4509e-02,  8.3389e-03, -3.0681e-03, -5.5637e-03,\n",
      "         3.6603e-03,  1.4503e-02,  4.3342e-03, -1.3600e-02,  1.0469e-02,\n",
      "        -6.1002e-03,  6.9226e-03,  5.6700e-03,  7.6937e-03,  1.4212e-02,\n",
      "         8.9467e-03, -7.8878e-03,  1.0118e-03,  5.9149e-03,  8.1011e-03,\n",
      "        -4.2471e-03, -1.0388e-03, -1.3654e-02, -1.4156e-02,  8.8624e-04,\n",
      "         1.2489e-02, -5.0267e-03, -7.2704e-03,  1.6569e-03, -7.6988e-03,\n",
      "        -5.2998e-04, -5.6984e-03,  4.0047e-04, -6.0651e-03, -3.8932e-04,\n",
      "        -3.6893e-04, -1.2950e-02, -1.2144e-02,  1.0797e-02,  8.8467e-03,\n",
      "         1.2415e-02, -4.7694e-05,  1.1096e-02,  1.8130e-03, -8.9671e-03,\n",
      "         8.9842e-03, -2.7177e-03, -1.2397e-02, -2.1675e-03,  5.3144e-03,\n",
      "        -1.2834e-02,  8.7552e-03,  2.0436e-03,  5.0854e-03,  1.3159e-02,\n",
      "        -1.1520e-02,  1.1211e-02,  1.0409e-03,  6.9262e-03, -1.1651e-02,\n",
      "         4.2542e-03, -2.2807e-03, -2.7338e-04, -5.0628e-03,  9.9204e-03,\n",
      "        -4.1682e-03, -1.4475e-03, -7.3697e-03, -1.0151e-02,  5.7762e-03,\n",
      "        -1.1246e-02, -2.2885e-03, -2.7608e-03,  1.2226e-02,  1.6941e-03,\n",
      "         7.6764e-03,  1.4441e-02, -9.8498e-03,  9.7043e-03, -9.3445e-03,\n",
      "         4.3604e-03,  7.9650e-04,  3.0469e-04,  9.4523e-04, -4.5897e-03,\n",
      "         7.8678e-03, -8.3161e-03,  1.0875e-02, -2.1173e-03,  1.5649e-03,\n",
      "         1.4710e-02, -6.4505e-03, -1.4439e-02,  1.3317e-02,  1.4435e-02,\n",
      "         1.1954e-02,  6.3483e-03, -8.8413e-03,  3.1019e-03, -3.0376e-03,\n",
      "         1.2918e-02, -6.3012e-03, -6.9388e-04, -5.2189e-03,  5.5700e-04,\n",
      "        -1.1803e-02, -4.9295e-03,  8.6976e-03, -8.3628e-03, -7.8109e-03,\n",
      "         4.1016e-03,  3.0381e-03,  8.9254e-03,  7.4320e-03, -7.3198e-03,\n",
      "        -2.5600e-03, -6.6517e-03,  9.0404e-03,  4.8838e-03, -4.3782e-03,\n",
      "        -5.4268e-03,  2.4728e-03,  7.8584e-03, -6.4607e-03,  6.7433e-03,\n",
      "         1.1124e-03,  3.2916e-03, -6.7077e-03,  1.9329e-03, -9.9080e-03,\n",
      "        -3.0320e-03, -6.7376e-03,  1.4257e-03,  6.5586e-03,  3.2840e-03,\n",
      "         8.2462e-03, -1.3884e-02, -1.2204e-02, -1.0461e-02, -6.0950e-03,\n",
      "        -6.8111e-03, -1.0659e-03,  5.1066e-03, -7.6363e-03, -1.2950e-02,\n",
      "         8.4269e-03,  6.1617e-03,  2.7286e-04,  9.1239e-03,  6.0789e-04,\n",
      "         2.9403e-03,  3.9814e-03, -4.3019e-03,  6.3295e-03,  3.9129e-03,\n",
      "         9.9499e-03, -5.8741e-03, -1.0098e-03,  9.0674e-03,  3.1431e-03,\n",
      "         8.8845e-03, -1.1648e-02,  3.6636e-03, -9.9138e-03, -1.3911e-02,\n",
      "        -5.1031e-03, -1.2133e-02, -5.9906e-03,  1.3133e-02,  1.2425e-02,\n",
      "         3.8013e-03, -6.3608e-03, -6.0655e-03,  7.6046e-04,  6.8336e-03,\n",
      "        -6.0978e-03,  4.5578e-03, -8.3807e-03, -3.4496e-03,  1.4082e-02,\n",
      "         8.6860e-03,  5.0618e-03, -4.9033e-03, -3.5631e-03,  5.4200e-03,\n",
      "        -8.1447e-03,  7.0771e-03, -1.0667e-02, -1.3477e-02, -7.7659e-03,\n",
      "        -1.1251e-02, -4.4750e-03,  6.7095e-03,  1.2012e-02,  9.0373e-03,\n",
      "        -9.0274e-03, -3.0083e-03, -1.1474e-02, -5.8537e-03, -1.3503e-02,\n",
      "         1.1942e-02])\n",
      "Layer: layer4.2.bn1.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])\n",
      "Layer: layer4.2.bn1.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: layer4.2.conv2.weight:, Weights: tensor([[[[ 0.0048, -0.0124, -0.0108],\n",
      "          [-0.0113,  0.0064,  0.0055],\n",
      "          [ 0.0183, -0.0169, -0.0066]],\n",
      "\n",
      "         [[ 0.0164,  0.0048,  0.0087],\n",
      "          [ 0.0002, -0.0090, -0.0024],\n",
      "          [-0.0103,  0.0070,  0.0016]],\n",
      "\n",
      "         [[ 0.0117,  0.0133, -0.0103],\n",
      "          [-0.0169,  0.0099,  0.0090],\n",
      "          [-0.0160, -0.0011, -0.0091]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0029,  0.0099,  0.0180],\n",
      "          [ 0.0036,  0.0002,  0.0005],\n",
      "          [-0.0195, -0.0180, -0.0048]],\n",
      "\n",
      "         [[ 0.0056, -0.0123,  0.0172],\n",
      "          [ 0.0030, -0.0053, -0.0187],\n",
      "          [-0.0047, -0.0097,  0.0031]],\n",
      "\n",
      "         [[-0.0139,  0.0131, -0.0202],\n",
      "          [ 0.0187,  0.0040,  0.0128],\n",
      "          [ 0.0044, -0.0040,  0.0206]]],\n",
      "\n",
      "\n",
      "        [[[-0.0098, -0.0130,  0.0017],\n",
      "          [-0.0136, -0.0083,  0.0191],\n",
      "          [ 0.0010,  0.0114,  0.0088]],\n",
      "\n",
      "         [[ 0.0051, -0.0064, -0.0194],\n",
      "          [ 0.0105,  0.0126,  0.0026],\n",
      "          [ 0.0050, -0.0012,  0.0125]],\n",
      "\n",
      "         [[ 0.0068, -0.0111,  0.0030],\n",
      "          [-0.0147,  0.0158,  0.0112],\n",
      "          [-0.0082,  0.0023,  0.0153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0058, -0.0089, -0.0075],\n",
      "          [ 0.0205,  0.0184, -0.0157],\n",
      "          [-0.0027,  0.0033, -0.0206]],\n",
      "\n",
      "         [[-0.0206,  0.0079, -0.0172],\n",
      "          [ 0.0136, -0.0204, -0.0067],\n",
      "          [ 0.0047,  0.0151, -0.0188]],\n",
      "\n",
      "         [[-0.0165,  0.0132,  0.0017],\n",
      "          [ 0.0013,  0.0067, -0.0137],\n",
      "          [-0.0176,  0.0205, -0.0156]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0095, -0.0027, -0.0057],\n",
      "          [-0.0148, -0.0115,  0.0160],\n",
      "          [ 0.0167, -0.0048, -0.0054]],\n",
      "\n",
      "         [[ 0.0168,  0.0036, -0.0124],\n",
      "          [ 0.0182, -0.0206,  0.0078],\n",
      "          [ 0.0191, -0.0167, -0.0007]],\n",
      "\n",
      "         [[-0.0131, -0.0087,  0.0080],\n",
      "          [-0.0195, -0.0200,  0.0034],\n",
      "          [-0.0125,  0.0003, -0.0205]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0115, -0.0080, -0.0053],\n",
      "          [-0.0149,  0.0033, -0.0021],\n",
      "          [-0.0135,  0.0080,  0.0185]],\n",
      "\n",
      "         [[ 0.0019, -0.0157, -0.0181],\n",
      "          [-0.0052, -0.0117,  0.0049],\n",
      "          [ 0.0122, -0.0205,  0.0158]],\n",
      "\n",
      "         [[ 0.0099, -0.0080,  0.0152],\n",
      "          [ 0.0079, -0.0049, -0.0007],\n",
      "          [ 0.0133,  0.0097,  0.0134]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0144,  0.0077,  0.0112],\n",
      "          [ 0.0031, -0.0155, -0.0006],\n",
      "          [-0.0008, -0.0063,  0.0085]],\n",
      "\n",
      "         [[-0.0035,  0.0117,  0.0072],\n",
      "          [ 0.0031,  0.0203, -0.0009],\n",
      "          [-0.0002, -0.0165, -0.0090]],\n",
      "\n",
      "         [[ 0.0146, -0.0091, -0.0012],\n",
      "          [-0.0184, -0.0008, -0.0125],\n",
      "          [-0.0091,  0.0166,  0.0134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0046,  0.0207,  0.0133],\n",
      "          [ 0.0022,  0.0117, -0.0060],\n",
      "          [-0.0120, -0.0201,  0.0183]],\n",
      "\n",
      "         [[-0.0061,  0.0183,  0.0164],\n",
      "          [-0.0038, -0.0118, -0.0082],\n",
      "          [ 0.0047,  0.0039, -0.0020]],\n",
      "\n",
      "         [[ 0.0116, -0.0136, -0.0020],\n",
      "          [-0.0127, -0.0183, -0.0142],\n",
      "          [-0.0181,  0.0035,  0.0139]]],\n",
      "\n",
      "\n",
      "        [[[-0.0183,  0.0037, -0.0184],\n",
      "          [-0.0042, -0.0190,  0.0031],\n",
      "          [-0.0109,  0.0036,  0.0075]],\n",
      "\n",
      "         [[ 0.0133, -0.0183,  0.0176],\n",
      "          [-0.0005, -0.0131, -0.0171],\n",
      "          [ 0.0194,  0.0173,  0.0053]],\n",
      "\n",
      "         [[-0.0118,  0.0077,  0.0090],\n",
      "          [ 0.0194, -0.0183,  0.0056],\n",
      "          [-0.0100, -0.0204,  0.0029]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0158, -0.0105, -0.0095],\n",
      "          [-0.0114, -0.0167, -0.0122],\n",
      "          [ 0.0179, -0.0142, -0.0115]],\n",
      "\n",
      "         [[ 0.0177,  0.0104,  0.0130],\n",
      "          [ 0.0189, -0.0196,  0.0042],\n",
      "          [-0.0081,  0.0005,  0.0158]],\n",
      "\n",
      "         [[ 0.0052,  0.0100,  0.0003],\n",
      "          [-0.0039,  0.0158,  0.0037],\n",
      "          [-0.0116,  0.0177, -0.0151]]],\n",
      "\n",
      "\n",
      "        [[[-0.0172,  0.0206,  0.0066],\n",
      "          [-0.0160, -0.0070,  0.0046],\n",
      "          [-0.0204,  0.0165,  0.0160]],\n",
      "\n",
      "         [[-0.0042,  0.0003, -0.0064],\n",
      "          [ 0.0093, -0.0079,  0.0046],\n",
      "          [-0.0045,  0.0039,  0.0085]],\n",
      "\n",
      "         [[ 0.0026, -0.0206,  0.0121],\n",
      "          [-0.0043,  0.0089,  0.0162],\n",
      "          [-0.0129, -0.0138, -0.0170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0130, -0.0035, -0.0155],\n",
      "          [ 0.0148, -0.0111, -0.0113],\n",
      "          [ 0.0107,  0.0166, -0.0077]],\n",
      "\n",
      "         [[ 0.0052, -0.0066,  0.0017],\n",
      "          [-0.0136, -0.0183, -0.0070],\n",
      "          [-0.0151, -0.0110,  0.0026]],\n",
      "\n",
      "         [[ 0.0068, -0.0079, -0.0006],\n",
      "          [-0.0032, -0.0112,  0.0026],\n",
      "          [ 0.0041,  0.0177, -0.0159]]]])\n",
      "Layer: layer4.2.conv2.bias, Biases: tensor([-0.0066, -0.0183,  0.0162,  0.0062, -0.0031,  0.0139, -0.0134, -0.0175,\n",
      "        -0.0088, -0.0180, -0.0065, -0.0126, -0.0020, -0.0165, -0.0075,  0.0167,\n",
      "         0.0020, -0.0094, -0.0065,  0.0159,  0.0050, -0.0170,  0.0039,  0.0129,\n",
      "         0.0051,  0.0170,  0.0153,  0.0084, -0.0103, -0.0051,  0.0072,  0.0088,\n",
      "         0.0063,  0.0153,  0.0173,  0.0208, -0.0040, -0.0102, -0.0014, -0.0144,\n",
      "        -0.0195, -0.0023, -0.0157,  0.0071, -0.0206, -0.0083, -0.0199,  0.0030,\n",
      "         0.0179,  0.0073, -0.0082,  0.0159,  0.0042, -0.0100, -0.0024, -0.0052,\n",
      "         0.0194,  0.0087,  0.0013,  0.0114, -0.0142, -0.0132,  0.0027, -0.0178,\n",
      "         0.0167,  0.0010,  0.0050,  0.0094,  0.0152,  0.0176,  0.0084,  0.0054,\n",
      "        -0.0086, -0.0126, -0.0117, -0.0093, -0.0106,  0.0070,  0.0188,  0.0179,\n",
      "         0.0079, -0.0205, -0.0108, -0.0103, -0.0200, -0.0160, -0.0156, -0.0033,\n",
      "         0.0005,  0.0105,  0.0149,  0.0039, -0.0014,  0.0112, -0.0077,  0.0006,\n",
      "        -0.0195,  0.0043,  0.0004,  0.0178,  0.0167,  0.0069, -0.0151,  0.0179,\n",
      "         0.0049,  0.0032, -0.0123, -0.0039,  0.0039, -0.0179,  0.0169, -0.0022,\n",
      "         0.0192,  0.0081, -0.0114, -0.0133, -0.0122, -0.0101, -0.0190, -0.0012,\n",
      "         0.0042,  0.0121,  0.0068, -0.0093,  0.0016, -0.0094, -0.0014,  0.0108,\n",
      "         0.0081, -0.0043, -0.0090, -0.0171, -0.0171, -0.0139,  0.0078,  0.0164,\n",
      "         0.0026,  0.0067, -0.0019, -0.0147, -0.0175, -0.0181,  0.0091, -0.0168,\n",
      "        -0.0108, -0.0043,  0.0094, -0.0208, -0.0033, -0.0193,  0.0008, -0.0080,\n",
      "         0.0041, -0.0017,  0.0111, -0.0169,  0.0010,  0.0081,  0.0041, -0.0163,\n",
      "         0.0138, -0.0042,  0.0033, -0.0066, -0.0053,  0.0009,  0.0152, -0.0030,\n",
      "        -0.0030,  0.0186,  0.0195, -0.0060, -0.0118,  0.0157,  0.0129, -0.0032,\n",
      "         0.0093, -0.0071, -0.0198, -0.0155, -0.0062,  0.0088,  0.0007, -0.0202,\n",
      "        -0.0184,  0.0034,  0.0116,  0.0033,  0.0127,  0.0204,  0.0136,  0.0148,\n",
      "         0.0181, -0.0160, -0.0112,  0.0160, -0.0184,  0.0171,  0.0104, -0.0115,\n",
      "        -0.0064,  0.0121,  0.0014, -0.0059, -0.0045, -0.0147, -0.0081, -0.0157,\n",
      "        -0.0072, -0.0116,  0.0183, -0.0040,  0.0157,  0.0047,  0.0068,  0.0105,\n",
      "        -0.0030, -0.0048,  0.0040,  0.0140, -0.0200, -0.0140, -0.0180,  0.0077,\n",
      "         0.0023,  0.0054,  0.0171,  0.0165, -0.0072,  0.0146,  0.0103,  0.0154,\n",
      "        -0.0171,  0.0018, -0.0087, -0.0010,  0.0016, -0.0045,  0.0035,  0.0117,\n",
      "        -0.0059,  0.0061, -0.0054,  0.0105,  0.0202,  0.0156,  0.0207, -0.0168,\n",
      "         0.0136,  0.0128, -0.0168, -0.0137, -0.0078, -0.0014,  0.0167, -0.0174,\n",
      "        -0.0073,  0.0103, -0.0178, -0.0085,  0.0147,  0.0163, -0.0047, -0.0061,\n",
      "        -0.0135,  0.0085, -0.0109,  0.0161,  0.0153,  0.0041, -0.0162, -0.0165,\n",
      "        -0.0142,  0.0185,  0.0013,  0.0092,  0.0065,  0.0145,  0.0079,  0.0042,\n",
      "         0.0071,  0.0054, -0.0059, -0.0113,  0.0043,  0.0076,  0.0207, -0.0096,\n",
      "         0.0165,  0.0052, -0.0099,  0.0059, -0.0100,  0.0101,  0.0189,  0.0022,\n",
      "        -0.0151, -0.0100,  0.0003,  0.0003,  0.0061, -0.0187,  0.0049,  0.0171,\n",
      "         0.0060,  0.0058, -0.0185,  0.0051,  0.0081, -0.0074, -0.0135, -0.0020,\n",
      "        -0.0134, -0.0003,  0.0178, -0.0192,  0.0024, -0.0185, -0.0152, -0.0148,\n",
      "         0.0176,  0.0182, -0.0065, -0.0187,  0.0027,  0.0075, -0.0108,  0.0085,\n",
      "        -0.0196, -0.0073,  0.0205,  0.0068,  0.0090, -0.0145,  0.0052,  0.0182,\n",
      "         0.0158,  0.0117, -0.0053, -0.0155,  0.0164, -0.0016,  0.0046,  0.0003,\n",
      "        -0.0139, -0.0108, -0.0063,  0.0006, -0.0061,  0.0153, -0.0081,  0.0054,\n",
      "        -0.0007, -0.0178, -0.0175,  0.0034, -0.0070, -0.0139,  0.0024, -0.0199,\n",
      "         0.0041, -0.0111, -0.0201, -0.0061,  0.0095, -0.0200,  0.0032, -0.0112,\n",
      "        -0.0085, -0.0168,  0.0056, -0.0180, -0.0170,  0.0019,  0.0105, -0.0207,\n",
      "        -0.0183, -0.0096, -0.0016, -0.0136,  0.0095,  0.0032,  0.0015, -0.0069,\n",
      "         0.0009,  0.0179,  0.0024, -0.0146, -0.0015,  0.0111, -0.0183, -0.0121,\n",
      "         0.0114, -0.0136,  0.0136, -0.0092, -0.0156,  0.0083,  0.0025,  0.0106,\n",
      "         0.0064,  0.0202,  0.0173,  0.0072, -0.0023, -0.0202,  0.0162,  0.0037,\n",
      "         0.0134,  0.0098, -0.0189,  0.0027, -0.0074, -0.0171, -0.0008,  0.0193,\n",
      "        -0.0114,  0.0046,  0.0112,  0.0154, -0.0115, -0.0199,  0.0123, -0.0111,\n",
      "         0.0070, -0.0093, -0.0120,  0.0168, -0.0013,  0.0155,  0.0020,  0.0159,\n",
      "         0.0103,  0.0163,  0.0031, -0.0143,  0.0069,  0.0190, -0.0135, -0.0077,\n",
      "         0.0113,  0.0057, -0.0038,  0.0172, -0.0069,  0.0039, -0.0071,  0.0138,\n",
      "        -0.0127,  0.0053,  0.0097, -0.0104, -0.0101,  0.0150, -0.0088, -0.0049,\n",
      "        -0.0179,  0.0176,  0.0182,  0.0083,  0.0029,  0.0024,  0.0073,  0.0090,\n",
      "        -0.0199, -0.0030, -0.0074,  0.0058, -0.0182,  0.0020,  0.0162, -0.0149,\n",
      "        -0.0192, -0.0017, -0.0174,  0.0154, -0.0187, -0.0207, -0.0175, -0.0074,\n",
      "        -0.0160, -0.0046, -0.0056, -0.0184,  0.0152,  0.0097,  0.0007, -0.0065,\n",
      "         0.0157,  0.0048, -0.0084, -0.0083, -0.0119, -0.0079,  0.0100,  0.0062,\n",
      "         0.0106, -0.0061,  0.0106, -0.0093, -0.0050,  0.0129, -0.0207,  0.0119,\n",
      "         0.0064, -0.0069,  0.0139, -0.0031, -0.0135,  0.0135,  0.0111, -0.0194])\n",
      "Layer: layer4.2.bn2.weight:, Weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Layer: layer4.2.bn2.bias, Biases: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Layer: KANClassifier.1.bias, Biases: tensor([[-1.3758, -2.9940,  0.8463,  2.3187, -2.5407,  2.3297, -1.3961, -2.0403,\n",
      "          0.8004,  1.0879,  1.0158,  1.8600, -2.9019,  2.4034, -0.8635,  0.7029,\n",
      "         -0.1953, -3.1094,  0.7632,  0.0120, -0.1742, -2.7760,  0.4157, -1.6533,\n",
      "         -2.3691, -3.0034,  0.7593, -0.8160,  2.7111,  1.7814, -0.9087, -0.7688,\n",
      "          2.3297,  1.8794, -1.5790, -1.0334,  2.8819, -2.2367, -2.4349,  1.7607,\n",
      "         -0.7054,  0.2895, -1.5905,  2.0150, -0.5189, -2.4766,  0.6979, -0.2955,\n",
      "         -2.6112,  1.1938, -2.3093,  1.1281,  1.5964,  2.2912, -0.8165,  0.1877,\n",
      "          0.1406, -2.1198, -2.1914, -1.5140, -2.8735, -2.1024,  1.5805,  0.4533,\n",
      "          2.5305, -2.0128, -2.4880, -0.0663,  2.9341,  1.1616,  0.1723, -0.3045,\n",
      "          3.1300,  2.9354,  3.1100, -2.0422, -2.0312, -0.4083,  2.8425, -2.9346,\n",
      "         -1.7242,  1.3236, -3.1135, -1.7738, -0.8718, -2.8844, -2.4615, -3.1049,\n",
      "          2.3908, -2.9267,  0.9897,  0.7546,  0.1567,  0.2924, -1.0375, -2.5219,\n",
      "         -0.9143,  3.0795,  1.6161,  0.7732,  2.2874,  2.0482,  2.2790, -2.1488,\n",
      "          2.9065,  2.2043,  2.8917, -0.3572, -0.1232,  1.7829, -1.1487, -0.9803,\n",
      "         -2.3591,  1.5599, -1.1193,  2.1808, -0.6602,  0.6905, -0.3997, -3.0106,\n",
      "          0.6401,  1.5060,  2.9178,  3.0334, -2.3235,  0.6964, -2.1732, -1.3939,\n",
      "         -2.9280,  0.4282, -1.3776,  1.4321, -1.4900, -1.0481, -0.6654,  0.8024,\n",
      "         -2.3458,  2.9096,  0.2628, -3.1348, -2.0970,  1.8656,  0.7110,  0.4647,\n",
      "         -2.9791,  0.4778, -2.3570,  0.2022, -1.5665,  2.4864,  2.2160, -0.3286,\n",
      "          3.1322, -2.9430, -0.3840, -1.8095, -1.4792,  1.6611, -2.7299,  1.9447,\n",
      "         -2.9888,  2.6996,  1.5666,  2.1094, -2.9781, -1.3954,  2.2580, -0.1315,\n",
      "         -1.4088, -0.2998,  2.6553,  2.5391,  1.7056,  1.9587, -2.9878, -0.4825,\n",
      "          0.3076,  2.4877,  1.9259,  2.8931,  2.3652, -1.5035,  2.2594,  0.7325,\n",
      "          1.8270,  0.6215,  1.1533, -0.5436,  2.6990, -1.7372,  0.3282, -0.2938,\n",
      "          3.0623, -3.0979,  1.3740, -1.6129, -0.4152, -1.7028, -2.5453, -2.7888,\n",
      "         -0.3098,  2.0986,  1.3924,  1.8413,  2.9237,  1.2207, -1.1509,  1.0572,\n",
      "          2.5611, -1.1516, -0.2921, -0.5402, -0.1316,  0.4686, -0.1304, -0.4944,\n",
      "         -1.1967, -0.0078,  0.6006,  2.2273,  2.6589,  0.9875, -2.7574, -0.1962,\n",
      "         -2.6350,  1.5993, -0.8704,  1.8290,  2.8512,  1.7462,  3.0993, -1.7347,\n",
      "         -1.6217, -2.0739, -2.1798, -1.0565, -0.0670, -2.7729, -2.1964, -2.7134,\n",
      "         -0.5814, -2.5409, -1.6570, -1.4672,  1.1073, -1.0195,  2.7267,  0.9152,\n",
      "         -1.3724, -1.1024,  0.0140, -0.0129,  0.6347,  1.3822,  0.7359,  1.1023,\n",
      "         -0.5589,  2.0803,  2.4219, -0.9544,  1.1185,  1.4335, -2.8729,  1.1431,\n",
      "          2.0495,  2.9703,  1.9853, -0.0638,  0.2245,  2.3747,  1.7871,  1.1521,\n",
      "          2.5351,  0.8320, -1.0410, -0.4596, -0.1359, -2.0227,  2.7839, -1.8752,\n",
      "         -1.0950,  0.1353,  1.1196, -1.5180,  0.6736, -0.7013, -3.0931,  3.0884,\n",
      "          0.8172, -1.4379,  0.5621,  2.5645,  0.4501,  1.7509,  1.6080,  1.8914,\n",
      "          1.7487,  1.2970, -2.6318, -1.6665,  2.0051,  0.8162, -1.0761,  0.7870,\n",
      "          2.9986,  0.7190,  0.4717, -1.1585,  1.0797, -0.4155, -1.4410,  1.9463,\n",
      "          2.1722,  2.6145, -2.3966, -1.3401, -0.8514,  1.2864, -1.2439, -3.0251,\n",
      "          0.6588, -2.4444,  1.2484, -0.5050,  2.3264,  0.3045, -2.1033, -0.5022,\n",
      "         -1.5775, -1.5912,  0.6720,  1.1685,  0.7958,  1.6459, -1.4357,  2.5009,\n",
      "          0.0569,  0.8847,  0.0787,  0.5464,  2.1532, -0.3842, -3.1134,  2.9396,\n",
      "          0.5044,  1.4599, -2.6475, -0.6517, -1.1855,  1.4029,  2.0894, -2.1466,\n",
      "          0.6994, -1.3832, -2.5908,  2.3258,  1.2093, -1.0195, -2.7522,  0.7938,\n",
      "          0.7210,  2.9751,  1.3743,  2.9904,  0.3404,  1.5452,  2.2048,  0.8271,\n",
      "          2.4896,  2.6453,  2.1239, -1.6063,  2.9175, -2.8294,  2.3153,  0.9763,\n",
      "          2.4138,  0.6715, -1.0764, -0.1509,  3.0136,  0.6692,  0.9009,  1.2458,\n",
      "          0.8911, -0.0529, -1.7280, -2.9589,  0.7581,  1.2702, -1.7378, -0.0036,\n",
      "         -1.0692, -2.4174, -2.7728, -2.4767, -2.1410,  0.2010,  2.7296,  2.3833,\n",
      "          0.8335, -1.0804,  2.2146,  1.2733, -2.4470, -0.5937, -0.4269, -1.1263,\n",
      "         -1.0905, -2.9270, -1.4662,  2.3095,  1.9750, -2.8405,  0.9028, -2.0037,\n",
      "          0.5486,  0.7116, -2.7378, -2.0230, -2.4378, -2.8849,  0.8736,  2.1903,\n",
      "          1.8759,  3.0478,  2.6237,  3.0307, -2.3629,  0.2919,  0.0908, -0.7945,\n",
      "         -2.4190,  1.8291, -2.3281,  0.0910, -1.4149, -0.7311,  0.5757,  0.2117,\n",
      "          2.5769, -2.5200, -1.0714, -0.3712,  0.8814, -1.1383, -0.4113, -2.6978,\n",
      "         -0.3318, -0.4339,  0.4507,  0.8975, -2.2292, -1.9889,  1.8558, -2.0713,\n",
      "          2.8576,  1.4770,  1.7992, -3.0085, -2.7382, -0.4537,  2.9135,  0.1964,\n",
      "         -1.9747, -0.6037, -2.0240, -2.3974,  0.2309,  2.7007,  0.7048, -2.1345,\n",
      "         -0.2685, -0.8146, -2.7502, -1.0481, -1.0823, -2.1859, -0.6987, -0.8200,\n",
      "         -0.2580,  0.7522,  0.0988,  2.6791,  2.1754,  0.1302,  2.9949, -2.6250,\n",
      "          2.3638,  1.7315, -0.5906,  2.6596, -0.2853, -1.7030, -0.1127, -0.1934,\n",
      "          1.2902, -2.7238, -1.9807, -3.0168,  0.3045,  2.1123,  1.1589, -0.6213,\n",
      "         -2.7789,  0.6692,  3.0942, -2.8506,  0.3613,  0.7429,  0.1932,  1.6950]])\n",
      "Layer: KANClassifier.2.bias, Biases: tensor([[-0.4512, -1.8751,  2.3812,  2.9201,  2.2896,  0.9163, -0.3591,  2.1218,\n",
      "          1.7555,  0.3257,  0.3355,  1.2942, -3.0934,  2.5497, -1.4665,  2.8206,\n",
      "         -1.9098, -2.0113,  2.6851, -0.0968, -0.1157,  3.0854,  0.0638, -1.3496,\n",
      "          1.1687, -1.9674]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in fsl_model.named_parameters():\n",
    "  if \"weight\" in name:\n",
    "    print(f\"Layer: {name}:, Weights: {param.data}\")\n",
    "  elif \"bias\" in name:\n",
    "    print(f\"Layer: {name}, Biases: {param.data}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
