{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/eonurk/CNN-KAN/blob/main/CNN_KAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtlZnvl4vdBs"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QaUPxiJleN-D",
    "outputId": "6a1693fb-bf07-4e95-b72c-144af45cbcb8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 17:33:11.016982: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/crl/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Train Epoch: 0 [0/6000 (0%)]\tLoss: 2.022842\n",
      "Train Epoch: 0 [640/6000 (11%)]\tLoss: 2.445345\n",
      "Train Epoch: 0 [1280/6000 (21%)]\tLoss: 2.267748\n",
      "Train Epoch: 0 [1920/6000 (32%)]\tLoss: 2.345423\n",
      "Train Epoch: 0 [2560/6000 (43%)]\tLoss: 2.343441\n",
      "Train Epoch: 0 [3200/6000 (53%)]\tLoss: 2.423165\n",
      "Train Epoch: 0 [3840/6000 (64%)]\tLoss: 2.403017\n",
      "Train Epoch: 0 [4480/6000 (74%)]\tLoss: 2.416418\n",
      "Train Epoch: 0 [5120/6000 (85%)]\tLoss: 2.209141\n",
      "Train Epoch: 0 [5760/6000 (96%)]\tLoss: 2.254274\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 1005/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tensorflow import keras\n",
    "\n",
    "# NaiveFourierKANLayer definition (as previously discussed)\n",
    "class NaiveFourierKANLayer(nn.Module):\n",
    "    def __init__(self, inputdim, outdim, initial_gridsize, addbias=True):\n",
    "        super(NaiveFourierKANLayer, self).__init__()\n",
    "        self.addbias = addbias\n",
    "        self.inputdim = inputdim\n",
    "        self.outdim = outdim\n",
    "        self.gridsize_param = nn.Parameter(torch.tensor(initial_gridsize, dtype=torch.float32)) #adjusted during training\n",
    "        self.fouriercoeffs = nn.Parameter(torch.empty(2, outdim, inputdim, initial_gridsize)) #adjusted during training\n",
    "        nn.init.xavier_uniform_(self.fouriercoeffs)\n",
    "        if self.addbias:\n",
    "            self.bias = nn.Parameter(torch.zeros(1, outdim))\n",
    "\n",
    "    def forward(self, x): #Combines cosine/sine terms with learnable coefficents for Fourier expansion and sums them + bias\n",
    "        gridsize = torch.clamp(self.gridsize_param, min=1).round().int()\n",
    "        outshape = x.shape[:-1] + (self.outdim,)\n",
    "        x = torch.reshape(x, (-1, self.inputdim))\n",
    "        k = torch.reshape(torch.arange(1, gridsize + 1, device=x.device), (1, 1, 1, gridsize))\n",
    "        xrshp = torch.reshape(x, (x.shape[0], 1, x.shape[1], 1))\n",
    "        c = torch.cos(k * xrshp)\n",
    "        s = torch.sin(k * xrshp)\n",
    "        y = torch.sum(c * self.fouriercoeffs[0:1, :, :, :gridsize], (-2, -1))\n",
    "        y += torch.sum(s * self.fouriercoeffs[1:2, :, :, :gridsize], (-2, -1))\n",
    "        if self.addbias:\n",
    "            y += self.bias\n",
    "        y = torch.reshape(y, outshape)\n",
    "        return y\n",
    "\n",
    "# CNNFourierKAN model definition\n",
    "class CNNFourierKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNFourierKAN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fourierkan1 = NaiveFourierKANLayer(32*7*7, 128, initial_gridsize=100)\n",
    "        self.fourierkan2 = NaiveFourierKANLayer(128, 10, initial_gridsize=100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.selu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.selu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fourierkan1(x)\n",
    "        x = self.fourierkan2(x)\n",
    "        return x\n",
    "\n",
    "# Dataset and DataLoader setup\n",
    "\n",
    "#Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "#Convert data to PyTorch tensors\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "#Reshape data to add channel dimension\n",
    "x_train = x_train.unsqueeze(1)\n",
    "x_test = x_test.unsqueeze(1)\n",
    "\n",
    "#Create data loaders\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "subset_indices = np.random.choice(len(train_dataset), int(len(train_dataset) * 0.1), replace=False)\n",
    "train_subset = Subset(train_dataset, subset_indices)\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# Model, Optimizer and Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNFourierKAN().to(device)\n",
    "optimizer = optim.LBFGS(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training function\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data.to(device))\n",
    "            loss = nn.CrossEntropyLoss()(output, target.to(device))\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "        if batch_idx % 10 == 0:\n",
    "            loss = closure()  # Re-run closure to get loss for printing\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn.CrossEntropyLoss()(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "\n",
    "# Running training and evaluation\n",
    "for epoch in range(0, 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "evaluate(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkuY2Pn_eFqg"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
